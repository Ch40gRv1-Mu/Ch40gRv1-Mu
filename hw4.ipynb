{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJYz_YSl66oL"
      },
      "source": [
        "# 10-714 Homework 4\n",
        "\n",
        "In this homework, you will leverage all of the components built in the last three homeworks to solve some modern problems with high performing network structures. We will start by adding a few new ops leveraging our new CPU/CUDA backends. Then, you will implement convolution, and a convolutional neural network to train a classifier on the CIFAR-10 image classification dataset. Then, you will implement recurrent and long-short term memory (LSTM) neural networks, and do word-level prediction language modeling on the Penn Treebank dataset.\n",
        "\n",
        "As always, we will start by copying this notebook and getting the starting code.\n",
        "Reminder: __you must save a copy in drive__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhqB97UU66oM",
        "outputId": "919a58f9-29eb-4a22-b40a-1a91f89ac30e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/10714\n",
            "fatal: destination path 'hw4' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/10714/hw4\n",
            "Collecting git+https://github.com/dlsys10714/mugrade.git\n",
            "  Cloning https://github.com/dlsys10714/mugrade.git to /tmp/pip-req-build-vzi1ckhu\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/dlsys10714/mugrade.git /tmp/pip-req-build-vzi1ckhu\n",
            "  Resolved https://github.com/dlsys10714/mugrade.git to commit ac73f725eb2ce0e2c6a38fa540035ee970b8b873\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n"
          ]
        }
      ],
      "source": [
        "# Code to set up the assignment\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/\n",
        "!mkdir -p 10714\n",
        "%cd /content/drive/MyDrive/10714\n",
        "!git clone https://github.com/dlsys10714/hw4.git\n",
        "%cd /content/drive/MyDrive/10714/hw4\n",
        "\n",
        "!pip3 install --upgrade --no-deps git+https://github.com/dlsys10714/mugrade.git\n",
        "!pip3 install pybind11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "rnasCl8V66oM"
      },
      "outputs": [],
      "source": [
        "# REQUIRED FOR MUGRADE\n",
        "MY_API_KEY = \"npnvWYJh0QPS6kFO40SK\"\n",
        "HW4_NAME = \"hw4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkAuYUb766oM",
        "outputId": "9467bc83-c655-4ab3-bd99-14a1dcc59cb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.10 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
            "  to tell CMake that the project requires at least <min> but has been updated\n",
            "  to work with policies introduced by <max> or earlier.\n",
            "\n",
            "\u001b[0m\n",
            "-- Found pybind11: /usr/local/lib/python3.12/dist-packages/pybind11/include (found version \"3.0.1\")\n",
            "-- Found cuda, building cuda backend\n",
            "-- Configuring done (0.6s)\n",
            "-- Generating done (0.6s)\n",
            "-- Build files have been written to: /content/drive/MyDrive/10714/hw4/build\n",
            "make[1]: Entering directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "make[2]: Entering directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "[  0%] Built target ndarray_backend_cpu\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "[ 25%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/ndarray_backend_cuda.dir/src/ndarray_backend_cuda_generated_ndarray_backend_cuda.cu.o\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX shared module /content/drive/MyDrive/10714/hw4/python/needle/backend_ndarray/ndarray_backend_cuda.cpython-312-x86_64-linux-gnu.so\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "[ 50%] Built target ndarray_backend_cuda\n",
            "make[2]: Leaving directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "make[1]: Leaving directory '/content/drive/MyDrive/10714/hw4/build'\n"
          ]
        }
      ],
      "source": [
        "!make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsZ4wUug66oM",
        "outputId": "473191dc-3599-4a61-9c69-b45d7605a955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=./python\n",
            "env: NEEDLE_BACKEND=nd\n"
          ]
        }
      ],
      "source": [
        "%set_env PYTHONPATH ./python\n",
        "%set_env NEEDLE_BACKEND nd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "KXXl19NP66oM"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('./python')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "VwL0Qtfh66oM"
      },
      "outputs": [],
      "source": [
        "# Download the datasets you will be using for this assignment\n",
        "\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "!mkdir -p './data/ptb'\n",
        "# Download Penn Treebank dataset\n",
        "ptb_data = \"https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.\"\n",
        "for f in ['train.txt', 'test.txt', 'valid.txt']:\n",
        "    if not os.path.exists(os.path.join('./data/ptb', f)):\n",
        "        urllib.request.urlretrieve(ptb_data + f, os.path.join('./data/ptb', f))\n",
        "\n",
        "# Download CIFAR-10 dataset\n",
        "if not os.path.isdir(\"./data/cifar-10-batches-py\"):\n",
        "    urllib.request.urlretrieve(\"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\", \"./data/cifar-10-python.tar.gz\")\n",
        "    !tar -xvzf './data/cifar-10-python.tar.gz' -C './data'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DX8NprUX66oN"
      },
      "source": [
        "To finish setting up the assignment, go ahead and fill in all the code in `python/needle/autograd.py` using your solution code from the previous homework. Also copy the solutions in `src/ndarray_backend_cpu.cc` and `src/ndarray_backend_cuda.cu` from homework 3.\n",
        "\n",
        "**Note**: Be careful not to accidentally delete or modify any new imports and function declarations when copying over code from previous assignments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IRWOZwj66oN"
      },
      "source": [
        "## Part 1: ND Backend [10 pts]\n",
        "\n",
        "Recall that in homework 2, the `array_api` was imported as `numpy`. In this part, the goal is to write the necessary operations with `array_api` imported from the needle backend `NDArray` in `python/needle/backend_ndarray/ndarray.py`. Make sure to copy the solutions for `reshape`, `permute`, `broadcast_to` and `__getitem__` from homework 3.\n",
        "\n",
        "Fill in the following classes in `python/needle/ops/ops_logarithmic.py` and `python/needle/ops/ops_mathematic.py`:\n",
        "\n",
        "- `PowerScalar`\n",
        "- `EWiseDiv`\n",
        "- `DivScalar`\n",
        "- `Transpose`\n",
        "- `Reshape`\n",
        "- `BroadcastTo`\n",
        "- `Summation`\n",
        "- `MatMul`\n",
        "- `Negate`\n",
        "- `Log`\n",
        "- `Exp`\n",
        "- `ReLU`\n",
        "- `LogSumExp`\n",
        "- `Tanh` (new)\n",
        "- `Stack` (new)\n",
        "- `Split` (new)\n",
        "\n",
        "Note that for most of these, you already wrote the solutions in the previous homework and you should not change most part of your previous solution, if issues arise, please check if the `array_api` function used is supported in the needle backend.\n",
        "\n",
        "The `Tanh`, `Stack`, and `Split` operators are newly added. `Stack` concatenates same-sized tensors along a new axis, and `Split` undoes this operation. The gradients of the two operations can be written in terms of each other. We do not directly test `Split`, and only test the backward pass of `Stack` (for which we assume you used `Split`).\n",
        "\n",
        "**Note:** You may want to make your Summation op support sums over multiple axes; you will likely need it for the backward pass of the BroadcastTo op if yours supports broadcasting over multiple axes at a time. However, this is more about ease of use than necessity, and we leave this decision up to you (there are no corresponding tests).\n",
        "\n",
        "**Note:** Depending on your implementations, you may want to ensure that you call `.compact()` before reshaping arrays. (If this is necessary, you will run into corresponding error messages later in the assignment.)\n",
        "\n",
        "**Note**: Be careful not to accidentally delete or modify any new imports and function declarations when copying over code from previous assignments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyuBN41q66oN",
        "outputId": "ae02a701-2900-421c-bfe4-9b0989e89424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[ 2.5433717 ,  2.202355  , -1.7542894 , ...,  0.4746837 ,\n",
            "         0.291169  ,  0.632095  ],\n",
            "       [ 0.5023340...8],\n",
            "       [ 0.3124429 ,  0.67045975, -0.2541804 , ...,  0.8254428 ,\n",
            "        -0.9933159 , -1.3417903 ]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bc4230>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (74, 73), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939bc6060>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (74, 73)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m________________________ test_matmul[cuda-128-128-128] _________________________\u001b[0m\n",
            "\n",
            "m = 128, n = 128, p = 128, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mm,n,p\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, MATMUL_DIMS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_matmul\u001b[39;49;00m(m, n, p, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(m, n).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _B = np.random.randn(n, p).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[ 1.9537501 ,  0.05903736, -1.2711045 , ...,  0.22699478,\n",
            "        -0.10282926, -0.18651716],\n",
            "       [-0.2311179...2],\n",
            "       [ 0.06558133, -1.1310216 , -1.9421903 , ..., -1.8011059 ,\n",
            "         1.3072039 ,  0.5935067 ]], dtype=float32)\n",
            "_B         = array([[ 0.9572396 , -0.46439824, -1.6827878 , ..., -0.11662703,\n",
            "        -1.5686997 ,  0.01031934],\n",
            "       [-0.1855606...7],\n",
            "       [-0.8687678 , -1.4076406 ,  2.1396523 , ...,  1.6590946 ,\n",
            "        -0.4116172 , -0.4557549 ]], dtype=float32)\n",
            "device     = cuda()\n",
            "m          = 128\n",
            "n          = 128\n",
            "p          = 128\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:91: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[ 1.9537501   0.05903736 -1.2711045  ...  0.22699478 -0.10282926\n",
            "  -0.18651716]\n",
            " [-0.2311179  -0.41253147 -1....43\n",
            "   0.36630192]\n",
            " [ 0.06558133 -1.1310216  -1.9421903  ... -1.8011059   1.3072039\n",
            "   0.5935067 ]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939bc5ee0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[ 1.9537501   0.05903736 -1.2711045  ...  0.22699478 -0.10282926\n",
            "  -0.18651716]\n",
            " [-0.2311179  -0.41253147 -1....43\n",
            "   0.36630192]\n",
            " [ 0.06558133 -1.1310216  -1.9421903  ... -1.8011059   1.3072039\n",
            "   0.5935067 ]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[ 1.9537501   0.05903736 -1.2711045  ...  0.22699478 -0.10282926\n",
            "  -0.18651716]\n",
            " [-0.2311179  -0.41253147 -1....43\n",
            "   0.36630192]\n",
            " [ 0.06558133 -1.1310216  -1.9421903  ... -1.8011059   1.3072039\n",
            "   0.5935067 ]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[ 1.9537501   0.05903736 -1.2711045  ...  0.22699478 -0.10282926\n",
            "  -0.18651716]\n",
            " [-0.2311179  -0.41253147 -1....43\n",
            "   0.36630192]\n",
            " [ 0.06558133 -1.1310216  -1.9421903  ... -1.8011059   1.3072039\n",
            "   0.5935067 ]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bc4530>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[ 1.9537501   0.05903736 -1.2711045  ...  0.22699478 -0.10282926\n",
            "  -0.18651716]\n",
            " [-0.2311179  -0.41253147 -1....43\n",
            "   0.36630192]\n",
            " [ 0.06558133 -1.1310216  -1.9421903  ... -1.8011059   1.3072039\n",
            "   0.5935067 ]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[ 1.9537501 ,  0.05903736, -1.2711045 , ...,  0.22699478,\n",
            "        -0.10282926, -0.18651716],\n",
            "       [-0.2311179...2],\n",
            "       [ 0.06558133, -1.1310216 , -1.9421903 , ..., -1.8011059 ,\n",
            "         1.3072039 ,  0.5935067 ]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bc4dd0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (128, 128), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939bc6120>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (128, 128)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m___________________________ test_power[cuda-shape0] ____________________________\u001b[0m\n",
            "\n",
            "shape = (1, 1, 1), device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, GENERAL_SHAPES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_power\u001b[39;49;00m(shape, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _B = np.random.randint(\u001b[94m1\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[1.171145]]], dtype=float32)\n",
            "_B         = 0\n",
            "device     = cuda()\n",
            "shape      = (1, 1, 1)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:101: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[1.171145]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939bf7b30>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[1.171145]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[1.171145]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[1.171145]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bf7320>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[1.171145]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[1.171145]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bf6420>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (1, 1, 1), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939bf4d10>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (1, 1, 1)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m___________________________ test_power[cuda-shape1] ____________________________\u001b[0m\n",
            "\n",
            "shape = (4, 5, 6), device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, GENERAL_SHAPES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_power\u001b[39;49;00m(shape, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _B = np.random.randint(\u001b[94m1\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[-0.6280028 , -0.43987197,  2.9139524 ,  0.05009432,\n",
            "         -0.73577106, -0.47775924],\n",
            "        [-1.7431105 ,...16 ],\n",
            "        [-0.8517918 , -1.9387237 ,  0.42015556, -0.24831858,\n",
            "         -1.0194412 ,  0.38210192]]], dtype=float32)\n",
            "_B         = 0\n",
            "device     = cuda()\n",
            "shape      = (4, 5, 6)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:101: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[-0.6280028  -0.43987197  2.9139524   0.05009432 -0.73577106\n",
            "   -0.47775924]\n",
            "  [-1.7431105  -1.9756789  -0.3...08\n",
            "    1.2529916 ]\n",
            "  [-0.8517918  -1.9387237   0.42015556 -0.24831858 -1.0194412\n",
            "    0.38210192]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939bf7860>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[-0.6280028  -0.43987197  2.9139524   0.05009432 -0.73577106\n",
            "   -0.47775924]\n",
            "  [-1.7431105  -1.9756789  -0.3...08\n",
            "    1.2529916 ]\n",
            "  [-0.8517918  -1.9387237   0.42015556 -0.24831858 -1.0194412\n",
            "    0.38210192]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[-0.6280028  -0.43987197  2.9139524   0.05009432 -0.73577106\n",
            "   -0.47775924]\n",
            "  [-1.7431105  -1.9756789  -0.3...08\n",
            "    1.2529916 ]\n",
            "  [-0.8517918  -1.9387237   0.42015556 -0.24831858 -1.0194412\n",
            "    0.38210192]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[-0.6280028  -0.43987197  2.9139524   0.05009432 -0.73577106\n",
            "   -0.47775924]\n",
            "  [-1.7431105  -1.9756789  -0.3...08\n",
            "    1.2529916 ]\n",
            "  [-0.8517918  -1.9387237   0.42015556 -0.24831858 -1.0194412\n",
            "    0.38210192]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bf50d0>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[-0.6280028  -0.43987197  2.9139524   0.05009432 -0.73577106\n",
            "   -0.47775924]\n",
            "  [-1.7431105  -1.9756789  -0.3...08\n",
            "    1.2529916 ]\n",
            "  [-0.8517918  -1.9387237   0.42015556 -0.24831858 -1.0194412\n",
            "    0.38210192]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[-0.6280028 , -0.43987197,  2.9139524 ,  0.05009432,\n",
            "         -0.73577106, -0.47775924],\n",
            "        [-1.7431105 ,...16 ],\n",
            "        [-0.8517918 , -1.9387237 ,  0.42015556, -0.24831858,\n",
            "         -1.0194412 ,  0.38210192]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bf63f0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (4, 5, 6), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939bf7170>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (4, 5, 6)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m____________________________ test_log[cuda-shape0] _____________________________\u001b[0m\n",
            "\n",
            "shape = (1, 1, 1), device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, GENERAL_SHAPES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_log\u001b[39;49;00m(shape, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32) + \u001b[94m5.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[6.5344124]]], dtype=float32)\n",
            "device     = cuda()\n",
            "shape      = (1, 1, 1)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:109: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[6.5344124]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939bc5ac0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[6.5344124]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[6.5344124]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[6.5344124]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bc6180>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[6.5344124]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[6.5344124]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bc7e60>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (1, 1, 1), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939bc4ec0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (1, 1, 1)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m____________________________ test_log[cuda-shape1] _____________________________\u001b[0m\n",
            "\n",
            "shape = (4, 5, 6), device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, GENERAL_SHAPES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_log\u001b[39;49;00m(shape, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32) + \u001b[94m5.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[3.516722 , 4.4941716, 3.9078727, 5.770175 , 4.984753 ,\n",
            "         5.790717 ],\n",
            "        [2.6877737, 4.846334 , 5....      5.082136 ],\n",
            "        [6.005202 , 4.3703594, 5.3648767, 4.616481 , 5.4491186,\n",
            "         5.858667 ]]], dtype=float32)\n",
            "device     = cuda()\n",
            "shape      = (4, 5, 6)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:109: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[3.516722  4.4941716 3.9078727 5.770175  4.984753  5.790717 ]\n",
            "  [2.6877737 4.846334  5.371132  5.643005  4.3...4 4.144942  5.491352  5.082136 ]\n",
            "  [6.005202  4.3703594 5.3648767 4.616481  5.4491186 5.858667 ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939bf6e40>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[3.516722  4.4941716 3.9078727 5.770175  4.984753  5.790717 ]\n",
            "  [2.6877737 4.846334  5.371132  5.643005  4.3...4 4.144942  5.491352  5.082136 ]\n",
            "  [6.005202  4.3703594 5.3648767 4.616481  5.4491186 5.858667 ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[3.516722  4.4941716 3.9078727 5.770175  4.984753  5.790717 ]\n",
            "  [2.6877737 4.846334  5.371132  5.643005  4.3...4 4.144942  5.491352  5.082136 ]\n",
            "  [6.005202  4.3703594 5.3648767 4.616481  5.4491186 5.858667 ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[3.516722  4.4941716 3.9078727 5.770175  4.984753  5.790717 ]\n",
            "  [2.6877737 4.846334  5.371132  5.643005  4.3...4 4.144942  5.491352  5.082136 ]\n",
            "  [6.005202  4.3703594 5.3648767 4.616481  5.4491186 5.858667 ]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bf4890>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[3.516722  4.4941716 3.9078727 5.770175  4.984753  5.790717 ]\n",
            "  [2.6877737 4.846334  5.371132  5.643005  4.3...4 4.144942  5.491352  5.082136 ]\n",
            "  [6.005202  4.3703594 5.3648767 4.616481  5.4491186 5.858667 ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[3.516722 , 4.4941716, 3.9078727, 5.770175 , 4.984753 ,\n",
            "         5.790717 ],\n",
            "        [2.6877737, 4.846334 , 5....      5.082136 ],\n",
            "        [6.005202 , 4.3703594, 5.3648767, 4.616481 , 5.4491186,\n",
            "         5.858667 ]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bf6660>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (4, 5, 6), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939bf6990>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (4, 5, 6)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m____________________________ test_exp[cuda-shape0] _____________________________\u001b[0m\n",
            "\n",
            "shape = (1, 1, 1), device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, GENERAL_SHAPES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_exp\u001b[39;49;00m(shape, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[0.14809337]]], dtype=float32)\n",
            "device     = cuda()\n",
            "shape      = (1, 1, 1)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:117: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[0.14809337]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939bbe1e0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[0.14809337]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[0.14809337]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[0.14809337]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bbc8c0>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[0.14809337]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[0.14809337]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bbdd30>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (1, 1, 1), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939bbea80>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (1, 1, 1)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m____________________________ test_exp[cuda-shape1] _____________________________\u001b[0m\n",
            "\n",
            "shape = (4, 5, 6), device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, GENERAL_SHAPES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_exp\u001b[39;49;00m(shape, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[ 2.4905684 , -0.6954556 , -1.8243234 , -0.31614092,\n",
            "          0.08606078, -0.74876255],\n",
            "        [ 1.3998232 ,...898],\n",
            "        [ 0.1688959 ,  0.02774058, -1.563431  ,  0.17357937,\n",
            "          0.47140115,  1.1728562 ]]], dtype=float32)\n",
            "device     = cuda()\n",
            "shape      = (4, 5, 6)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:117: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[ 2.4905684  -0.6954556  -1.8243234  -0.31614092  0.08606078\n",
            "   -0.74876255]\n",
            "  [ 1.3998232  -1.0975965  -0.2...1\n",
            "   -0.49917898]\n",
            "  [ 0.1688959   0.02774058 -1.563431    0.17357937  0.47140115\n",
            "    1.1728562 ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939bf50a0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[ 2.4905684  -0.6954556  -1.8243234  -0.31614092  0.08606078\n",
            "   -0.74876255]\n",
            "  [ 1.3998232  -1.0975965  -0.2...1\n",
            "   -0.49917898]\n",
            "  [ 0.1688959   0.02774058 -1.563431    0.17357937  0.47140115\n",
            "    1.1728562 ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[ 2.4905684  -0.6954556  -1.8243234  -0.31614092  0.08606078\n",
            "   -0.74876255]\n",
            "  [ 1.3998232  -1.0975965  -0.2...1\n",
            "   -0.49917898]\n",
            "  [ 0.1688959   0.02774058 -1.563431    0.17357937  0.47140115\n",
            "    1.1728562 ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[ 2.4905684  -0.6954556  -1.8243234  -0.31614092  0.08606078\n",
            "   -0.74876255]\n",
            "  [ 1.3998232  -1.0975965  -0.2...1\n",
            "   -0.49917898]\n",
            "  [ 0.1688959   0.02774058 -1.563431    0.17357937  0.47140115\n",
            "    1.1728562 ]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bf7b00>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[ 2.4905684  -0.6954556  -1.8243234  -0.31614092  0.08606078\n",
            "   -0.74876255]\n",
            "  [ 1.3998232  -1.0975965  -0.2...1\n",
            "   -0.49917898]\n",
            "  [ 0.1688959   0.02774058 -1.563431    0.17357937  0.47140115\n",
            "    1.1728562 ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[ 2.4905684 , -0.6954556 , -1.8243234 , -0.31614092,\n",
            "          0.08606078, -0.74876255],\n",
            "        [ 1.3998232 ,...898],\n",
            "        [ 0.1688959 ,  0.02774058, -1.563431  ,  0.17357937,\n",
            "          0.47140115,  1.1728562 ]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bf7dd0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (4, 5, 6), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939bf4740>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (4, 5, 6)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m____________________________ test_relu[cuda-shape0] ____________________________\u001b[0m\n",
            "\n",
            "shape = (1, 1, 1), device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, GENERAL_SHAPES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_relu\u001b[39;49;00m(shape, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[1.2374331]]], dtype=float32)\n",
            "device     = cuda()\n",
            "shape      = (1, 1, 1)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:125: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[1.2374331]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939bbc3e0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[1.2374331]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[1.2374331]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[1.2374331]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bbdd30>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[1.2374331]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[1.2374331]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bbee70>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (1, 1, 1), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939bbe4e0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (1, 1, 1)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m____________________________ test_relu[cuda-shape1] ____________________________\u001b[0m\n",
            "\n",
            "shape = (4, 5, 6), device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, GENERAL_SHAPES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_relu\u001b[39;49;00m(shape, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[-0.05377588,  0.20338777,  0.16131176,  0.04317565,\n",
            "         -1.4132142 ,  0.14171205],\n",
            "        [-0.5501977 ,...069],\n",
            "        [-0.79452735,  0.3885921 ,  0.13083026,  0.47227657,\n",
            "         -2.1078956 ,  0.21374775]]], dtype=float32)\n",
            "device     = cuda()\n",
            "shape      = (4, 5, 6)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:125: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[-0.05377588  0.20338777  0.16131176  0.04317565 -1.4132142\n",
            "    0.14171205]\n",
            "  [-0.5501977  -1.1564685   0.16...37\n",
            "   -0.20687069]\n",
            "  [-0.79452735  0.3885921   0.13083026  0.47227657 -2.1078956\n",
            "    0.21374775]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939bcd400>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[-0.05377588  0.20338777  0.16131176  0.04317565 -1.4132142\n",
            "    0.14171205]\n",
            "  [-0.5501977  -1.1564685   0.16...37\n",
            "   -0.20687069]\n",
            "  [-0.79452735  0.3885921   0.13083026  0.47227657 -2.1078956\n",
            "    0.21374775]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[-0.05377588  0.20338777  0.16131176  0.04317565 -1.4132142\n",
            "    0.14171205]\n",
            "  [-0.5501977  -1.1564685   0.16...37\n",
            "   -0.20687069]\n",
            "  [-0.79452735  0.3885921   0.13083026  0.47227657 -2.1078956\n",
            "    0.21374775]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[-0.05377588  0.20338777  0.16131176  0.04317565 -1.4132142\n",
            "    0.14171205]\n",
            "  [-0.5501977  -1.1564685   0.16...37\n",
            "   -0.20687069]\n",
            "  [-0.79452735  0.3885921   0.13083026  0.47227657 -2.1078956\n",
            "    0.21374775]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bcdc70>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[-0.05377588  0.20338777  0.16131176  0.04317565 -1.4132142\n",
            "    0.14171205]\n",
            "  [-0.5501977  -1.1564685   0.16...37\n",
            "   -0.20687069]\n",
            "  [-0.79452735  0.3885921   0.13083026  0.47227657 -2.1078956\n",
            "    0.21374775]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[-0.05377588,  0.20338777,  0.16131176,  0.04317565,\n",
            "         -1.4132142 ,  0.14171205],\n",
            "        [-0.5501977 ,...069],\n",
            "        [-0.79452735,  0.3885921 ,  0.13083026,  0.47227657,\n",
            "         -2.1078956 ,  0.21374775]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bce420>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (4, 5, 6), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939bcf980>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (4, 5, 6)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m____________________________ test_tanh[cuda-shape0] ____________________________\u001b[0m\n",
            "\n",
            "shape = (1, 1, 1), device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, GENERAL_SHAPES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_tanh\u001b[39;49;00m(shape, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[-2.3530958]]], dtype=float32)\n",
            "device     = cuda()\n",
            "shape      = (1, 1, 1)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:133: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[-2.3530958]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939bcf560>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[-2.3530958]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[-2.3530958]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[-2.3530958]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bcfc20>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[-2.3530958]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[-2.3530958]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bcd250>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (1, 1, 1), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939bcfad0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (1, 1, 1)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m____________________________ test_tanh[cuda-shape1] ____________________________\u001b[0m\n",
            "\n",
            "shape = (4, 5, 6), device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, GENERAL_SHAPES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_tanh\u001b[39;49;00m(shape, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[-0.5291037 , -1.1316243 ,  1.2829843 ,  0.6779355 ,\n",
            "         -0.32166547, -0.51734763],\n",
            "        [ 0.48438653,...48 ],\n",
            "        [-0.8919766 , -0.5311779 ,  1.3061328 ,  0.70647854,\n",
            "          0.99664706, -1.344323  ]]], dtype=float32)\n",
            "device     = cuda()\n",
            "shape      = (4, 5, 6)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:133: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[-0.5291037  -1.1316243   1.2829843   0.6779355  -0.32166547\n",
            "   -0.51734763]\n",
            "  [ 0.48438653 -1.1732628   1.5...6\n",
            "   -1.0003148 ]\n",
            "  [-0.8919766  -0.5311779   1.3061328   0.70647854  0.99664706\n",
            "   -1.344323  ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939a3cce0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[-0.5291037  -1.1316243   1.2829843   0.6779355  -0.32166547\n",
            "   -0.51734763]\n",
            "  [ 0.48438653 -1.1732628   1.5...6\n",
            "   -1.0003148 ]\n",
            "  [-0.8919766  -0.5311779   1.3061328   0.70647854  0.99664706\n",
            "   -1.344323  ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[-0.5291037  -1.1316243   1.2829843   0.6779355  -0.32166547\n",
            "   -0.51734763]\n",
            "  [ 0.48438653 -1.1732628   1.5...6\n",
            "   -1.0003148 ]\n",
            "  [-0.8919766  -0.5311779   1.3061328   0.70647854  0.99664706\n",
            "   -1.344323  ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[-0.5291037  -1.1316243   1.2829843   0.6779355  -0.32166547\n",
            "   -0.51734763]\n",
            "  [ 0.48438653 -1.1732628   1.5...6\n",
            "   -1.0003148 ]\n",
            "  [-0.8919766  -0.5311779   1.3061328   0.70647854  0.99664706\n",
            "   -1.344323  ]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a3e180>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[-0.5291037  -1.1316243   1.2829843   0.6779355  -0.32166547\n",
            "   -0.51734763]\n",
            "  [ 0.48438653 -1.1732628   1.5...6\n",
            "   -1.0003148 ]\n",
            "  [-0.8919766  -0.5311779   1.3061328   0.70647854  0.99664706\n",
            "   -1.344323  ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[-0.5291037 , -1.1316243 ,  1.2829843 ,  0.6779355 ,\n",
            "         -0.32166547, -0.51734763],\n",
            "        [ 0.48438653,...48 ],\n",
            "        [-0.8919766 , -0.5311779 ,  1.3061328 ,  0.70647854,\n",
            "          0.99664706, -1.344323  ]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a3e0f0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (4, 5, 6), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939a3e8a0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (4, 5, 6)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_______________________ test_tanh_backward[cuda-shape0] ________________________\u001b[0m\n",
            "\n",
            "shape = (1, 1, 1), device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, GENERAL_SHAPES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_tanh_backward\u001b[39;49;00m(shape, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[0.90795034]]], dtype=float32)\n",
            "device     = cuda()\n",
            "shape      = (1, 1, 1)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:141: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[0.90795034]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939bceab0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[0.90795034]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[0.90795034]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[0.90795034]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bcf9b0>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[0.90795034]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[0.90795034]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bcf230>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (1, 1, 1), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939bcfd40>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (1, 1, 1)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_______________________ test_tanh_backward[cuda-shape1] ________________________\u001b[0m\n",
            "\n",
            "shape = (4, 5, 6), device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, GENERAL_SHAPES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_tanh_backward\u001b[39;49;00m(shape, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[ 1.1914672 ,  0.6276671 ,  1.7709465 ,  2.5802875 ,\n",
            "          1.0994289 , -0.25607443],\n",
            "        [-0.30351138,...125],\n",
            "        [ 0.6493112 , -0.8847228 , -1.9263881 , -1.6778411 ,\n",
            "          0.455592  ,  0.29220578]]], dtype=float32)\n",
            "device     = cuda()\n",
            "shape      = (4, 5, 6)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:141: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[ 1.1914672   0.6276671   1.7709465   2.5802875   1.0994289\n",
            "   -0.25607443]\n",
            "  [-0.30351138 -1.2755342   1.43...374\n",
            "    0.13385125]\n",
            "  [ 0.6493112  -0.8847228  -1.9263881  -1.6778411   0.455592\n",
            "    0.29220578]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939a3c980>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[ 1.1914672   0.6276671   1.7709465   2.5802875   1.0994289\n",
            "   -0.25607443]\n",
            "  [-0.30351138 -1.2755342   1.43...374\n",
            "    0.13385125]\n",
            "  [ 0.6493112  -0.8847228  -1.9263881  -1.6778411   0.455592\n",
            "    0.29220578]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[ 1.1914672   0.6276671   1.7709465   2.5802875   1.0994289\n",
            "   -0.25607443]\n",
            "  [-0.30351138 -1.2755342   1.43...374\n",
            "    0.13385125]\n",
            "  [ 0.6493112  -0.8847228  -1.9263881  -1.6778411   0.455592\n",
            "    0.29220578]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[ 1.1914672   0.6276671   1.7709465   2.5802875   1.0994289\n",
            "   -0.25607443]\n",
            "  [-0.30351138 -1.2755342   1.43...374\n",
            "    0.13385125]\n",
            "  [ 0.6493112  -0.8847228  -1.9263881  -1.6778411   0.455592\n",
            "    0.29220578]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a3e630>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[ 1.1914672   0.6276671   1.7709465   2.5802875   1.0994289\n",
            "   -0.25607443]\n",
            "  [-0.30351138 -1.2755342   1.43...374\n",
            "    0.13385125]\n",
            "  [ 0.6493112  -0.8847228  -1.9263881  -1.6778411   0.455592\n",
            "    0.29220578]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[ 1.1914672 ,  0.6276671 ,  1.7709465 ,  2.5802875 ,\n",
            "          1.0994289 , -0.25607443],\n",
            "        [-0.30351138,...125],\n",
            "        [ 0.6493112 , -0.8847228 , -1.9263881 , -1.6778411 ,\n",
            "          0.455592  ,  0.29220578]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a3e510>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (4, 5, 6), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939a3f050>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (4, 5, 6)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_________________________ test_stack[cuda-shape0-0-1] __________________________\u001b[0m\n",
            "\n",
            "shape = (5, 5), axis = 0, l = 1, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape, axis, l\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, STACK_PARAMETERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_stack\u001b[39;49;00m(shape, axis, l, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = [np.random.randn(*shape).astype(np.float32) \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(l)]\u001b[90m\u001b[39;49;00m\n",
            ">       A = [ndl.Tensor(nd.array(_A[i]), device=device) \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(l)]\u001b[90m\u001b[39;49;00m\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = [array([[ 1.7134967 , -0.41470623, -1.7430415 ,  0.6519293 ,  0.07126308],\n",
            "       [-0.48818034, -0.42512143, -0.232472...629536 ,  1.272113  ],\n",
            "       [-0.71344495, -1.5708133 , -0.37528518,  0.11450187,  1.4668971 ]],\n",
            "      dtype=float32)]\n",
            "axis       = 0\n",
            "device     = cuda()\n",
            "l          = 1\n",
            "shape      = (5, 5)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:152: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[ 1.7134967  -0.41470623 -1.7430415   0.6519293   0.07126308]\n",
            " [-0.48818034 -0.42512143 -0.2324723   0.720774....04173418  2.1629536   1.272113  ]\n",
            " [-0.71344495 -1.5708133  -0.37528518  0.11450187  1.4668971 ]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939a3e600>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[ 1.7134967  -0.41470623 -1.7430415   0.6519293   0.07126308]\n",
            " [-0.48818034 -0.42512143 -0.2324723   0.720774....04173418  2.1629536   1.272113  ]\n",
            " [-0.71344495 -1.5708133  -0.37528518  0.11450187  1.4668971 ]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[ 1.7134967  -0.41470623 -1.7430415   0.6519293   0.07126308]\n",
            " [-0.48818034 -0.42512143 -0.2324723   0.720774....04173418  2.1629536   1.272113  ]\n",
            " [-0.71344495 -1.5708133  -0.37528518  0.11450187  1.4668971 ]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[ 1.7134967  -0.41470623 -1.7430415   0.6519293   0.07126308]\n",
            " [-0.48818034 -0.42512143 -0.2324723   0.720774....04173418  2.1629536   1.272113  ]\n",
            " [-0.71344495 -1.5708133  -0.37528518  0.11450187  1.4668971 ]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a3f260>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[ 1.7134967  -0.41470623 -1.7430415   0.6519293   0.07126308]\n",
            " [-0.48818034 -0.42512143 -0.2324723   0.720774....04173418  2.1629536   1.272113  ]\n",
            " [-0.71344495 -1.5708133  -0.37528518  0.11450187  1.4668971 ]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[ 1.7134967 , -0.41470623, -1.7430415 ,  0.6519293 ,  0.07126308],\n",
            "       [-0.48818034, -0.42512143, -0.2324723...1629536 ,  1.272113  ],\n",
            "       [-0.71344495, -1.5708133 , -0.37528518,  0.11450187,  1.4668971 ]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a3f0e0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (5, 5), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939a3c470>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (5, 5)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_________________________ test_stack[cuda-shape1-0-2] __________________________\u001b[0m\n",
            "\n",
            "shape = (5, 5), axis = 0, l = 2, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape, axis, l\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, STACK_PARAMETERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_stack\u001b[39;49;00m(shape, axis, l, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = [np.random.randn(*shape).astype(np.float32) \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(l)]\u001b[90m\u001b[39;49;00m\n",
            ">       A = [ndl.Tensor(nd.array(_A[i]), device=device) \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(l)]\u001b[90m\u001b[39;49;00m\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = [array([[-1.3115026 , -0.10614888,  0.6780119 , -0.74381435,  0.29154974],\n",
            "       [-1.0264622 ,  0.05647625,  1.332177...8355542,  1.1190343 ],\n",
            "       [-1.2428849 ,  0.34594685, -0.83825415,  0.0265399 , -0.13059294]],\n",
            "      dtype=float32)]\n",
            "axis       = 0\n",
            "device     = cuda()\n",
            "l          = 2\n",
            "shape      = (5, 5)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:152: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[-1.3115026  -0.10614888  0.6780119  -0.74381435  0.29154974]\n",
            " [-1.0264622   0.05647625  1.3321772  -0.399015....20510961  1.5976351  -1.3755882 ]\n",
            " [-1.4667304  -0.3004477  -0.26057717  0.8301129  -1.4546351 ]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939a3ddc0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[-1.3115026  -0.10614888  0.6780119  -0.74381435  0.29154974]\n",
            " [-1.0264622   0.05647625  1.3321772  -0.399015....20510961  1.5976351  -1.3755882 ]\n",
            " [-1.4667304  -0.3004477  -0.26057717  0.8301129  -1.4546351 ]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[-1.3115026  -0.10614888  0.6780119  -0.74381435  0.29154974]\n",
            " [-1.0264622   0.05647625  1.3321772  -0.399015....20510961  1.5976351  -1.3755882 ]\n",
            " [-1.4667304  -0.3004477  -0.26057717  0.8301129  -1.4546351 ]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[-1.3115026  -0.10614888  0.6780119  -0.74381435  0.29154974]\n",
            " [-1.0264622   0.05647625  1.3321772  -0.399015....20510961  1.5976351  -1.3755882 ]\n",
            " [-1.4667304  -0.3004477  -0.26057717  0.8301129  -1.4546351 ]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a3df40>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[-1.3115026  -0.10614888  0.6780119  -0.74381435  0.29154974]\n",
            " [-1.0264622   0.05647625  1.3321772  -0.399015....20510961  1.5976351  -1.3755882 ]\n",
            " [-1.4667304  -0.3004477  -0.26057717  0.8301129  -1.4546351 ]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[-1.3115026 , -0.10614888,  0.6780119 , -0.74381435,  0.29154974],\n",
            "       [-1.0264622 ,  0.05647625,  1.3321772...5976351 , -1.3755882 ],\n",
            "       [-1.4667304 , -0.3004477 , -0.26057717,  0.8301129 , -1.4546351 ]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a3e6f0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (5, 5), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939a3f800>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (5, 5)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_________________________ test_stack[cuda-shape2-2-5] __________________________\u001b[0m\n",
            "\n",
            "shape = (1, 5, 7), axis = 2, l = 5, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape, axis, l\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, STACK_PARAMETERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_stack\u001b[39;49;00m(shape, axis, l, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = [np.random.randn(*shape).astype(np.float32) \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(l)]\u001b[90m\u001b[39;49;00m\n",
            ">       A = [ndl.Tensor(nd.array(_A[i]), device=device) \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(l)]\u001b[90m\u001b[39;49;00m\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = [array([[[-2.0257597e+00, -9.2441577e-01,  8.7577009e-01,  8.2509273e-01,\n",
            "         -3.4123892e-01,  1.1967411e+00, -2....[-1.4124417 ,  1.7589831 , -2.416149  ,  0.22257139,\n",
            "         -0.19093359, -1.1048661 ,  1.0865548 ]]], dtype=float32)]\n",
            "axis       = 2\n",
            "device     = cuda()\n",
            "l          = 5\n",
            "shape      = (1, 5, 7)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:152: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[-2.0257597e+00 -9.2441577e-01  8.7577009e-01  8.2509273e-01\n",
            "   -3.4123892e-01  1.1967411e+00 -2.4219371e-01...01 -1.3308005e+00  1.3250008e-03  9.9273151e-01\n",
            "    1.5571724e-01  1.4486442e-02  1.7297605e+00]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939a3f9e0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[-2.0257597e+00 -9.2441577e-01  8.7577009e-01  8.2509273e-01\n",
            "   -3.4123892e-01  1.1967411e+00 -2.4219371e-01...01 -1.3308005e+00  1.3250008e-03  9.9273151e-01\n",
            "    1.5571724e-01  1.4486442e-02  1.7297605e+00]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[-2.0257597e+00 -9.2441577e-01  8.7577009e-01  8.2509273e-01\n",
            "   -3.4123892e-01  1.1967411e+00 -2.4219371e-01...01 -1.3308005e+00  1.3250008e-03  9.9273151e-01\n",
            "    1.5571724e-01  1.4486442e-02  1.7297605e+00]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[-2.0257597e+00 -9.2441577e-01  8.7577009e-01  8.2509273e-01\n",
            "   -3.4123892e-01  1.1967411e+00 -2.4219371e-01...01 -1.3308005e+00  1.3250008e-03  9.9273151e-01\n",
            "    1.5571724e-01  1.4486442e-02  1.7297605e+00]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a3df10>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[-2.0257597e+00 -9.2441577e-01  8.7577009e-01  8.2509273e-01\n",
            "   -3.4123892e-01  1.1967411e+00 -2.4219371e-01...01 -1.3308005e+00  1.3250008e-03  9.9273151e-01\n",
            "    1.5571724e-01  1.4486442e-02  1.7297605e+00]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[-2.0257597e+00, -9.2441577e-01,  8.7577009e-01,  8.2509273e-01,\n",
            "         -3.4123892e-01,  1.1967411e+00, -2.4...3308005e+00,  1.3250008e-03,  9.9273151e-01,\n",
            "          1.5571724e-01,  1.4486442e-02,  1.7297605e+00]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a3c380>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (1, 5, 7), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939a3da60>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (1, 5, 7)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_____________________ test_stack_backward[cpu-shape0-0-1] ______________________\u001b[0m\n",
            "\n",
            "shape = (5, 5), axis = 0, l = 1, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape, axis, l\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, STACK_PARAMETERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_stack_backward\u001b[39;49;00m(shape, axis, l, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = [np.random.randn(*shape).astype(np.float32) \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(l)]\u001b[90m\u001b[39;49;00m\n",
            "        A = [ndl.Tensor(nd.array(_A[i]), device=device) \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(l)]\u001b[90m\u001b[39;49;00m\n",
            "        A_t = [torch.Tensor(_A[i]) \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(l)]\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(l):\u001b[90m\u001b[39;49;00m\n",
            "            A_t[i].requires_grad = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       ndl.stack(A, axis=axis).sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "A          = [needle.Tensor([[ 0.2816349   0.3178875   0.21565525 -0.16981374 -0.9697202 ]\n",
            " [-1.5763242   0.9952032  -0.11875166  0...0888 -0.37552926  0.41463757 -0.3126289  -0.78449106]\n",
            " [ 2.2518485   0.34867704  0.09316532 -0.95765305  0.8677775 ]])]\n",
            "A_t        = [tensor([[ 0.2816,  0.3179,  0.2157, -0.1698, -0.9697],\n",
            "        [-1.5763,  0.9952, -0.1188,  0.3065, -0.8361],\n",
            "       ...1713, -0.3755,  0.4146, -0.3126, -0.7845],\n",
            "        [ 2.2518,  0.3487,  0.0932, -0.9577,  0.8678]], requires_grad=True)]\n",
            "_A         = [array([[ 0.2816349 ,  0.3178875 ,  0.21565525, -0.16981374, -0.9697202 ],\n",
            "       [-1.5763242 ,  0.9952032 , -0.118751...126289 , -0.78449106],\n",
            "       [ 2.2518485 ,  0.34867704,  0.09316532, -0.95765305,  0.8677775 ]],\n",
            "      dtype=float32)]\n",
            "axis       = 0\n",
            "device     = cpu()\n",
            "i          = 0\n",
            "l          = 1\n",
            "shape      = (5, 5)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:167: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:297: in backward\n",
            "    \u001b[0mcompute_gradient_of_variables(\u001b[96mself\u001b[39;49;00m, out_grad)\u001b[90m\u001b[39;49;00m\n",
            "        out_grad   = needle.Tensor([1.])\n",
            "        self       = needle.Tensor([-0.9694019])\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:401: in compute_gradient_of_variables\n",
            "    \u001b[0minput_grads = node.op.gradient_as_tuple(node.grad, node)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        grad_list  = [needle.Tensor([[1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]])]\n",
            "        i          = 0\n",
            "        input_grads = (needle.Tensor([[1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]]),)\n",
            "        input_node = needle.TensorTuple(needle.Tensor([[ 0.2816349   0.3178875   0.21565525 -0.16981374 -0.9697202 ]\n",
            " [-1.5763242   0.99520...888 -0.37552926  0.41463757 -0.3126289  -0.78449106]\n",
            " [ 2.2518485   0.34867704  0.09316532 -0.95765305  0.8677775 ]]),)\n",
            "        node       = needle.TensorTuple(needle.Tensor([[ 0.2816349   0.3178875   0.21565525 -0.16981374 -0.9697202 ]\n",
            " [-1.5763242   0.99520...888 -0.37552926  0.41463757 -0.3126289  -0.78449106]\n",
            " [ 2.2518485   0.34867704  0.09316532 -0.95765305  0.8677775 ]]),)\n",
            "        node_to_output_grads_list = {needle.Tensor([-0.9694019]): [needle.Tensor([1.])], needle.Tensor([[[ 0.2816349   0.3178875   0.21565525 -0.16981374 ...775 ]]),): [needle.Tensor([[1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]])]}\n",
            "        out_grad   = needle.Tensor([1.])\n",
            "        output_tensor = needle.Tensor([-0.9694019])\n",
            "        reverse_topo_order = [needle.Tensor([-0.9694019]), needle.Tensor([[[ 0.2816349   0.3178875   0.21565525 -0.16981374 -0.9697202 ]\n",
            "  [-1.5763...0888 -0.37552926  0.41463757 -0.3126289  -0.78449106]\n",
            " [ 2.2518485   0.34867704  0.09316532 -0.95765305  0.8677775 ]])]\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:67: in gradient_as_tuple\n",
            "    \u001b[0moutput = \u001b[96mself\u001b[39;49;00m.gradient(out_grad, node)\u001b[90m\u001b[39;49;00m\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        node       = needle.TensorTuple(needle.Tensor([[ 0.2816349   0.3178875   0.21565525 -0.16981374 -0.9697202 ]\n",
            " [-1.5763242   0.99520...888 -0.37552926  0.41463757 -0.3126289  -0.78449106]\n",
            " [ 2.2518485   0.34867704  0.09316532 -0.95765305  0.8677775 ]]),)\n",
            "        out_grad   = needle.Tensor([[1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]])\n",
            "        self       = <needle.ops.ops_tuple.MakeTensorTuple object at 0x7c7939bce9f0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_tuple.MakeTensorTuple object at 0x7c7939bce9f0>\n",
            "out_grad = needle.Tensor([[1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]])\n",
            "node = needle.TensorTuple(needle.Tensor([[ 0.2816349   0.3178875   0.21565525 -0.16981374 -0.9697202 ]\n",
            " [-1.5763242   0.99520...888 -0.37552926  0.41463757 -0.3126289  -0.78449106]\n",
            " [ 2.2518485   0.34867704  0.09316532 -0.95765305  0.8677775 ]]),)\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mgradient\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, out_grad, node):\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(out_grad, TensorTuple)\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError\u001b[0m\n",
            "\n",
            "node       = needle.TensorTuple(needle.Tensor([[ 0.2816349   0.3178875   0.21565525 -0.16981374 -0.9697202 ]\n",
            " [-1.5763242   0.99520...888 -0.37552926  0.41463757 -0.3126289  -0.78449106]\n",
            " [ 2.2518485   0.34867704  0.09316532 -0.95765305  0.8677775 ]]),)\n",
            "out_grad   = needle.Tensor([[1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]])\n",
            "self       = <needle.ops.ops_tuple.MakeTensorTuple object at 0x7c7939bce9f0>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_tuple.py\u001b[0m:9: AssertionError\n",
            "\u001b[31m\u001b[1m_____________________ test_stack_backward[cpu-shape1-0-2] ______________________\u001b[0m\n",
            "\n",
            "shape = (5, 5), axis = 0, l = 2, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape, axis, l\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, STACK_PARAMETERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_stack_backward\u001b[39;49;00m(shape, axis, l, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = [np.random.randn(*shape).astype(np.float32) \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(l)]\u001b[90m\u001b[39;49;00m\n",
            "        A = [ndl.Tensor(nd.array(_A[i]), device=device) \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(l)]\u001b[90m\u001b[39;49;00m\n",
            "        A_t = [torch.Tensor(_A[i]) \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(l)]\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(l):\u001b[90m\u001b[39;49;00m\n",
            "            A_t[i].requires_grad = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       ndl.stack(A, axis=axis).sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "A          = [needle.Tensor([[ 0.886228    0.8968615   0.3050795   0.48108444 -0.5455804 ]\n",
            " [-0.36771476  0.5798573  -1.9824095  -0...0516  1.2291428  -0.54384065 -0.9167164  -1.2931924 ]\n",
            " [-0.50769776 -0.6700247  -1.0846429   0.00867054  1.0298263 ]])]\n",
            "A_t        = [tensor([[ 0.8862,  0.8969,  0.3051,  0.4811, -0.5456],\n",
            "        [-0.3677,  0.5799, -1.9824, -0.8696,  0.7906],\n",
            "       ...3858,  1.2291, -0.5438, -0.9167, -1.2932],\n",
            "        [-0.5077, -0.6700, -1.0846,  0.0087,  1.0298]], requires_grad=True)]\n",
            "_A         = [array([[ 0.886228  ,  0.8968615 ,  0.3050795 ,  0.48108444, -0.5455804 ],\n",
            "       [-0.36771476,  0.5798573 , -1.982409...167164 , -1.2931924 ],\n",
            "       [-0.50769776, -0.6700247 , -1.0846429 ,  0.00867054,  1.0298263 ]],\n",
            "      dtype=float32)]\n",
            "axis       = 0\n",
            "device     = cpu()\n",
            "i          = 1\n",
            "l          = 2\n",
            "shape      = (5, 5)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:167: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:297: in backward\n",
            "    \u001b[0mcompute_gradient_of_variables(\u001b[96mself\u001b[39;49;00m, out_grad)\u001b[90m\u001b[39;49;00m\n",
            "        out_grad   = needle.Tensor([1.])\n",
            "        self       = needle.Tensor([-3.117652])\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:401: in compute_gradient_of_variables\n",
            "    \u001b[0minput_grads = node.op.gradient_as_tuple(node.grad, node)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        grad_list  = [needle.Tensor([[1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]])]\n",
            "        i          = 0\n",
            "        input_grads = (needle.Tensor([[1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]]),)\n",
            "        input_node = needle.TensorTuple(needle.Tensor([[ 0.886228    0.8968615   0.3050795   0.48108444 -0.5455804 ]\n",
            " [-0.36771476  0.57985...0516  1.2291428  -0.54384065 -0.9167164  -1.2931924 ]\n",
            " [-0.50769776 -0.6700247  -1.0846429   0.00867054  1.0298263 ]]))\n",
            "        node       = needle.TensorTuple(needle.Tensor([[ 0.886228    0.8968615   0.3050795   0.48108444 -0.5455804 ]\n",
            " [-0.36771476  0.57985...0516  1.2291428  -0.54384065 -0.9167164  -1.2931924 ]\n",
            " [-0.50769776 -0.6700247  -1.0846429   0.00867054  1.0298263 ]]))\n",
            "        node_to_output_grads_list = {needle.Tensor([-3.117652]): [needle.Tensor([1.])], needle.Tensor([[[ 0.886228    0.8968615   0.3050795   0.48108444 -...8263 ]])): [needle.Tensor([[1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]])]}\n",
            "        out_grad   = needle.Tensor([1.])\n",
            "        output_tensor = needle.Tensor([-3.117652])\n",
            "        reverse_topo_order = [needle.Tensor([-3.117652]), needle.Tensor([[[ 0.886228    0.8968615   0.3050795   0.48108444 -0.5455804 ]\n",
            "  [-0.36771...558   0.8739965  -0.41004968 -1.4406291  -1.1649334 ]\n",
            " [-0.88063025 -0.01936003  0.7857401   0.6362656   0.14448641]])]\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:67: in gradient_as_tuple\n",
            "    \u001b[0moutput = \u001b[96mself\u001b[39;49;00m.gradient(out_grad, node)\u001b[90m\u001b[39;49;00m\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        node       = needle.TensorTuple(needle.Tensor([[ 0.886228    0.8968615   0.3050795   0.48108444 -0.5455804 ]\n",
            " [-0.36771476  0.57985...0516  1.2291428  -0.54384065 -0.9167164  -1.2931924 ]\n",
            " [-0.50769776 -0.6700247  -1.0846429   0.00867054  1.0298263 ]]))\n",
            "        out_grad   = needle.Tensor([[1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]])\n",
            "        self       = <needle.ops.ops_tuple.MakeTensorTuple object at 0x7c7939ac5e20>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_tuple.MakeTensorTuple object at 0x7c7939ac5e20>\n",
            "out_grad = needle.Tensor([[1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]])\n",
            "node = needle.TensorTuple(needle.Tensor([[ 0.886228    0.8968615   0.3050795   0.48108444 -0.5455804 ]\n",
            " [-0.36771476  0.57985...0516  1.2291428  -0.54384065 -0.9167164  -1.2931924 ]\n",
            " [-0.50769776 -0.6700247  -1.0846429   0.00867054  1.0298263 ]]))\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mgradient\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, out_grad, node):\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(out_grad, TensorTuple)\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError\u001b[0m\n",
            "\n",
            "node       = needle.TensorTuple(needle.Tensor([[ 0.886228    0.8968615   0.3050795   0.48108444 -0.5455804 ]\n",
            " [-0.36771476  0.57985...0516  1.2291428  -0.54384065 -0.9167164  -1.2931924 ]\n",
            " [-0.50769776 -0.6700247  -1.0846429   0.00867054  1.0298263 ]]))\n",
            "out_grad   = needle.Tensor([[1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]])\n",
            "self       = <needle.ops.ops_tuple.MakeTensorTuple object at 0x7c7939ac5e20>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_tuple.py\u001b[0m:9: AssertionError\n",
            "\u001b[31m\u001b[1m_____________________ test_stack_backward[cpu-shape2-2-5] ______________________\u001b[0m\n",
            "\n",
            "shape = (1, 5, 7), axis = 2, l = 5, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape, axis, l\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, STACK_PARAMETERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_stack_backward\u001b[39;49;00m(shape, axis, l, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = [np.random.randn(*shape).astype(np.float32) \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(l)]\u001b[90m\u001b[39;49;00m\n",
            "        A = [ndl.Tensor(nd.array(_A[i]), device=device) \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(l)]\u001b[90m\u001b[39;49;00m\n",
            "        A_t = [torch.Tensor(_A[i]) \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(l)]\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(l):\u001b[90m\u001b[39;49;00m\n",
            "            A_t[i].requires_grad = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       ndl.stack(A, axis=axis).sum().backward()\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "A          = [needle.Tensor([[[ 0.64557946 -0.6966982   2.6833293   1.065397   -0.5908425\n",
            "   -1.110827   -1.3543594 ]\n",
            "  [ 1.0475779... -0.06175245  1.6014707 ]\n",
            "  [ 1.1028751  -0.9660115   1.0091268  -0.39626575 -1.7092937\n",
            "    1.2298361   0.32076636]]])]\n",
            "A_t        = [tensor([[[ 0.6456, -0.6967,  2.6833,  1.0654, -0.5908, -1.1108, -1.3544],\n",
            "         [ 1.0476, -1.5948,  1.2582, -1.886...0618,  1.6015],\n",
            "         [ 1.1029, -0.9660,  1.0091, -0.3963, -1.7093,  1.2298,  0.3208]]],\n",
            "       requires_grad=True)]\n",
            "_A         = [array([[[ 0.64557946, -0.6966982 ,  2.6833293 ,  1.065397  ,\n",
            "         -0.5908425 , -1.110827  , -1.3543594 ],\n",
            "       ...[ 1.1028751 , -0.9660115 ,  1.0091268 , -0.39626575,\n",
            "         -1.7092937 ,  1.2298361 ,  0.32076636]]], dtype=float32)]\n",
            "axis       = 2\n",
            "device     = cpu()\n",
            "i          = 4\n",
            "l          = 5\n",
            "shape      = (1, 5, 7)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:167: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:297: in backward\n",
            "    \u001b[0mcompute_gradient_of_variables(\u001b[96mself\u001b[39;49;00m, out_grad)\u001b[90m\u001b[39;49;00m\n",
            "        out_grad   = needle.Tensor([1.])\n",
            "        self       = needle.Tensor([9.767403])\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:401: in compute_gradient_of_variables\n",
            "    \u001b[0minput_grads = node.op.gradient_as_tuple(node.grad, node)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        grad_list  = [needle.Tensor([[[1. 1. 1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1. 1. 1.]]])]\n",
            "        i          = 0\n",
            "        input_grads = (needle.Tensor([[[1. 1. 1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1. 1. 1.]]]),)\n",
            "        input_node = needle.TensorTuple(needle.Tensor([[[ 0.64557946 -0.6966982   2.6833293   1.065397   -0.5908425\n",
            "   -1.110827   -1.35435... -0.06175245  1.6014707 ]\n",
            "  [ 1.1028751  -0.9660115   1.0091268  -0.39626575 -1.7092937\n",
            "    1.2298361   0.32076636]]]))\n",
            "        node       = needle.TensorTuple(needle.Tensor([[[ 0.64557946 -0.6966982   2.6833293   1.065397   -0.5908425\n",
            "   -1.110827   -1.35435... -0.06175245  1.6014707 ]\n",
            "  [ 1.1028751  -0.9660115   1.0091268  -0.39626575 -1.7092937\n",
            "    1.2298361   0.32076636]]]))\n",
            "        node_to_output_grads_list = {needle.Tensor([9.767403]): [needle.Tensor([1.])], needle.Tensor([[[[ 0.64557946 -0.6966982   2.6833293   1.065397   -.... 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1. 1. 1.]]])]}\n",
            "        out_grad   = needle.Tensor([1.])\n",
            "        output_tensor = needle.Tensor([9.767403])\n",
            "        reverse_topo_order = [needle.Tensor([9.767403]), needle.Tensor([[[[ 0.64557946 -0.6966982   2.6833293   1.065397   -0.5908425\n",
            "    -1.110827...626434 -1.3271939 ]\n",
            "  [-0.3857271   1.9829966  -1.4881061  -0.05948393  0.49879983\n",
            "   -0.94834065 -0.7898696 ]]]), ...]\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:67: in gradient_as_tuple\n",
            "    \u001b[0moutput = \u001b[96mself\u001b[39;49;00m.gradient(out_grad, node)\u001b[90m\u001b[39;49;00m\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        node       = needle.TensorTuple(needle.Tensor([[[ 0.64557946 -0.6966982   2.6833293   1.065397   -0.5908425\n",
            "   -1.110827   -1.35435... -0.06175245  1.6014707 ]\n",
            "  [ 1.1028751  -0.9660115   1.0091268  -0.39626575 -1.7092937\n",
            "    1.2298361   0.32076636]]]))\n",
            "        out_grad   = needle.Tensor([[[1. 1. 1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1. 1. 1.]]])\n",
            "        self       = <needle.ops.ops_tuple.MakeTensorTuple object at 0x7c7939ac59a0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_tuple.MakeTensorTuple object at 0x7c7939ac59a0>\n",
            "out_grad = needle.Tensor([[[1. 1. 1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1. 1. 1.]]])\n",
            "node = needle.TensorTuple(needle.Tensor([[[ 0.64557946 -0.6966982   2.6833293   1.065397   -0.5908425\n",
            "   -1.110827   -1.35435... -0.06175245  1.6014707 ]\n",
            "  [ 1.1028751  -0.9660115   1.0091268  -0.39626575 -1.7092937\n",
            "    1.2298361   0.32076636]]]))\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mgradient\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, out_grad, node):\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(out_grad, TensorTuple)\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError\u001b[0m\n",
            "\n",
            "node       = needle.TensorTuple(needle.Tensor([[[ 0.64557946 -0.6966982   2.6833293   1.065397   -0.5908425\n",
            "   -1.110827   -1.35435... -0.06175245  1.6014707 ]\n",
            "  [ 1.1028751  -0.9660115   1.0091268  -0.39626575 -1.7092937\n",
            "    1.2298361   0.32076636]]]))\n",
            "out_grad   = needle.Tensor([[[1. 1. 1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1. 1. 1.]]])\n",
            "self       = <needle.ops.ops_tuple.MakeTensorTuple object at 0x7c7939ac59a0>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_tuple.py\u001b[0m:9: AssertionError\n",
            "\u001b[31m\u001b[1m_____________________ test_stack_backward[cuda-shape0-0-1] _____________________\u001b[0m\n",
            "\n",
            "shape = (5, 5), axis = 0, l = 1, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape, axis, l\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, STACK_PARAMETERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_stack_backward\u001b[39;49;00m(shape, axis, l, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = [np.random.randn(*shape).astype(np.float32) \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(l)]\u001b[90m\u001b[39;49;00m\n",
            ">       A = [ndl.Tensor(nd.array(_A[i]), device=device) \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(l)]\u001b[90m\u001b[39;49;00m\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = [array([[ 0.5721981 ,  0.2235861 ,  0.35144737, -1.193306  , -0.37559596],\n",
            "       [-0.8369131 ,  1.9658917 , -0.515321...222518 ,  1.489412  ],\n",
            "       [ 1.1438326 ,  1.6791093 , -1.203218  , -1.4277622 , -0.7563902 ]],\n",
            "      dtype=float32)]\n",
            "axis       = 0\n",
            "device     = cuda()\n",
            "l          = 1\n",
            "shape      = (5, 5)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:163: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[ 0.5721981   0.2235861   0.35144737 -1.193306   -0.37559596]\n",
            " [-0.8369131   1.9658917  -0.5153218  -0.006911....9560969  -1.0222518   1.489412  ]\n",
            " [ 1.1438326   1.6791093  -1.203218   -1.4277622  -0.7563902 ]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939a3c770>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[ 0.5721981   0.2235861   0.35144737 -1.193306   -0.37559596]\n",
            " [-0.8369131   1.9658917  -0.5153218  -0.006911....9560969  -1.0222518   1.489412  ]\n",
            " [ 1.1438326   1.6791093  -1.203218   -1.4277622  -0.7563902 ]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[ 0.5721981   0.2235861   0.35144737 -1.193306   -0.37559596]\n",
            " [-0.8369131   1.9658917  -0.5153218  -0.006911....9560969  -1.0222518   1.489412  ]\n",
            " [ 1.1438326   1.6791093  -1.203218   -1.4277622  -0.7563902 ]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[ 0.5721981   0.2235861   0.35144737 -1.193306   -0.37559596]\n",
            " [-0.8369131   1.9658917  -0.5153218  -0.006911....9560969  -1.0222518   1.489412  ]\n",
            " [ 1.1438326   1.6791093  -1.203218   -1.4277622  -0.7563902 ]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a3ef60>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[ 0.5721981   0.2235861   0.35144737 -1.193306   -0.37559596]\n",
            " [-0.8369131   1.9658917  -0.5153218  -0.006911....9560969  -1.0222518   1.489412  ]\n",
            " [ 1.1438326   1.6791093  -1.203218   -1.4277622  -0.7563902 ]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[ 0.5721981 ,  0.2235861 ,  0.35144737, -1.193306  , -0.37559596],\n",
            "       [-0.8369131 ,  1.9658917 , -0.5153218...0222518 ,  1.489412  ],\n",
            "       [ 1.1438326 ,  1.6791093 , -1.203218  , -1.4277622 , -0.7563902 ]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a3c380>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (5, 5), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939a3dc10>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (5, 5)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_____________________ test_stack_backward[cuda-shape1-0-2] _____________________\u001b[0m\n",
            "\n",
            "shape = (5, 5), axis = 0, l = 2, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape, axis, l\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, STACK_PARAMETERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_stack_backward\u001b[39;49;00m(shape, axis, l, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = [np.random.randn(*shape).astype(np.float32) \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(l)]\u001b[90m\u001b[39;49;00m\n",
            ">       A = [ndl.Tensor(nd.array(_A[i]), device=device) \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(l)]\u001b[90m\u001b[39;49;00m\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = [array([[-0.32789522,  1.3911211 ,  0.7655447 ,  1.9600631 ,  1.5961113 ],\n",
            "       [-0.2593512 , -0.8191968 , -0.009145...2705046,  0.07045578],\n",
            "       [ 0.05973172, -1.8943669 , -1.3532592 ,  0.08178733,  1.1173035 ]],\n",
            "      dtype=float32)]\n",
            "axis       = 0\n",
            "device     = cuda()\n",
            "l          = 2\n",
            "shape      = (5, 5)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:163: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[-0.32789522  1.3911211   0.7655447   1.9600631   1.5961113 ]\n",
            " [-0.2593512  -0.8191968  -0.00914596  0.148704....13224109  1.7002633   1.189483  ]\n",
            " [ 0.05497759  1.6756395  -0.01245357  0.00698522  1.9540731 ]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939ac48c0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[-0.32789522  1.3911211   0.7655447   1.9600631   1.5961113 ]\n",
            " [-0.2593512  -0.8191968  -0.00914596  0.148704....13224109  1.7002633   1.189483  ]\n",
            " [ 0.05497759  1.6756395  -0.01245357  0.00698522  1.9540731 ]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[-0.32789522  1.3911211   0.7655447   1.9600631   1.5961113 ]\n",
            " [-0.2593512  -0.8191968  -0.00914596  0.148704....13224109  1.7002633   1.189483  ]\n",
            " [ 0.05497759  1.6756395  -0.01245357  0.00698522  1.9540731 ]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[-0.32789522  1.3911211   0.7655447   1.9600631   1.5961113 ]\n",
            " [-0.2593512  -0.8191968  -0.00914596  0.148704....13224109  1.7002633   1.189483  ]\n",
            " [ 0.05497759  1.6756395  -0.01245357  0.00698522  1.9540731 ]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939ac7ec0>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[-0.32789522  1.3911211   0.7655447   1.9600631   1.5961113 ]\n",
            " [-0.2593512  -0.8191968  -0.00914596  0.148704....13224109  1.7002633   1.189483  ]\n",
            " [ 0.05497759  1.6756395  -0.01245357  0.00698522  1.9540731 ]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[-0.32789522,  1.3911211 ,  0.7655447 ,  1.9600631 ,  1.5961113 ],\n",
            "       [-0.2593512 , -0.8191968 , -0.0091459...7002633 ,  1.189483  ],\n",
            "       [ 0.05497759,  1.6756395 , -0.01245357,  0.00698522,  1.9540731 ]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939ac7980>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (5, 5), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939ac4770>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (5, 5)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_____________________ test_stack_backward[cuda-shape2-2-5] _____________________\u001b[0m\n",
            "\n",
            "shape = (1, 5, 7), axis = 2, l = 5, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape, axis, l\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, STACK_PARAMETERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_stack_backward\u001b[39;49;00m(shape, axis, l, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = [np.random.randn(*shape).astype(np.float32) \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(l)]\u001b[90m\u001b[39;49;00m\n",
            ">       A = [ndl.Tensor(nd.array(_A[i]), device=device) \u001b[94mfor\u001b[39;49;00m i \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(l)]\u001b[90m\u001b[39;49;00m\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = [array([[[-1.9620842 ,  1.1954788 , -0.591674  ,  1.1645355 ,\n",
            "         -1.3027852 ,  1.5342665 ,  1.0155736 ],\n",
            "       ...[-0.31015334,  0.9066847 , -0.15136234,  0.8248054 ,\n",
            "          0.588381  ,  1.102897  ,  0.14859103]]], dtype=float32)]\n",
            "axis       = 2\n",
            "device     = cuda()\n",
            "l          = 5\n",
            "shape      = (1, 5, 7)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:163: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[-1.9620842   1.1954788  -0.591674    1.1645355  -1.3027852\n",
            "    1.5342665   1.0155736 ]\n",
            "  [ 2.647594    1.21...095 ]\n",
            "  [-1.2008259  -0.05399305  2.054389   -1.274145   -0.50362986\n",
            "    1.3914616   0.10191219]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939ab6180>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[-1.9620842   1.1954788  -0.591674    1.1645355  -1.3027852\n",
            "    1.5342665   1.0155736 ]\n",
            "  [ 2.647594    1.21...095 ]\n",
            "  [-1.2008259  -0.05399305  2.054389   -1.274145   -0.50362986\n",
            "    1.3914616   0.10191219]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[-1.9620842   1.1954788  -0.591674    1.1645355  -1.3027852\n",
            "    1.5342665   1.0155736 ]\n",
            "  [ 2.647594    1.21...095 ]\n",
            "  [-1.2008259  -0.05399305  2.054389   -1.274145   -0.50362986\n",
            "    1.3914616   0.10191219]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[-1.9620842   1.1954788  -0.591674    1.1645355  -1.3027852\n",
            "    1.5342665   1.0155736 ]\n",
            "  [ 2.647594    1.21...095 ]\n",
            "  [-1.2008259  -0.05399305  2.054389   -1.274145   -0.50362986\n",
            "    1.3914616   0.10191219]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939ab5160>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[-1.9620842   1.1954788  -0.591674    1.1645355  -1.3027852\n",
            "    1.5342665   1.0155736 ]\n",
            "  [ 2.647594    1.21...095 ]\n",
            "  [-1.2008259  -0.05399305  2.054389   -1.274145   -0.50362986\n",
            "    1.3914616   0.10191219]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[-1.9620842 ,  1.1954788 , -0.591674  ,  1.1645355 ,\n",
            "         -1.3027852 ,  1.5342665 ,  1.0155736 ],\n",
            "        ... [-1.2008259 , -0.05399305,  2.054389  , -1.274145  ,\n",
            "         -0.50362986,  1.3914616 ,  0.10191219]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939ab6990>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (1, 5, 7), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939ab6a50>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (1, 5, 7)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_______________________ test_summation[cuda-shape0-None] _______________________\u001b[0m\n",
            "\n",
            "shape = (1, 1, 1), axes = None, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape, axes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SUMMATION_PARAMETERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_summation\u001b[39;49;00m(shape, axes, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[-1.9483194]]], dtype=float32)\n",
            "axes       = None\n",
            "device     = cuda()\n",
            "shape      = (1, 1, 1)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:182: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[-1.9483194]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939ab5430>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[-1.9483194]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[-1.9483194]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[-1.9483194]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939ab5610>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[-1.9483194]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[-1.9483194]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939ab7620>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (1, 1, 1), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939ab5280>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (1, 1, 1)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m________________________ test_summation[cuda-shape1-0] _________________________\u001b[0m\n",
            "\n",
            "shape = (5, 3), axes = 0, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape, axes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SUMMATION_PARAMETERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_summation\u001b[39;49;00m(shape, axes, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[ 0.21689712,  0.43637753, -0.49504337],\n",
            "       [ 1.4166641 , -0.2632424 ,  1.5031598 ],\n",
            "       [-1.2881242 , -...3875 ],\n",
            "       [ 1.1767663 , -1.223357  ,  1.9838535 ],\n",
            "       [-0.40351707,  1.5878327 ,  1.8947744 ]], dtype=float32)\n",
            "axes       = 0\n",
            "device     = cuda()\n",
            "shape      = (5, 3)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:182: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[ 0.21689712  0.43637753 -0.49504337]\n",
            " [ 1.4166641  -0.2632424   1.5031598 ]\n",
            " [-1.2881242  -0.24279231  0.5133875 ]\n",
            " [ 1.1767663  -1.223357    1.9838535 ]\n",
            " [-0.40351707  1.5878327   1.8947744 ]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939ac7740>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[ 0.21689712  0.43637753 -0.49504337]\n",
            " [ 1.4166641  -0.2632424   1.5031598 ]\n",
            " [-1.2881242  -0.24279231  0.5133875 ]\n",
            " [ 1.1767663  -1.223357    1.9838535 ]\n",
            " [-0.40351707  1.5878327   1.8947744 ]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[ 0.21689712  0.43637753 -0.49504337]\n",
            " [ 1.4166641  -0.2632424   1.5031598 ]\n",
            " [-1.2881242  -0.24279231  0.5133875 ]\n",
            " [ 1.1767663  -1.223357    1.9838535 ]\n",
            " [-0.40351707  1.5878327   1.8947744 ]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[ 0.21689712  0.43637753 -0.49504337]\n",
            " [ 1.4166641  -0.2632424   1.5031598 ]\n",
            " [-1.2881242  -0.24279231  0.5133875 ]\n",
            " [ 1.1767663  -1.223357    1.9838535 ]\n",
            " [-0.40351707  1.5878327   1.8947744 ]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939ac5550>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[ 0.21689712  0.43637753 -0.49504337]\n",
            " [ 1.4166641  -0.2632424   1.5031598 ]\n",
            " [-1.2881242  -0.24279231  0.5133875 ]\n",
            " [ 1.1767663  -1.223357    1.9838535 ]\n",
            " [-0.40351707  1.5878327   1.8947744 ]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[ 0.21689712,  0.43637753, -0.49504337],\n",
            "       [ 1.4166641 , -0.2632424 ,  1.5031598 ],\n",
            "       [-1.2881242 , -...3875 ],\n",
            "       [ 1.1767663 , -1.223357  ,  1.9838535 ],\n",
            "       [-0.40351707,  1.5878327 ,  1.8947744 ]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939ac6bd0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (5, 3), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939ac56d0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (5, 3)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m________________________ test_summation[cuda-shape2-1] _________________________\u001b[0m\n",
            "\n",
            "shape = (8, 3, 2), axes = 1, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape, axes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SUMMATION_PARAMETERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_summation\u001b[39;49;00m(shape, axes, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[ 1.2847524 , -0.955546  ],\n",
            "        [-0.42559817,  0.98641783],\n",
            "        [ 0.02986824, -0.71762425]],\n",
            "\n",
            "       [...  [[ 2.3362038 , -0.02063232],\n",
            "        [ 0.17829332,  1.2977082 ],\n",
            "        [ 1.223755  ,  0.5619403 ]]], dtype=float32)\n",
            "axes       = 1\n",
            "device     = cuda()\n",
            "shape      = (8, 3, 2)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:182: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[ 1.2847524  -0.955546  ]\n",
            "  [-0.42559817  0.98641783]\n",
            "  [ 0.02986824 -0.71762425]]\n",
            "\n",
            " [[-0.7889268   0.548743....05775288]]\n",
            "\n",
            " [[ 2.3362038  -0.02063232]\n",
            "  [ 0.17829332  1.2977082 ]\n",
            "  [ 1.223755    0.5619403 ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939a3e1b0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[ 1.2847524  -0.955546  ]\n",
            "  [-0.42559817  0.98641783]\n",
            "  [ 0.02986824 -0.71762425]]\n",
            "\n",
            " [[-0.7889268   0.548743....05775288]]\n",
            "\n",
            " [[ 2.3362038  -0.02063232]\n",
            "  [ 0.17829332  1.2977082 ]\n",
            "  [ 1.223755    0.5619403 ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[ 1.2847524  -0.955546  ]\n",
            "  [-0.42559817  0.98641783]\n",
            "  [ 0.02986824 -0.71762425]]\n",
            "\n",
            " [[-0.7889268   0.548743....05775288]]\n",
            "\n",
            " [[ 2.3362038  -0.02063232]\n",
            "  [ 0.17829332  1.2977082 ]\n",
            "  [ 1.223755    0.5619403 ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[ 1.2847524  -0.955546  ]\n",
            "  [-0.42559817  0.98641783]\n",
            "  [ 0.02986824 -0.71762425]]\n",
            "\n",
            " [[-0.7889268   0.548743....05775288]]\n",
            "\n",
            " [[ 2.3362038  -0.02063232]\n",
            "  [ 0.17829332  1.2977082 ]\n",
            "  [ 1.223755    0.5619403 ]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a3fb00>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[ 1.2847524  -0.955546  ]\n",
            "  [-0.42559817  0.98641783]\n",
            "  [ 0.02986824 -0.71762425]]\n",
            "\n",
            " [[-0.7889268   0.548743....05775288]]\n",
            "\n",
            " [[ 2.3362038  -0.02063232]\n",
            "  [ 0.17829332  1.2977082 ]\n",
            "  [ 1.223755    0.5619403 ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[ 1.2847524 , -0.955546  ],\n",
            "        [-0.42559817,  0.98641783],\n",
            "        [ 0.02986824, -0.71762425]],\n",
            "\n",
            "       [...  [[ 2.3362038 , -0.02063232],\n",
            "        [ 0.17829332,  1.2977082 ],\n",
            "        [ 1.223755  ,  0.5619403 ]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a3d940>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (8, 3, 2), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939a3eba0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (8, 3, 2)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m________________________ test_summation[cuda-shape3-2] _________________________\u001b[0m\n",
            "\n",
            "shape = (8, 3, 2), axes = 2, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape, axes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SUMMATION_PARAMETERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_summation\u001b[39;49;00m(shape, axes, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[ 0.5748034 , -0.39962965],\n",
            "        [ 0.39787385, -1.5687171 ],\n",
            "        [-0.5583447 , -0.8579677 ]],\n",
            "\n",
            "       [...  [[-0.7648952 , -0.33858636],\n",
            "        [ 1.2390388 , -1.1854753 ],\n",
            "        [ 0.45743605,  1.3178569 ]]], dtype=float32)\n",
            "axes       = 2\n",
            "device     = cuda()\n",
            "shape      = (8, 3, 2)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:182: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[ 0.5748034  -0.39962965]\n",
            "  [ 0.39787385 -1.5687171 ]\n",
            "  [-0.5583447  -0.8579677 ]]\n",
            "\n",
            " [[ 0.14308996 -1.598674....494915  ]]\n",
            "\n",
            " [[-0.7648952  -0.33858636]\n",
            "  [ 1.2390388  -1.1854753 ]\n",
            "  [ 0.45743605  1.3178569 ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939bf5730>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[ 0.5748034  -0.39962965]\n",
            "  [ 0.39787385 -1.5687171 ]\n",
            "  [-0.5583447  -0.8579677 ]]\n",
            "\n",
            " [[ 0.14308996 -1.598674....494915  ]]\n",
            "\n",
            " [[-0.7648952  -0.33858636]\n",
            "  [ 1.2390388  -1.1854753 ]\n",
            "  [ 0.45743605  1.3178569 ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[ 0.5748034  -0.39962965]\n",
            "  [ 0.39787385 -1.5687171 ]\n",
            "  [-0.5583447  -0.8579677 ]]\n",
            "\n",
            " [[ 0.14308996 -1.598674....494915  ]]\n",
            "\n",
            " [[-0.7648952  -0.33858636]\n",
            "  [ 1.2390388  -1.1854753 ]\n",
            "  [ 0.45743605  1.3178569 ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[ 0.5748034  -0.39962965]\n",
            "  [ 0.39787385 -1.5687171 ]\n",
            "  [-0.5583447  -0.8579677 ]]\n",
            "\n",
            " [[ 0.14308996 -1.598674....494915  ]]\n",
            "\n",
            " [[-0.7648952  -0.33858636]\n",
            "  [ 1.2390388  -1.1854753 ]\n",
            "  [ 0.45743605  1.3178569 ]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bf6270>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[ 0.5748034  -0.39962965]\n",
            "  [ 0.39787385 -1.5687171 ]\n",
            "  [-0.5583447  -0.8579677 ]]\n",
            "\n",
            " [[ 0.14308996 -1.598674....494915  ]]\n",
            "\n",
            " [[-0.7648952  -0.33858636]\n",
            "  [ 1.2390388  -1.1854753 ]\n",
            "  [ 0.45743605  1.3178569 ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[ 0.5748034 , -0.39962965],\n",
            "        [ 0.39787385, -1.5687171 ],\n",
            "        [-0.5583447 , -0.8579677 ]],\n",
            "\n",
            "       [...  [[-0.7648952 , -0.33858636],\n",
            "        [ 1.2390388 , -1.1854753 ],\n",
            "        [ 0.45743605,  1.3178569 ]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bf6240>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (8, 3, 2), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939bf5eb0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (8, 3, 2)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m__________________ test_summation_backward[cuda-shape0-None] ___________________\u001b[0m\n",
            "\n",
            "shape = (1, 1, 1), axes = None, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape, axes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SUMMATION_PARAMETERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_summation_backward\u001b[39;49;00m(shape, axes, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[1.7799296]]], dtype=float32)\n",
            "axes       = None\n",
            "device     = cuda()\n",
            "shape      = (1, 1, 1)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:190: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[1.7799296]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939bcd1f0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[1.7799296]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[1.7799296]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[1.7799296]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bcd3d0>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[1.7799296]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[1.7799296]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bcc0b0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (1, 1, 1), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939bceba0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (1, 1, 1)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m____________________ test_summation_backward[cuda-shape1-0] ____________________\u001b[0m\n",
            "\n",
            "shape = (5, 3), axes = 0, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape, axes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SUMMATION_PARAMETERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_summation_backward\u001b[39;49;00m(shape, axes, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[ 2.1140475 , -0.9384094 , -0.2541468 ],\n",
            "       [ 1.4692454 , -0.2594365 ,  1.2197713 ],\n",
            "       [-0.9723478 , -...47044],\n",
            "       [ 0.16003066,  1.2728198 ,  1.1000712 ],\n",
            "       [-0.74093074, -0.50888014,  0.408108  ]], dtype=float32)\n",
            "axes       = 0\n",
            "device     = cuda()\n",
            "shape      = (5, 3)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:190: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[ 2.1140475  -0.9384094  -0.2541468 ]\n",
            " [ 1.4692454  -0.2594365   1.2197713 ]\n",
            " [-0.9723478  -0.6831798   0.37447044]\n",
            " [ 0.16003066  1.2728198   1.1000712 ]\n",
            " [-0.74093074 -0.50888014  0.408108  ]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c793a0cb650>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[ 2.1140475  -0.9384094  -0.2541468 ]\n",
            " [ 1.4692454  -0.2594365   1.2197713 ]\n",
            " [-0.9723478  -0.6831798   0.37447044]\n",
            " [ 0.16003066  1.2728198   1.1000712 ]\n",
            " [-0.74093074 -0.50888014  0.408108  ]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[ 2.1140475  -0.9384094  -0.2541468 ]\n",
            " [ 1.4692454  -0.2594365   1.2197713 ]\n",
            " [-0.9723478  -0.6831798   0.37447044]\n",
            " [ 0.16003066  1.2728198   1.1000712 ]\n",
            " [-0.74093074 -0.50888014  0.408108  ]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[ 2.1140475  -0.9384094  -0.2541468 ]\n",
            " [ 1.4692454  -0.2594365   1.2197713 ]\n",
            " [-0.9723478  -0.6831798   0.37447044]\n",
            " [ 0.16003066  1.2728198   1.1000712 ]\n",
            " [-0.74093074 -0.50888014  0.408108  ]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c793a0ca420>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[ 2.1140475  -0.9384094  -0.2541468 ]\n",
            " [ 1.4692454  -0.2594365   1.2197713 ]\n",
            " [-0.9723478  -0.6831798   0.37447044]\n",
            " [ 0.16003066  1.2728198   1.1000712 ]\n",
            " [-0.74093074 -0.50888014  0.408108  ]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[ 2.1140475 , -0.9384094 , -0.2541468 ],\n",
            "       [ 1.4692454 , -0.2594365 ,  1.2197713 ],\n",
            "       [-0.9723478 , -...47044],\n",
            "       [ 0.16003066,  1.2728198 ,  1.1000712 ],\n",
            "       [-0.74093074, -0.50888014,  0.408108  ]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c793a0ca630>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (5, 3), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c793a0cb350>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (5, 3)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m____________________ test_summation_backward[cuda-shape2-1] ____________________\u001b[0m\n",
            "\n",
            "shape = (8, 3, 2), axes = 1, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape, axes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SUMMATION_PARAMETERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_summation_backward\u001b[39;49;00m(shape, axes, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[ 0.53634965, -2.1118162 ],\n",
            "        [-0.27859452,  1.0560247 ],\n",
            "        [-0.5948552 , -1.2022481 ]],\n",
            "\n",
            "       [...  [[-0.3477448 , -1.2089167 ],\n",
            "        [-0.03831517, -1.8689636 ],\n",
            "        [-0.53026855, -1.1635985 ]]], dtype=float32)\n",
            "axes       = 1\n",
            "device     = cuda()\n",
            "shape      = (8, 3, 2)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:190: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[ 0.53634965 -2.1118162 ]\n",
            "  [-0.27859452  1.0560247 ]\n",
            "  [-0.5948552  -1.2022481 ]]\n",
            "\n",
            " [[-1.1025962  -0.060151....1230552 ]]\n",
            "\n",
            " [[-0.3477448  -1.2089167 ]\n",
            "  [-0.03831517 -1.8689636 ]\n",
            "  [-0.53026855 -1.1635985 ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939a3eb10>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[ 0.53634965 -2.1118162 ]\n",
            "  [-0.27859452  1.0560247 ]\n",
            "  [-0.5948552  -1.2022481 ]]\n",
            "\n",
            " [[-1.1025962  -0.060151....1230552 ]]\n",
            "\n",
            " [[-0.3477448  -1.2089167 ]\n",
            "  [-0.03831517 -1.8689636 ]\n",
            "  [-0.53026855 -1.1635985 ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[ 0.53634965 -2.1118162 ]\n",
            "  [-0.27859452  1.0560247 ]\n",
            "  [-0.5948552  -1.2022481 ]]\n",
            "\n",
            " [[-1.1025962  -0.060151....1230552 ]]\n",
            "\n",
            " [[-0.3477448  -1.2089167 ]\n",
            "  [-0.03831517 -1.8689636 ]\n",
            "  [-0.53026855 -1.1635985 ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[ 0.53634965 -2.1118162 ]\n",
            "  [-0.27859452  1.0560247 ]\n",
            "  [-0.5948552  -1.2022481 ]]\n",
            "\n",
            " [[-1.1025962  -0.060151....1230552 ]]\n",
            "\n",
            " [[-0.3477448  -1.2089167 ]\n",
            "  [-0.03831517 -1.8689636 ]\n",
            "  [-0.53026855 -1.1635985 ]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a3fb30>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[ 0.53634965 -2.1118162 ]\n",
            "  [-0.27859452  1.0560247 ]\n",
            "  [-0.5948552  -1.2022481 ]]\n",
            "\n",
            " [[-1.1025962  -0.060151....1230552 ]]\n",
            "\n",
            " [[-0.3477448  -1.2089167 ]\n",
            "  [-0.03831517 -1.8689636 ]\n",
            "  [-0.53026855 -1.1635985 ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[ 0.53634965, -2.1118162 ],\n",
            "        [-0.27859452,  1.0560247 ],\n",
            "        [-0.5948552 , -1.2022481 ]],\n",
            "\n",
            "       [...  [[-0.3477448 , -1.2089167 ],\n",
            "        [-0.03831517, -1.8689636 ],\n",
            "        [-0.53026855, -1.1635985 ]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a3e7e0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (8, 3, 2), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939a3fb60>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (8, 3, 2)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m____________________ test_summation_backward[cuda-shape3-2] ____________________\u001b[0m\n",
            "\n",
            "shape = (8, 3, 2), axes = 2, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape, axes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SUMMATION_PARAMETERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_summation_backward\u001b[39;49;00m(shape, axes, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[-0.6694544 ,  0.99575835],\n",
            "        [-0.675602  , -1.1355246 ],\n",
            "        [-0.3549894 ,  0.46968827]],\n",
            "\n",
            "       [...  [[-1.3204774 ,  2.5963671 ],\n",
            "        [-1.2905574 , -0.2102861 ],\n",
            "        [-0.09622368, -0.613245  ]]], dtype=float32)\n",
            "axes       = 2\n",
            "device     = cuda()\n",
            "shape      = (8, 3, 2)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:190: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[-0.6694544   0.99575835]\n",
            "  [-0.675602   -1.1355246 ]\n",
            "  [-0.3549894   0.46968827]]\n",
            "\n",
            " [[ 0.4585768  -0.155006....4239696 ]]\n",
            "\n",
            " [[-1.3204774   2.5963671 ]\n",
            "  [-1.2905574  -0.2102861 ]\n",
            "  [-0.09622368 -0.613245  ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939bde600>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[-0.6694544   0.99575835]\n",
            "  [-0.675602   -1.1355246 ]\n",
            "  [-0.3549894   0.46968827]]\n",
            "\n",
            " [[ 0.4585768  -0.155006....4239696 ]]\n",
            "\n",
            " [[-1.3204774   2.5963671 ]\n",
            "  [-1.2905574  -0.2102861 ]\n",
            "  [-0.09622368 -0.613245  ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[-0.6694544   0.99575835]\n",
            "  [-0.675602   -1.1355246 ]\n",
            "  [-0.3549894   0.46968827]]\n",
            "\n",
            " [[ 0.4585768  -0.155006....4239696 ]]\n",
            "\n",
            " [[-1.3204774   2.5963671 ]\n",
            "  [-1.2905574  -0.2102861 ]\n",
            "  [-0.09622368 -0.613245  ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[-0.6694544   0.99575835]\n",
            "  [-0.675602   -1.1355246 ]\n",
            "  [-0.3549894   0.46968827]]\n",
            "\n",
            " [[ 0.4585768  -0.155006....4239696 ]]\n",
            "\n",
            " [[-1.3204774   2.5963671 ]\n",
            "  [-1.2905574  -0.2102861 ]\n",
            "  [-0.09622368 -0.613245  ]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bdf1d0>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[-0.6694544   0.99575835]\n",
            "  [-0.675602   -1.1355246 ]\n",
            "  [-0.3549894   0.46968827]]\n",
            "\n",
            " [[ 0.4585768  -0.155006....4239696 ]]\n",
            "\n",
            " [[-1.3204774   2.5963671 ]\n",
            "  [-1.2905574  -0.2102861 ]\n",
            "  [-0.09622368 -0.613245  ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[-0.6694544 ,  0.99575835],\n",
            "        [-0.675602  , -1.1355246 ],\n",
            "        [-0.3549894 ,  0.46968827]],\n",
            "\n",
            "       [...  [[-1.3204774 ,  2.5963671 ],\n",
            "        [-1.2905574 , -0.2102861 ],\n",
            "        [-0.09622368, -0.613245  ]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939bf4920>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (8, 3, 2), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939bf58b0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (8, 3, 2)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m___________________ test_broadcast_to[cuda-shape0-shape_to0] ___________________\u001b[0m\n",
            "\n",
            "shape = (1, 1, 1), shape_to = (3, 3, 3), device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape,shape_to\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BROADCAST_SHAPES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_broadcast_to\u001b[39;49;00m(shape, shape_to, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[0.45943186]]], dtype=float32)\n",
            "device     = cuda()\n",
            "shape      = (1, 1, 1)\n",
            "shape_to   = (3, 3, 3)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:200: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[0.45943186]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939b9b350>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[0.45943186]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[0.45943186]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[0.45943186]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939b9aea0>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[0.45943186]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[0.45943186]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939b9be90>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (1, 1, 1), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939b9b050>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (1, 1, 1)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m___________________ test_broadcast_to[cuda-shape1-shape_to1] ___________________\u001b[0m\n",
            "\n",
            "shape = (4, 1, 6), shape_to = (4, 3, 6), device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape,shape_to\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BROADCAST_SHAPES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_broadcast_to\u001b[39;49;00m(shape, shape_to, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[ 0.8649256 , -0.5685719 , -0.13818243,  0.02258228,\n",
            "          0.7159469 ,  1.4280046 ]],\n",
            "\n",
            "       [[ 0.0493846... ]],\n",
            "\n",
            "       [[-0.53128463,  1.3710403 , -0.17000628, -1.4833229 ,\n",
            "          0.02208569,  1.2701598 ]]], dtype=float32)\n",
            "device     = cuda()\n",
            "shape      = (4, 1, 6)\n",
            "shape_to   = (4, 3, 6)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:200: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[ 0.8649256  -0.5685719  -0.13818243  0.02258228  0.7159469\n",
            "    1.4280046 ]]\n",
            "\n",
            " [[ 0.04938466  0.27715296  0....   -0.6487425 ]]\n",
            "\n",
            " [[-0.53128463  1.3710403  -0.17000628 -1.4833229   0.02208569\n",
            "    1.2701598 ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939ac6090>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[ 0.8649256  -0.5685719  -0.13818243  0.02258228  0.7159469\n",
            "    1.4280046 ]]\n",
            "\n",
            " [[ 0.04938466  0.27715296  0....   -0.6487425 ]]\n",
            "\n",
            " [[-0.53128463  1.3710403  -0.17000628 -1.4833229   0.02208569\n",
            "    1.2701598 ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[ 0.8649256  -0.5685719  -0.13818243  0.02258228  0.7159469\n",
            "    1.4280046 ]]\n",
            "\n",
            " [[ 0.04938466  0.27715296  0....   -0.6487425 ]]\n",
            "\n",
            " [[-0.53128463  1.3710403  -0.17000628 -1.4833229   0.02208569\n",
            "    1.2701598 ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[ 0.8649256  -0.5685719  -0.13818243  0.02258228  0.7159469\n",
            "    1.4280046 ]]\n",
            "\n",
            " [[ 0.04938466  0.27715296  0....   -0.6487425 ]]\n",
            "\n",
            " [[-0.53128463  1.3710403  -0.17000628 -1.4833229   0.02208569\n",
            "    1.2701598 ]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939ac7890>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[ 0.8649256  -0.5685719  -0.13818243  0.02258228  0.7159469\n",
            "    1.4280046 ]]\n",
            "\n",
            " [[ 0.04938466  0.27715296  0....   -0.6487425 ]]\n",
            "\n",
            " [[-0.53128463  1.3710403  -0.17000628 -1.4833229   0.02208569\n",
            "    1.2701598 ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[ 0.8649256 , -0.5685719 , -0.13818243,  0.02258228,\n",
            "          0.7159469 ,  1.4280046 ]],\n",
            "\n",
            "       [[ 0.0493846... ]],\n",
            "\n",
            "       [[-0.53128463,  1.3710403 , -0.17000628, -1.4833229 ,\n",
            "          0.02208569,  1.2701598 ]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939ab7ce0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (4, 1, 6), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939ab7bf0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (4, 1, 6)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_____________________ test_reshape[cuda-shape0-shape_to0] ______________________\u001b[0m\n",
            "\n",
            "shape = (1, 1, 1), shape_to = (1,), device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape,shape_to\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, RESHAPE_SHAPES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_reshape\u001b[39;49;00m(shape, shape_to, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[0.24750309]]], dtype=float32)\n",
            "device     = cuda()\n",
            "shape      = (1, 1, 1)\n",
            "shape_to   = (1,)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:210: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[0.24750309]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939b9bec0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[0.24750309]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[0.24750309]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[0.24750309]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939b9b560>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[0.24750309]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[0.24750309]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939b9bce0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (1, 1, 1), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939b9b530>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (1, 1, 1)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_____________________ test_reshape[cuda-shape1-shape_to1] ______________________\u001b[0m\n",
            "\n",
            "shape = (4, 1, 6), shape_to = (6, 4, 1), device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape,shape_to\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, RESHAPE_SHAPES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_reshape\u001b[39;49;00m(shape, shape_to, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[ 1.7347882 ,  1.9780853 , -2.1093915 ,  0.0146967 ,\n",
            "          0.07289008,  0.33634785]],\n",
            "\n",
            "       [[ 1.129713 ... ]],\n",
            "\n",
            "       [[-0.55685735,  0.17516482, -0.59294105,  0.16579469,\n",
            "         -1.4521552 , -1.1660721 ]]], dtype=float32)\n",
            "device     = cuda()\n",
            "shape      = (4, 1, 6)\n",
            "shape_to   = (6, 4, 1)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:210: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[ 1.7347882   1.9780853  -2.1093915   0.0146967   0.07289008\n",
            "    0.33634785]]\n",
            "\n",
            " [[ 1.129713    0.01987992 -0...\n",
            "   -0.3165104 ]]\n",
            "\n",
            " [[-0.55685735  0.17516482 -0.59294105  0.16579469 -1.4521552\n",
            "   -1.1660721 ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939ab54c0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[ 1.7347882   1.9780853  -2.1093915   0.0146967   0.07289008\n",
            "    0.33634785]]\n",
            "\n",
            " [[ 1.129713    0.01987992 -0...\n",
            "   -0.3165104 ]]\n",
            "\n",
            " [[-0.55685735  0.17516482 -0.59294105  0.16579469 -1.4521552\n",
            "   -1.1660721 ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[ 1.7347882   1.9780853  -2.1093915   0.0146967   0.07289008\n",
            "    0.33634785]]\n",
            "\n",
            " [[ 1.129713    0.01987992 -0...\n",
            "   -0.3165104 ]]\n",
            "\n",
            " [[-0.55685735  0.17516482 -0.59294105  0.16579469 -1.4521552\n",
            "   -1.1660721 ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[ 1.7347882   1.9780853  -2.1093915   0.0146967   0.07289008\n",
            "    0.33634785]]\n",
            "\n",
            " [[ 1.129713    0.01987992 -0...\n",
            "   -0.3165104 ]]\n",
            "\n",
            " [[-0.55685735  0.17516482 -0.59294105  0.16579469 -1.4521552\n",
            "   -1.1660721 ]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939ab60c0>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[ 1.7347882   1.9780853  -2.1093915   0.0146967   0.07289008\n",
            "    0.33634785]]\n",
            "\n",
            " [[ 1.129713    0.01987992 -0...\n",
            "   -0.3165104 ]]\n",
            "\n",
            " [[-0.55685735  0.17516482 -0.59294105  0.16579469 -1.4521552\n",
            "   -1.1660721 ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[ 1.7347882 ,  1.9780853 , -2.1093915 ,  0.0146967 ,\n",
            "          0.07289008,  0.33634785]],\n",
            "\n",
            "       [[ 1.129713 ... ]],\n",
            "\n",
            "       [[-0.55685735,  0.17516482, -0.59294105,  0.16579469,\n",
            "         -1.4521552 , -1.1660721 ]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939ab5ee0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (4, 1, 6), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939ab6c90>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (4, 1, 6)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m______________________ test_transpose[cuda-axes0-shape0] _______________________\u001b[0m\n",
            "\n",
            "shape = (1, 1, 1), axes = (0, 1), device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, TRANSPOSE_SHAPES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, TRANSPOSE_AXES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_transpose\u001b[39;49;00m(shape, axes, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[0.9637891]]], dtype=float32)\n",
            "axes       = (0, 1)\n",
            "device     = cuda()\n",
            "shape      = (1, 1, 1)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:221: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[0.9637891]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939ab53d0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[0.9637891]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[0.9637891]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[0.9637891]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939ab7a40>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[0.9637891]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[0.9637891]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939ab6390>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (1, 1, 1), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939ab67b0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (1, 1, 1)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m______________________ test_transpose[cuda-axes0-shape1] _______________________\u001b[0m\n",
            "\n",
            "shape = (4, 5, 6), axes = (0, 1), device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, TRANSPOSE_SHAPES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, TRANSPOSE_AXES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_transpose\u001b[39;49;00m(shape, axes, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[ 0.24229313,  0.3038875 ,  1.0418386 , -0.30553612,\n",
            "          0.4815216 , -0.4495722 ],\n",
            "        [ 1.0149198 ,...036],\n",
            "        [-0.24230671,  0.40026274, -0.5793786 ,  0.18407841,\n",
            "          0.92437047,  0.4315171 ]]], dtype=float32)\n",
            "axes       = (0, 1)\n",
            "device     = cuda()\n",
            "shape      = (4, 5, 6)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:221: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[ 0.24229313  0.3038875   1.0418386  -0.30553612  0.4815216\n",
            "   -0.4495722 ]\n",
            "  [ 1.0149198   0.7344248  -1.13...6\n",
            "    0.62834036]\n",
            "  [-0.24230671  0.40026274 -0.5793786   0.18407841  0.92437047\n",
            "    0.4315171 ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939a0dcd0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[ 0.24229313  0.3038875   1.0418386  -0.30553612  0.4815216\n",
            "   -0.4495722 ]\n",
            "  [ 1.0149198   0.7344248  -1.13...6\n",
            "    0.62834036]\n",
            "  [-0.24230671  0.40026274 -0.5793786   0.18407841  0.92437047\n",
            "    0.4315171 ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[ 0.24229313  0.3038875   1.0418386  -0.30553612  0.4815216\n",
            "   -0.4495722 ]\n",
            "  [ 1.0149198   0.7344248  -1.13...6\n",
            "    0.62834036]\n",
            "  [-0.24230671  0.40026274 -0.5793786   0.18407841  0.92437047\n",
            "    0.4315171 ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[ 0.24229313  0.3038875   1.0418386  -0.30553612  0.4815216\n",
            "   -0.4495722 ]\n",
            "  [ 1.0149198   0.7344248  -1.13...6\n",
            "    0.62834036]\n",
            "  [-0.24230671  0.40026274 -0.5793786   0.18407841  0.92437047\n",
            "    0.4315171 ]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a0e1b0>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[ 0.24229313  0.3038875   1.0418386  -0.30553612  0.4815216\n",
            "   -0.4495722 ]\n",
            "  [ 1.0149198   0.7344248  -1.13...6\n",
            "    0.62834036]\n",
            "  [-0.24230671  0.40026274 -0.5793786   0.18407841  0.92437047\n",
            "    0.4315171 ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[ 0.24229313,  0.3038875 ,  1.0418386 , -0.30553612,\n",
            "          0.4815216 , -0.4495722 ],\n",
            "        [ 1.0149198 ,...036],\n",
            "        [-0.24230671,  0.40026274, -0.5793786 ,  0.18407841,\n",
            "          0.92437047,  0.4315171 ]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a0e120>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (4, 5, 6), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939a0e8d0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (4, 5, 6)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m______________________ test_transpose[cuda-axes1-shape0] _______________________\u001b[0m\n",
            "\n",
            "shape = (1, 1, 1), axes = (0, 2), device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, TRANSPOSE_SHAPES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, TRANSPOSE_AXES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_transpose\u001b[39;49;00m(shape, axes, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[-1.1008012]]], dtype=float32)\n",
            "axes       = (0, 2)\n",
            "device     = cuda()\n",
            "shape      = (1, 1, 1)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:221: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[-1.1008012]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939ab6120>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[-1.1008012]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[-1.1008012]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[-1.1008012]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939ab59a0>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[-1.1008012]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[-1.1008012]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939ab6690>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (1, 1, 1), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939ab5610>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (1, 1, 1)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m______________________ test_transpose[cuda-axes1-shape1] _______________________\u001b[0m\n",
            "\n",
            "shape = (4, 5, 6), axes = (0, 2), device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, TRANSPOSE_SHAPES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, TRANSPOSE_AXES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_transpose\u001b[39;49;00m(shape, axes, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[ 1.0299685 ,  0.3446224 ,  0.39228645,  0.07826652,\n",
            "         -0.86621696, -1.1352481 ],\n",
            "        [ 1.1580739 ,...68 ],\n",
            "        [ 0.09447403,  0.58481884, -0.23538569, -0.06364735,\n",
            "         -0.39236242, -1.6825415 ]]], dtype=float32)\n",
            "axes       = (0, 2)\n",
            "device     = cuda()\n",
            "shape      = (4, 5, 6)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:221: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[ 1.0299685   0.3446224   0.39228645  0.07826652 -0.86621696\n",
            "   -1.1352481 ]\n",
            "  [ 1.1580739   1.6779075   0.3...9\n",
            "    0.5314168 ]\n",
            "  [ 0.09447403  0.58481884 -0.23538569 -0.06364735 -0.39236242\n",
            "   -1.6825415 ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939a0df10>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[ 1.0299685   0.3446224   0.39228645  0.07826652 -0.86621696\n",
            "   -1.1352481 ]\n",
            "  [ 1.1580739   1.6779075   0.3...9\n",
            "    0.5314168 ]\n",
            "  [ 0.09447403  0.58481884 -0.23538569 -0.06364735 -0.39236242\n",
            "   -1.6825415 ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[ 1.0299685   0.3446224   0.39228645  0.07826652 -0.86621696\n",
            "   -1.1352481 ]\n",
            "  [ 1.1580739   1.6779075   0.3...9\n",
            "    0.5314168 ]\n",
            "  [ 0.09447403  0.58481884 -0.23538569 -0.06364735 -0.39236242\n",
            "   -1.6825415 ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[ 1.0299685   0.3446224   0.39228645  0.07826652 -0.86621696\n",
            "   -1.1352481 ]\n",
            "  [ 1.1580739   1.6779075   0.3...9\n",
            "    0.5314168 ]\n",
            "  [ 0.09447403  0.58481884 -0.23538569 -0.06364735 -0.39236242\n",
            "   -1.6825415 ]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a0e600>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[ 1.0299685   0.3446224   0.39228645  0.07826652 -0.86621696\n",
            "   -1.1352481 ]\n",
            "  [ 1.1580739   1.6779075   0.3...9\n",
            "    0.5314168 ]\n",
            "  [ 0.09447403  0.58481884 -0.23538569 -0.06364735 -0.39236242\n",
            "   -1.6825415 ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[ 1.0299685 ,  0.3446224 ,  0.39228645,  0.07826652,\n",
            "         -0.86621696, -1.1352481 ],\n",
            "        [ 1.1580739 ,...68 ],\n",
            "        [ 0.09447403,  0.58481884, -0.23538569, -0.06364735,\n",
            "         -0.39236242, -1.6825415 ]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a0e4b0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (4, 5, 6), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939a0eff0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (4, 5, 6)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_______________________ test_transpose[cuda-None-shape0] _______________________\u001b[0m\n",
            "\n",
            "shape = (1, 1, 1), axes = None, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, TRANSPOSE_SHAPES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, TRANSPOSE_AXES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_transpose\u001b[39;49;00m(shape, axes, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[1.6210349]]], dtype=float32)\n",
            "axes       = None\n",
            "device     = cuda()\n",
            "shape      = (1, 1, 1)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:221: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[1.6210349]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939a0d190>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[1.6210349]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[1.6210349]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[1.6210349]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a0e540>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[1.6210349]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[1.6210349]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a0c950>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (1, 1, 1), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939a0cb00>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (1, 1, 1)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_______________________ test_transpose[cuda-None-shape1] _______________________\u001b[0m\n",
            "\n",
            "shape = (4, 5, 6), axes = None, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, TRANSPOSE_SHAPES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, TRANSPOSE_AXES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_transpose\u001b[39;49;00m(shape, axes, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[-0.2345406 , -0.8517744 , -0.4243318 , -1.5320604 ,\n",
            "         -0.00643594,  1.0798386 ],\n",
            "        [ 0.27664822,...47 ],\n",
            "        [ 1.1980885 ,  0.61848694, -1.5373163 , -0.06471775,\n",
            "          1.9226277 ,  2.113707  ]]], dtype=float32)\n",
            "axes       = None\n",
            "device     = cuda()\n",
            "shape      = (4, 5, 6)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:221: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[-0.2345406  -0.8517744  -0.4243318  -1.5320604  -0.00643594\n",
            "    1.0798386 ]\n",
            "  [ 0.27664822 -0.11807661 -1.5...06\n",
            "   -1.3568047 ]\n",
            "  [ 1.1980885   0.61848694 -1.5373163  -0.06471775  1.9226277\n",
            "    2.113707  ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939a0fef0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[-0.2345406  -0.8517744  -0.4243318  -1.5320604  -0.00643594\n",
            "    1.0798386 ]\n",
            "  [ 0.27664822 -0.11807661 -1.5...06\n",
            "   -1.3568047 ]\n",
            "  [ 1.1980885   0.61848694 -1.5373163  -0.06471775  1.9226277\n",
            "    2.113707  ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[-0.2345406  -0.8517744  -0.4243318  -1.5320604  -0.00643594\n",
            "    1.0798386 ]\n",
            "  [ 0.27664822 -0.11807661 -1.5...06\n",
            "   -1.3568047 ]\n",
            "  [ 1.1980885   0.61848694 -1.5373163  -0.06471775  1.9226277\n",
            "    2.113707  ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[-0.2345406  -0.8517744  -0.4243318  -1.5320604  -0.00643594\n",
            "    1.0798386 ]\n",
            "  [ 0.27664822 -0.11807661 -1.5...06\n",
            "   -1.3568047 ]\n",
            "  [ 1.1980885   0.61848694 -1.5373163  -0.06471775  1.9226277\n",
            "    2.113707  ]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a0cd40>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[-0.2345406  -0.8517744  -0.4243318  -1.5320604  -0.00643594\n",
            "    1.0798386 ]\n",
            "  [ 0.27664822 -0.11807661 -1.5...06\n",
            "   -1.3568047 ]\n",
            "  [ 1.1980885   0.61848694 -1.5373163  -0.06471775  1.9226277\n",
            "    2.113707  ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[-0.2345406 , -0.8517744 , -0.4243318 , -1.5320604 ,\n",
            "         -0.00643594,  1.0798386 ],\n",
            "        [ 0.27664822,...47 ],\n",
            "        [ 1.1980885 ,  0.61848694, -1.5373163 , -0.06471775,\n",
            "          1.9226277 ,  2.113707  ]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a0dc70>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (4, 5, 6), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939a0ef00>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (4, 5, 6)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_______________________ test_logsumexp[cuda-shape0-None] _______________________\u001b[0m\n",
            "\n",
            "shape = (1, 1, 1), axes = None, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape, axes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SUMMATION_PARAMETERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_logsumexp\u001b[39;49;00m(shape, axes, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[3.3938375]]], dtype=float32)\n",
            "axes       = None\n",
            "device     = cuda()\n",
            "shape      = (1, 1, 1)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:233: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[3.3938375]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939ab5490>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[3.3938375]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[3.3938375]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[3.3938375]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939ab52b0>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[3.3938375]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[3.3938375]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a0f680>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (1, 1, 1), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939a0c5c0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (1, 1, 1)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m________________________ test_logsumexp[cuda-shape1-0] _________________________\u001b[0m\n",
            "\n",
            "shape = (5, 3), axes = 0, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape, axes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SUMMATION_PARAMETERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_logsumexp\u001b[39;49;00m(shape, axes, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[-1.1693304 , -1.9598371 ,  0.03200281],\n",
            "       [-0.5286519 ,  0.7414541 , -0.63044536],\n",
            "       [-0.8193606 ,  ...83168],\n",
            "       [ 0.92844015, -0.28567657,  0.49430585],\n",
            "       [ 0.8827713 ,  0.69667625, -0.7692884 ]], dtype=float32)\n",
            "axes       = 0\n",
            "device     = cuda()\n",
            "shape      = (5, 3)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:233: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[-1.1693304  -1.9598371   0.03200281]\n",
            " [-0.5286519   0.7414541  -0.63044536]\n",
            " [-0.8193606   0.20399947  0.11983168]\n",
            " [ 0.92844015 -0.28567657  0.49430585]\n",
            " [ 0.8827713   0.69667625 -0.7692884 ]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939a0ea50>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[-1.1693304  -1.9598371   0.03200281]\n",
            " [-0.5286519   0.7414541  -0.63044536]\n",
            " [-0.8193606   0.20399947  0.11983168]\n",
            " [ 0.92844015 -0.28567657  0.49430585]\n",
            " [ 0.8827713   0.69667625 -0.7692884 ]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[-1.1693304  -1.9598371   0.03200281]\n",
            " [-0.5286519   0.7414541  -0.63044536]\n",
            " [-0.8193606   0.20399947  0.11983168]\n",
            " [ 0.92844015 -0.28567657  0.49430585]\n",
            " [ 0.8827713   0.69667625 -0.7692884 ]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[-1.1693304  -1.9598371   0.03200281]\n",
            " [-0.5286519   0.7414541  -0.63044536]\n",
            " [-0.8193606   0.20399947  0.11983168]\n",
            " [ 0.92844015 -0.28567657  0.49430585]\n",
            " [ 0.8827713   0.69667625 -0.7692884 ]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a0f7a0>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[-1.1693304  -1.9598371   0.03200281]\n",
            " [-0.5286519   0.7414541  -0.63044536]\n",
            " [-0.8193606   0.20399947  0.11983168]\n",
            " [ 0.92844015 -0.28567657  0.49430585]\n",
            " [ 0.8827713   0.69667625 -0.7692884 ]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[-1.1693304 , -1.9598371 ,  0.03200281],\n",
            "       [-0.5286519 ,  0.7414541 , -0.63044536],\n",
            "       [-0.8193606 ,  ...83168],\n",
            "       [ 0.92844015, -0.28567657,  0.49430585],\n",
            "       [ 0.8827713 ,  0.69667625, -0.7692884 ]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939a0e600>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (5, 3), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939a0df40>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (5, 3)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m________________________ test_logsumexp[cuda-shape2-1] _________________________\u001b[0m\n",
            "\n",
            "shape = (8, 3, 2), axes = 1, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape, axes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SUMMATION_PARAMETERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_logsumexp\u001b[39;49;00m(shape, axes, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[-0.61970425,  0.49045902],\n",
            "        [-0.74332494, -1.2040609 ],\n",
            "        [-0.543691  , -0.10043301]],\n",
            "\n",
            "       [...  [[ 0.095046  , -0.2642157 ],\n",
            "        [-0.32524756,  0.70726275],\n",
            "        [-0.6719159 , -1.8796829 ]]], dtype=float32)\n",
            "axes       = 1\n",
            "device     = cuda()\n",
            "shape      = (8, 3, 2)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:233: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[-0.61970425  0.49045902]\n",
            "  [-0.74332494 -1.2040609 ]\n",
            "  [-0.543691   -0.10043301]]\n",
            "\n",
            " [[ 1.335728    0.161542....1180692 ]]\n",
            "\n",
            " [[ 0.095046   -0.2642157 ]\n",
            "  [-0.32524756  0.70726275]\n",
            "  [-0.6719159  -1.8796829 ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939af2a50>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[-0.61970425  0.49045902]\n",
            "  [-0.74332494 -1.2040609 ]\n",
            "  [-0.543691   -0.10043301]]\n",
            "\n",
            " [[ 1.335728    0.161542....1180692 ]]\n",
            "\n",
            " [[ 0.095046   -0.2642157 ]\n",
            "  [-0.32524756  0.70726275]\n",
            "  [-0.6719159  -1.8796829 ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[-0.61970425  0.49045902]\n",
            "  [-0.74332494 -1.2040609 ]\n",
            "  [-0.543691   -0.10043301]]\n",
            "\n",
            " [[ 1.335728    0.161542....1180692 ]]\n",
            "\n",
            " [[ 0.095046   -0.2642157 ]\n",
            "  [-0.32524756  0.70726275]\n",
            "  [-0.6719159  -1.8796829 ]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[-0.61970425  0.49045902]\n",
            "  [-0.74332494 -1.2040609 ]\n",
            "  [-0.543691   -0.10043301]]\n",
            "\n",
            " [[ 1.335728    0.161542....1180692 ]]\n",
            "\n",
            " [[ 0.095046   -0.2642157 ]\n",
            "  [-0.32524756  0.70726275]\n",
            "  [-0.6719159  -1.8796829 ]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939af3aa0>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[-0.61970425  0.49045902]\n",
            "  [-0.74332494 -1.2040609 ]\n",
            "  [-0.543691   -0.10043301]]\n",
            "\n",
            " [[ 1.335728    0.161542....1180692 ]]\n",
            "\n",
            " [[ 0.095046   -0.2642157 ]\n",
            "  [-0.32524756  0.70726275]\n",
            "  [-0.6719159  -1.8796829 ]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[-0.61970425,  0.49045902],\n",
            "        [-0.74332494, -1.2040609 ],\n",
            "        [-0.543691  , -0.10043301]],\n",
            "\n",
            "       [...  [[ 0.095046  , -0.2642157 ],\n",
            "        [-0.32524756,  0.70726275],\n",
            "        [-0.6719159 , -1.8796829 ]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939af0560>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (8, 3, 2), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939af1130>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (8, 3, 2)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m________________________ test_logsumexp[cuda-shape3-2] _________________________\u001b[0m\n",
            "\n",
            "shape = (8, 3, 2), axes = 2, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape, axes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SUMMATION_PARAMETERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_logsumexp\u001b[39;49;00m(shape, axes, device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[ 0.6002251 ,  0.4974558 ],\n",
            "        [-0.5366705 , -0.53319454],\n",
            "        [-0.18542138, -0.64573014]],\n",
            "\n",
            "       [...  [[-0.7940965 ,  1.0068549 ],\n",
            "        [ 1.13256   ,  0.5479147 ],\n",
            "        [-1.2947313 , -0.33982575]]], dtype=float32)\n",
            "axes       = 2\n",
            "device     = cuda()\n",
            "shape      = (8, 3, 2)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:233: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = NDArray([[[ 0.6002251   0.4974558 ]\n",
            "  [-0.5366705  -0.53319454]\n",
            "  [-0.18542138 -0.64573014]]\n",
            "\n",
            " [[-0.18989763  0.064258....1591896 ]]\n",
            "\n",
            " [[-0.7940965   1.0068549 ]\n",
            "  [ 1.13256     0.5479147 ]\n",
            "  [-1.2947313  -0.33982575]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c7939af3050>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = NDArray([[[ 0.6002251   0.4974558 ]\n",
            "  [-0.5366705  -0.53319454]\n",
            "  [-0.18542138 -0.64573014]]\n",
            "\n",
            " [[-0.18989763  0.064258....1591896 ]]\n",
            "\n",
            " [[-0.7940965   1.0068549 ]\n",
            "  [ 1.13256     0.5479147 ]\n",
            "  [-1.2947313  -0.33982575]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = NDArray([[[ 0.6002251   0.4974558 ]\n",
            "  [-0.5366705  -0.53319454]\n",
            "  [-0.18542138 -0.64573014]]\n",
            "\n",
            " [[-0.18989763  0.064258....1591896 ]]\n",
            "\n",
            " [[-0.7940965   1.0068549 ]\n",
            "  [ 1.13256     0.5479147 ]\n",
            "  [-1.2947313  -0.33982575]]], device=cpu_numpy())\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = NDArray([[[ 0.6002251   0.4974558 ]\n",
            "  [-0.5366705  -0.53319454]\n",
            "  [-0.18542138 -0.64573014]]\n",
            "\n",
            " [[-0.18989763  0.064258....1591896 ]]\n",
            "\n",
            " [[-0.7940965   1.0068549 ]\n",
            "  [ 1.13256     0.5479147 ]\n",
            "  [-1.2947313  -0.33982575]]], device=cpu_numpy())\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939af2540>\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        self       = NDArray([[[ 0.6002251   0.4974558 ]\n",
            "  [-0.5366705  -0.53319454]\n",
            "  [-0.18542138 -0.64573014]]\n",
            "\n",
            " [[-0.18989763  0.064258....1591896 ]]\n",
            "\n",
            " [[-0.7940965   1.0068549 ]\n",
            "  [ 1.13256     0.5479147 ]\n",
            "  [-1.2947313  -0.33982575]]], device=cpu_numpy())\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[ 0.6002251 ,  0.4974558 ],\n",
            "        [-0.5366705 , -0.53319454],\n",
            "        [-0.18542138, -0.64573014]],\n",
            "\n",
            "       [...  [[-0.7940965 ,  1.0068549 ],\n",
            "        [ 1.13256   ,  0.5479147 ],\n",
            "        [-1.2947313 , -0.33982575]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c7939af1220>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (8, 3, 2), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c7939af3380>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (8, 3, 2)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_ewise_fn[cuda-shape0-divide]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_ewise_fn[cuda-shape0-subtract]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_ewise_fn[cuda-shape1-divide]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_ewise_fn[cuda-shape1-subtract]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_scalar_fn[cuda-shape0-divide]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_scalar_fn[cuda-shape0-subtract]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_scalar_fn[cuda-shape1-divide]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_scalar_fn[cuda-shape1-subtract]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_matmul[cuda-16-16-16]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_matmul[cuda-8-8-8]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_matmul[cuda-1-2-3]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_matmul[cuda-3-4-5]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_matmul[cuda-5-4-3]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_matmul[cuda-16-16-32]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_matmul[cuda-64-64-64]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_matmul[cuda-72-72-72]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_matmul[cuda-72-73-74]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_matmul[cuda-74-73-72]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_matmul[cuda-128-128-128]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_power[cuda-shape0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_power[cuda-shape1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_log[cuda-shape0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_log[cuda-shape1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_exp[cuda-shape0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_exp[cuda-shape1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_relu[cuda-shape0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_relu[cuda-shape1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_tanh[cuda-shape0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_tanh[cuda-shape1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_tanh_backward[cuda-shape0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_tanh_backward[cuda-shape1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_stack[cuda-shape0-0-1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_stack[cuda-shape1-0-2]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_stack[cuda-shape2-2-5]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_stack_backward[cpu-shape0-0-1]\u001b[0m - AssertionError\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_stack_backward[cpu-shape1-0-2]\u001b[0m - AssertionError\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_stack_backward[cpu-shape2-2-5]\u001b[0m - AssertionError\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_stack_backward[cuda-shape0-0-1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_stack_backward[cuda-shape1-0-2]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_stack_backward[cuda-shape2-2-5]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_summation[cuda-shape0-None]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_summation[cuda-shape1-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_summation[cuda-shape2-1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_summation[cuda-shape3-2]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_summation_backward[cuda-shape0-None]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_summation_backward[cuda-shape1-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_summation_backward[cuda-shape2-1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_summation_backward[cuda-shape3-2]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_broadcast_to[cuda-shape0-shape_to0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_broadcast_to[cuda-shape1-shape_to1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_reshape[cuda-shape0-shape_to0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_reshape[cuda-shape1-shape_to1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_transpose[cuda-axes0-shape0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_transpose[cuda-axes0-shape1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_transpose[cuda-axes1-shape0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_transpose[cuda-axes1-shape1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_transpose[cuda-None-shape0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_transpose[cuda-None-shape1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_logsumexp[cuda-shape0-None]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_logsumexp[cuda-shape1-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_logsumexp[cuda-shape2-1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1mtest_logsumexp[cuda-shape3-2]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31m=============== \u001b[31m\u001b[1m62 failed\u001b[0m, \u001b[32m56 passed\u001b[0m, \u001b[33m1685 deselected\u001b[0m\u001b[31m in 12.25s\u001b[0m\u001b[31m ================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k  \"nd_backend\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UgiL1n-Wm0Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aeNjv4D5m0Ut"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVaWc61z66oN",
        "outputId": "4fb511cc-91c8-459f-c02b-0a4369917da1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submit\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: langsmith-0.4.42, typeguard-4.4.4, anyio-4.11.0\n",
            "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
            "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\n",
            "\n",
            "tests/hw4/test_nd_backend.py \n",
            "Submitting new_nd_backend...\n",
            "Grader test 1 passed\n",
            "Grader test 2 passed\n",
            "\u001b[31mF\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m____________________________ submit_new_nd_backend _____________________________\u001b[0m\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92msubmit_new_nd_backend\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "        devices = [ndl.cpu(), ndl.cuda()] \u001b[94mif\u001b[39;49;00m ndl.cuda().enabled() \u001b[94melse\u001b[39;49;00m [ndl.cpu()]\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m#devices = [ndl.cpu(), ndl.cuda()]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m ndl.cuda().enabled():\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[96mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mYou need a GPU to run some of these tests.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# ewise fn\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m (device, shape, fn_name) \u001b[95min\u001b[39;49;00m itertools.product(devices, TEST_GENERAL_SHAPES, EWISE_OP_NAMES):\u001b[90m\u001b[39;49;00m\n",
            "            _A = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "            _B = np.random.randn(*shape).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">           A = ndl.Tensor(nd.array(_A), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_nd_backend.py\u001b[0m:278: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:727: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:115: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m._init(other.to(device) + \u001b[94m0.0\u001b[39;49;00m)  \u001b[90m# this creates a copy\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:209: in to\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(\u001b[96mself\u001b[39;49;00m.numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 1, 2), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_nd_backend.py::\u001b[1msubmit_new_nd_backend\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[31m in 4.02s\u001b[0m\u001b[31m ========================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"new_nd_backend\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k4w22Mm66oN"
      },
      "source": [
        "## Part 2: CIFAR-10 dataset [10 points]\n",
        "\n",
        "Next, you will write support for the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) image classification dataset, which consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. There are 50k training images and 10k test images.\n",
        "\n",
        "Start by implementing the `__init__` function in the `CIFAR10Dataset` class in `python/needle/data/datasets/cifar10_dataset.py`. You can read in the link above how to properly read the CIFAR-10 dataset files you downloaded at the beginning of the homework. Also fill in `__getitem__` and `__len__`. Note that the return shape of the data from `__getitem__` should be in order (3, 32, 32).\n",
        "\n",
        "Copy `python/needle/data/data_transforms.py` and `python/needle/data/data_basic.py` from previous homeworks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEtoz7Su66oN",
        "outputId": "1c0d0da0-3ceb-4831-8f3b-354a84028e43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: langsmith-0.4.42, typeguard-4.4.4, anyio-4.11.0\n",
            "collected 1803 items / 1793 deselected / 10 selected                           \u001b[0m\n",
            "\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_dataset[True] \u001b[32mPASSED\u001b[0m\u001b[32m      [ 10%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_dataset[False] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 20%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cpu-True-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cpu-True-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cpu-False-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cpu-False-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cuda-True-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cuda-True-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cuda-False-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
            "tests/hw4/test_cifar_ptb_data.py::test_cifar10_loader[cuda-False-15] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m===================== \u001b[32m\u001b[1m10 passed\u001b[0m, \u001b[33m1793 deselected\u001b[0m\u001b[32m in 15.53s\u001b[0m\u001b[32m =====================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"test_cifar10\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3LpjCCO66oN",
        "outputId": "52f06384-cb3d-4fc5-c928-2458b23b408d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submit\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: langsmith-0.4.42, typeguard-4.4.4, anyio-4.11.0\n",
            "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
            "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\n",
            "\n",
            "tests/hw4/test_cifar_ptb_data.py \n",
            "Submitting cifar10...\n",
            "Grader test 1 passed\n",
            "Grader test 2 passed\n",
            "Grader test 3 passed\n",
            "Grader test 4 passed\n",
            "Grader test 5 passed\n",
            "Grader test 6 passed\n",
            "Grader test 7 passed\n",
            "Grader test 8 passed\n",
            "Grader test 9 passed\n",
            "Grader test 10 passed\n",
            "Grader test 11 passed\n",
            "Grader test 12 passed\n",
            "Grader test 13 passed\n",
            "Grader test 14 passed\n",
            "Grader test 15 passed\n",
            "Grader test 16 passed\n",
            "Grader test 17 passed\n",
            "Grader test 18 passed\n",
            "\u001b[32m.\u001b[0m\n",
            "\n",
            "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[32m in 9.23s\u001b[0m\u001b[32m ========================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"cifar10\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "Y3A0_UHF66oO"
      },
      "source": [
        "## Part 3: Convolutional neural network [40 points]\n",
        "\n",
        "Here's an outline of what you will do in this task.\n",
        "\n",
        "In `python/needle/backend_ndarray/ndarray.py`, implement:\n",
        "- `flip`\n",
        "- `pad`\n",
        "\n",
        "In `python/needle/ops/ops_mathematic.py`, implement (forward and backward):\n",
        "- `Flip`\n",
        "- `Dilate`\n",
        "- `UnDilate`\n",
        "- `Conv`\n",
        "\n",
        "In `python/needle/nn/nn_conv.py`, implement:\n",
        "- `Conv`\n",
        "\n",
        "In `apps/models.py`, fill in the `ResNet9` class.  \n",
        "\n",
        "In `apps/simple_ml.py`, fill in:\n",
        "- `epoch_general_cifar10`,\n",
        "- `train_cifar10`\n",
        "- `evaluate_cifar10`\n",
        "\n",
        "We have provided a `BatchNorm2d` implementation in `python/needle/nn/nn_basic.py` for you as a wrapper around your previous `BatchNorm1d` implementation.\n",
        "\n",
        "**Note**: Remember to copy the solution of `nn_basic.py` from previous homework, make sure to not overwrite the `BatchNorm2d` module."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_NNAOVH66oO"
      },
      "source": [
        "### Padding ndarrays\n",
        "\n",
        "Convolution as typically implemented in deep learning libraries cuts down the size of inputs;\n",
        "e.g., a (1, 32, 32, 3) image convolved with a 3x3 filter would give a (1, 30, 30, c) output.\n",
        "A way around this is to pad the input ndarray before performing convolution, e.g., pad with zeros to get a (1, 34, 34, 3) ndarray so that the result is (1, 32, 32, 3).\n",
        "\n",
        "Padding is also required for the backward pass of convolution.\n",
        "\n",
        "You should implement `pad` in `ndarray.py` to closely reflect the behavior of `np.pad`.\n",
        "That is, `pad` should take a tuple of 2-tuples with length equal to the number of dimensions of the array,\n",
        "where each element in the 2-tuple corresponds to \"left padding\" and \"right padding\", respectively.\n",
        "\n",
        "For example, if `A` is a (10, 32, 32, 8) ndarray (think NHWC), then `A.pad( (0, 0), (2, 2), (2, 2), (0, 0) )` would be a (10, 36, 36, 8) ndarray where the \"spatial\" dimension has been padded by two zeros on all sides."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6wm8auR66oO",
        "outputId": "b9e55c87-4fb2-4625-e6d1-1fad31f62d3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: langsmith-0.4.42, typeguard-4.4.4, anyio-4.11.0\n",
            "collected 1803 items / 1801 deselected / 2 selected                            \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py::test_pad_forward[params0-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_pad_forward[params1-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m====================== \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m1801 deselected\u001b[0m\u001b[32m in 3.19s\u001b[0m\u001b[32m ======================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"pad_forward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK8ZH7JP66oO"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RuQwXF_66oO"
      },
      "source": [
        "### Flipping ndarrays & FlipOp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "CPKupcBR66oO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import ctypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEdo5eMv66oO"
      },
      "source": [
        "Some utility code for a demonstration below which you can probably ignore. It might be instructive to check out the `offset` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "n1XA3cPp66oO"
      },
      "outputs": [],
      "source": [
        "# reads off the underlying data array in order (i.e., offset 0, offset 1, ..., offset n)\n",
        "# i.e., ignoring strides\n",
        "def raw_data(X):\n",
        "    X = np.array(X) # copy, thus compact X\n",
        "    return np.frombuffer(ctypes.string_at(X.ctypes.data, X.nbytes), dtype=X.dtype, count=X.size)\n",
        "\n",
        "# Xold and Xnew should reference the same underlying data\n",
        "def offset(Xold, Xnew):\n",
        "    assert Xold.itemsize == Xnew.itemsize\n",
        "    # compare addresses to the beginning of the arrays\n",
        "    return (Xnew.ctypes.data - Xold.ctypes.data)//Xnew.itemsize\n",
        "\n",
        "def strides(X):\n",
        "    return ', '.join([str(x//X.itemsize) for x in X.strides])\n",
        "\n",
        "def format_array(X, shape):\n",
        "    assert len(shape) == 3, \"I only made this formatting work for ndims = 3\"\n",
        "    def chunks(l, n):\n",
        "        n = max(1, n)\n",
        "        return (l[i:i+n] for i in range(0, len(l), n))\n",
        "    a = [str(x) if x >= 10 else ' ' + str(x) for x in X]\n",
        "    a = ['(' + ' '.join(y) + ')' for y in [x for x in chunks(a, shape[-1])]]\n",
        "    a = ['|' + ' '.join(y) + '|' for y in [x for x in chunks(a, shape[-2])]]\n",
        "    return '  '.join(a)\n",
        "\n",
        "def inspect_array(X, *, is_a_copy_of):\n",
        "    # compacts X, then reads it off in order\n",
        "    print('Data: %s' % format_array(raw_data(X), X.shape))\n",
        "    # compares address of X to copy_of, thus finding X's offset\n",
        "    print('Offset: %s' % offset(is_a_copy_of, X))\n",
        "    print('Strides: %s' % strides(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "1rfAhPDj66oO"
      },
      "source": [
        "In order to implement the backwards pass of 2D convolution, we will (probably) need a function which _flips_\n",
        "axes of ndarrays. We say \"probably\" because you could probably cleverly implement your convolution forward\n",
        "function to avoid this. However, we think it is easiest to think about this if you have the ability to \"flip\" the kernel along its vertical and horizontal dimensions.\n",
        "\n",
        "We will try to build up your intuition for the \"flip\" operation below in order to help you figure out how to implement it in `ndarray.py`. To do that, we explore numpy's `np.flip` function below. One thing to note is that\n",
        "`flip` is typically implemented by using negative strides and changing the _offset_ of the underlying array.\n",
        "\n",
        "For example, flipping an array on _all_ of its axes is equivalent to reversing the array. In this case, you can imagine that we would want all the strides to be negative, and the offset to be the length of the array (to start at the end of the array and \"stride\" backwards).\n",
        "\n",
        "Since we did not explicitly support negative strides in our implementation for the last homework, we will merely call `NDArray.make` with them to make our \"flipped\" array and then immediately call `.compact()`. Other than changing unsigned ints to signed ints in a few places, we suspect your existing `compact` function should not have to change at all to accomodate negative strides. In the .cc and .cu files we distributed, we have already changed the function signatures to reflect this.\n",
        "\n",
        "Alternatively, you could simply implement `flip` in the CPU backend by copying memory, which you _may_ find more intuitive. We suggest following our mini tutorial below to keep your implementation Python-focused, since we believe it is involves approximately the same amount of effort to implement it slightly more naively in C."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0OS7va266oO"
      },
      "source": [
        "Use this array as reference for the other examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5KWU1k266oO",
        "outputId": "7f69fb6d-093e-410f-cab7-7a1f81c2815f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: |( 1  2  3  4) ( 5  6  7  8)|  |( 9 10 11 12) (13 14 15 16)|  |(17 18 19 20) (21 22 23 24)|\n",
            "Offset: 0\n",
            "Strides: 8, 4, 1\n"
          ]
        }
      ],
      "source": [
        "A = np.arange(1, 25).reshape(3, 2, 4)\n",
        "inspect_array(A, is_a_copy_of=A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alyAYGge66oO"
      },
      "source": [
        "We have put brackets around each axis of the array. Notice that for this array, the offset is 0 and the strides are all positive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0LMNK9Q66oO"
      },
      "source": [
        "----------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHrMIl8u66oO"
      },
      "source": [
        "See what happens when you flip the array along the last axis below.\n",
        "Note that the `inspect_array` function compacts the array after flipping it so you can see the\n",
        "\"logical\" order of the data, and the offset is calculated by comparing the address of the **non**-compacted\n",
        "flipped array with that of `is_copy_of`, i.e., the array `A` we looked at above.\n",
        "\n",
        "That is, we are looking at how numpy calculates the strides and offset for flipped arrays in order\n",
        "to copy this behavior in our own implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY0bayVa66oP",
        "outputId": "e80933da-f897-48aa-aa4d-0f126d87748f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: |( 4  3  2  1) ( 8  7  6  5)|  |(12 11 10  9) (16 15 14 13)|  |(20 19 18 17) (24 23 22 21)|\n",
            "Offset: 3\n",
            "Strides: 8, 4, -1\n"
          ]
        }
      ],
      "source": [
        "inspect_array(np.flip(A, (2,)), is_a_copy_of=A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANkwAulp66oP"
      },
      "source": [
        "So flipping the last axis reverses the order of the elements within each 4-dimensional \"cell\", as you can see above. The stride corresponding to the axis we flipped has been negated. And the offset is 3 -- this makes sense, e.g., because we want the new \"first\" element of the array to be 4, which was at index 3 in `A`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZpDjdqW66oP",
        "outputId": "d974ae91-e503-45bb-daf7-826959d4c4af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: |( 5  6  7  8) ( 1  2  3  4)|  |(13 14 15 16) ( 9 10 11 12)|  |(21 22 23 24) (17 18 19 20)|\n",
            "Offset: 4\n",
            "Strides: 8, -4, 1\n"
          ]
        }
      ],
      "source": [
        "inspect_array(np.flip(A, (1,)), is_a_copy_of=A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0CPJHEx66oP"
      },
      "source": [
        "Again for the middle axis: we negate the middle stride, and the offset is 4, which seems reasonable since we now want the first element to be 5, which was at index 4 in the original array `A`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjQRcE4266oP",
        "outputId": "acdc7f1a-d94f-4a47-e81e-f2f84b358fbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: |(17 18 19 20) (21 22 23 24)|  |( 9 10 11 12) (13 14 15 16)|  |( 1  2  3  4) ( 5  6  7  8)|\n",
            "Offset: 16\n",
            "Strides: -8, 4, 1\n"
          ]
        }
      ],
      "source": [
        "inspect_array(np.flip(A, (0,)), is_a_copy_of=A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ_5DD4v66oP"
      },
      "source": [
        "Try to infer the more general algorithm for computing the offset given the axis to flip."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo-6pVqI66oP"
      },
      "source": [
        "----------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6u85_O366oP"
      },
      "source": [
        "Observe what happens when we flip _all_ axes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMh9IPV-66oP",
        "outputId": "51b1e4f2-46ed-4fe5-bb48-45172d228863"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: |(24 23 22 21) (20 19 18 17)|  |(16 15 14 13) (12 11 10  9)|  |( 8  7  6  5) ( 4  3  2  1)|\n",
            "Offset: 23\n",
            "Strides: -8, -4, -1\n"
          ]
        }
      ],
      "source": [
        "inspect_array(np.flip(A, (0, 1, 2)), is_a_copy_of=A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z90FZ9Qt66oP"
      },
      "source": [
        "As mentioned earlier, the offset is then sufficient to point to the last element of the array, and this is just the \"reverse order\" version of `A`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgeNsRoo66oP"
      },
      "source": [
        "When we flip just axes 1 and 0..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az0--_GJ66oV",
        "outputId": "807a32f1-a892-4faa-a6e6-a087ac4d010c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: |(21 22 23 24) (17 18 19 20)|  |(13 14 15 16) ( 9 10 11 12)|  |( 5  6  7  8) ( 1  2  3  4)|\n",
            "Offset: 20\n",
            "Strides: -8, -4, 1\n"
          ]
        }
      ],
      "source": [
        "inspect_array(np.flip(A, (0, 1)), is_a_copy_of=A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhBTaGMB66oV"
      },
      "source": [
        "The offset is 20. Looking back on our previous offset computations, do you notice something?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y--EBSOl66oV"
      },
      "source": [
        "-------------------\n",
        "\n",
        "With this exploration of numpy's ndarray flipping functionality, which uses negative strides and a custom offset,\n",
        "try to implement `flip` in `ndarray.py`. You also must implement \"flip\" forward and backward functions in `ops_mathematic.py`; note that these should be extremely short.\n",
        "\n",
        "**Important:** You should call NDArray.make with the new strides and offset, and then immediately `.compact()` this array. The resulting array is then copied and has positive strides. We want this (less-than-optimal) behavior because we did not account for negative strides in our previous implementation. _Aside:_ If you want, consider where/if negative strides break your implementation. `__getitem__` definitely doesn't work due to how we processed slices; is there anything else? (_Note_: this isn't graded.)\n",
        "\n",
        "Also, if you want to add a `flip` operator implementation on the CPU/CUDA backends instead, that's also okay.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zs47lPru66oV",
        "outputId": "c00633db-4a7c-47fc-c94b-0ff95ded8817"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: langsmith-0.4.42, typeguard-4.4.4, anyio-4.11.0\n",
            "collected 1803 items / 1763 deselected / 40 selected                           \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py::test_flip_forward[params0-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params0-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [  5%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params1-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [  7%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params1-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 10%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params2-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 12%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params2-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 15%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params3-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 17%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params3-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 20%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params4-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 22%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params4-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 25%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params5-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 27%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params5-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 30%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params6-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 32%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params6-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 35%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params7-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 37%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params7-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 40%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params8-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 42%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params8-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 45%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params9-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 47%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_forward[params9-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params0-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 52%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params0-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 55%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params1-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 57%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params1-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 60%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params2-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 62%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params2-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 65%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params3-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 67%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params3-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 70%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params4-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 72%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params4-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 75%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params5-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 77%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params5-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 80%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params6-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 82%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params6-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 85%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params7-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 87%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params7-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 90%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params8-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 92%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params8-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [ 95%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params9-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[31m [ 97%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_flip_backward[params9-needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m____ test_flip_forward[params0-needle.backend_ndarray.ndarray_backend_cuda] ____\u001b[0m\n",
            "\n",
            "params = {'axes': (0,), 'shape': (10, 5)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, flip_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_flip_forward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape)\u001b[90m\u001b[39;49;00m\n",
            "        _B = np.flip(_A, axes)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(_A, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "_B         = array([[-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028],\n",
            "       [-1.04855297, -1.42001794, -1.7062701...842, -0.15135721, -0.10321885,  0.4105985 ],\n",
            "       [ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799]])\n",
            "axes       = (0,)\n",
            "device     = cuda()\n",
            "params     = {'axes': (0,), 'shape': (10, 5)}\n",
            "shape      = (10, 5)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:122: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7f7afabe6ab0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:724: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7f7afa02a930>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (10, 5), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7f7be0b39430>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (10, 5)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m____ test_flip_forward[params1-needle.backend_ndarray.ndarray_backend_cuda] ____\u001b[0m\n",
            "\n",
            "params = {'axes': (1,), 'shape': (10, 5)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, flip_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_flip_forward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape)\u001b[90m\u001b[39;49;00m\n",
            "        _B = np.flip(_A, axes)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(_A, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "_B         = array([[ 1.86755799,  2.2408932 ,  0.97873798,  0.40015721,  1.76405235],\n",
            "       [ 0.4105985 , -0.10321885, -0.1513572...54 , -1.70627019, -1.42001794, -1.04855297],\n",
            "       [-0.21274028, -1.61389785,  0.77749036, -1.25279536, -0.4380743 ]])\n",
            "axes       = (1,)\n",
            "device     = cuda()\n",
            "params     = {'axes': (1,), 'shape': (10, 5)}\n",
            "shape      = (10, 5)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:122: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7f7afa0b2180>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:724: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7f7af945f920>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (10, 5), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7f7af945fa10>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (10, 5)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m____ test_flip_forward[params2-needle.backend_ndarray.ndarray_backend_cuda] ____\u001b[0m\n",
            "\n",
            "params = {'axes': (0, 1), 'shape': (10, 5)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, flip_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_flip_forward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape)\u001b[90m\u001b[39;49;00m\n",
            "        _B = np.flip(_A, axes)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(_A, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "_B         = array([[-0.21274028, -1.61389785,  0.77749036, -1.25279536, -0.4380743 ],\n",
            "       [-0.50965218,  1.9507754 , -1.7062701...885, -0.15135721,  0.95008842, -0.97727788],\n",
            "       [ 1.86755799,  2.2408932 ,  0.97873798,  0.40015721,  1.76405235]])\n",
            "axes       = (0, 1)\n",
            "device     = cuda()\n",
            "params     = {'axes': (0, 1), 'shape': (10, 5)}\n",
            "shape      = (10, 5)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:122: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7f7afa0b2a20>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:724: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7f7be0b55130>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (10, 5), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7f7be0b557f0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (10, 5)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m____ test_flip_forward[params3-needle.backend_ndarray.ndarray_backend_cuda] ____\u001b[0m\n",
            "\n",
            "params = {'axes': (0, 1), 'shape': (10, 32, 32, 8)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, flip_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_flip_forward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape)\u001b[90m\u001b[39;49;00m\n",
            "        _B = np.flip(_A, axes)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(_A, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[[ 1.76405235e+00,  4.00157208e-01,  9.78737984e-01, ...,\n",
            "          -9.77277880e-01,  9.50088418e-01, -1.51357...4.08956722e-01, -2.06575306e-01,  1.22084664e+00, ...,\n",
            "           3.40539329e-01,  6.47998581e-02,  8.28751864e-01]]]])\n",
            "_B         = array([[[[ 1.67386460e+00,  1.09525980e+00, -4.17631359e-01, ...,\n",
            "           9.36113484e-01,  5.84919249e-01, -8.18787...8.13364259e-01, -1.46642433e+00,  5.21064876e-01, ...,\n",
            "          -3.19328417e-01,  6.91538751e-01,  6.94749144e-01]]]])\n",
            "axes       = (0, 1)\n",
            "device     = cuda()\n",
            "params     = {'axes': (0, 1), 'shape': (10, 32, 32, 8)}\n",
            "shape      = (10, 32, 32, 8)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:122: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 1.76405235e+00,  4.00157208e-01,  9.78737984e-01, ...,\n",
            "          -9.77277880e-01,  9.50088418e-01, -1.51357...4.08956722e-01, -2.06575306e-01,  1.22084664e+00, ...,\n",
            "           3.40539329e-01,  6.47998581e-02,  8.28751864e-01]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7f7af949c980>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 1.76405235e+00,  4.00157208e-01,  9.78737984e-01, ...,\n",
            "          -9.77277880e-01,  9.50088418e-01, -1.51357...4.08956722e-01, -2.06575306e-01,  1.22084664e+00, ...,\n",
            "           3.40539329e-01,  6.47998581e-02,  8.28751864e-01]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:724: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 1.76405235e+00,  4.00157208e-01,  9.78737984e-01, ...,\n",
            "          -9.77277880e-01,  9.50088418e-01, -1.51357...4.08956722e-01, -2.06575306e-01,  1.22084664e+00, ...,\n",
            "           3.40539329e-01,  6.47998581e-02,  8.28751864e-01]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 1.76405235e+00,  4.00157208e-01,  9.78737984e-01, ...,\n",
            "          -9.77277880e-01,  9.50088418e-01, -1.51357...4.08956722e-01, -2.06575306e-01,  1.22084664e+00, ...,\n",
            "           3.40539329e-01,  6.47998581e-02,  8.28751864e-01]]]])\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7f7af949f8c0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (10, 32, 32, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7f7af949ea80>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (10, 32, 32, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m____ test_flip_forward[params4-needle.backend_ndarray.ndarray_backend_cuda] ____\u001b[0m\n",
            "\n",
            "params = {'axes': (0, 1), 'shape': (3, 3, 6, 8)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, flip_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_flip_forward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape)\u001b[90m\u001b[39;49;00m\n",
            "        _B = np.flip(_A, axes)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(_A, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,\n",
            "           1.86755799, -0.97727788,  0.95008842, -0.1513... [-0.13010695,  0.09395323,  0.94304609, -2.73967717,\n",
            "          -0.56931205,  0.26990435, -0.46684555, -1.41690611]]]])\n",
            "_B         = array([[[[ 0.03863055, -1.6567151 , -0.98551074, -1.47183501,\n",
            "           1.64813493,  0.16422776,  0.56729028, -0.2226... [-1.04855297, -1.42001794, -1.70627019,  1.9507754 ,\n",
            "          -0.50965218, -0.4380743 , -1.25279536,  0.77749036]]]])\n",
            "axes       = (0, 1)\n",
            "device     = cuda()\n",
            "params     = {'axes': (0, 1), 'shape': (3, 3, 6, 8)}\n",
            "shape      = (3, 3, 6, 8)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:122: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,\n",
            "           1.86755799, -0.97727788,  0.95008842, -0.1513... [-0.13010695,  0.09395323,  0.94304609, -2.73967717,\n",
            "          -0.56931205,  0.26990435, -0.46684555, -1.41690611]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7f7af94fd760>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,\n",
            "           1.86755799, -0.97727788,  0.95008842, -0.1513... [-0.13010695,  0.09395323,  0.94304609, -2.73967717,\n",
            "          -0.56931205,  0.26990435, -0.46684555, -1.41690611]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:724: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,\n",
            "           1.86755799, -0.97727788,  0.95008842, -0.1513... [-0.13010695,  0.09395323,  0.94304609, -2.73967717,\n",
            "          -0.56931205,  0.26990435, -0.46684555, -1.41690611]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,\n",
            "           1.86755799, -0.97727788,  0.95008842, -0.1513... [-0.13010695,  0.09395323,  0.94304609, -2.73967717,\n",
            "          -0.56931205,  0.26990435, -0.46684555, -1.41690611]]]])\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7f7af94fd490>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 3, 6, 8), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7f7af94fd430>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 3, 6, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m____ test_flip_forward[params5-needle.backend_ndarray.ndarray_backend_cuda] ____\u001b[0m\n",
            "\n",
            "params = {'axes': (1, 2), 'shape': (10, 32, 32, 8)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, flip_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_flip_forward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape)\u001b[90m\u001b[39;49;00m\n",
            "        _B = np.flip(_A, axes)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(_A, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[[ 1.76405235e+00,  4.00157208e-01,  9.78737984e-01, ...,\n",
            "          -9.77277880e-01,  9.50088418e-01, -1.51357...4.08956722e-01, -2.06575306e-01,  1.22084664e+00, ...,\n",
            "           3.40539329e-01,  6.47998581e-02,  8.28751864e-01]]]])\n",
            "_B         = array([[[[ 6.85915746e-01,  1.85270697e+00,  1.58169123e+00, ...,\n",
            "           6.66044853e-01,  5.32038766e-01, -1.05080...1.02348043e+00,  8.92468343e-01,  9.79886230e-01, ...,\n",
            "          -1.92371106e+00, -1.58578942e+00, -8.67523255e-02]]]])\n",
            "axes       = (1, 2)\n",
            "device     = cuda()\n",
            "params     = {'axes': (1, 2), 'shape': (10, 32, 32, 8)}\n",
            "shape      = (10, 32, 32, 8)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:122: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 1.76405235e+00,  4.00157208e-01,  9.78737984e-01, ...,\n",
            "          -9.77277880e-01,  9.50088418e-01, -1.51357...4.08956722e-01, -2.06575306e-01,  1.22084664e+00, ...,\n",
            "           3.40539329e-01,  6.47998581e-02,  8.28751864e-01]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7f7af94ff380>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 1.76405235e+00,  4.00157208e-01,  9.78737984e-01, ...,\n",
            "          -9.77277880e-01,  9.50088418e-01, -1.51357...4.08956722e-01, -2.06575306e-01,  1.22084664e+00, ...,\n",
            "           3.40539329e-01,  6.47998581e-02,  8.28751864e-01]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:724: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 1.76405235e+00,  4.00157208e-01,  9.78737984e-01, ...,\n",
            "          -9.77277880e-01,  9.50088418e-01, -1.51357...4.08956722e-01, -2.06575306e-01,  1.22084664e+00, ...,\n",
            "           3.40539329e-01,  6.47998581e-02,  8.28751864e-01]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 1.76405235e+00,  4.00157208e-01,  9.78737984e-01, ...,\n",
            "          -9.77277880e-01,  9.50088418e-01, -1.51357...4.08956722e-01, -2.06575306e-01,  1.22084664e+00, ...,\n",
            "           3.40539329e-01,  6.47998581e-02,  8.28751864e-01]]]])\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7f7af94ff5f0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (10, 32, 32, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7f7af94fcec0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (10, 32, 32, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m____ test_flip_forward[params6-needle.backend_ndarray.ndarray_backend_cuda] ____\u001b[0m\n",
            "\n",
            "params = {'axes': (1, 2), 'shape': (3, 3, 6, 8)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, flip_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_flip_forward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape)\u001b[90m\u001b[39;49;00m\n",
            "        _B = np.flip(_A, axes)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(_A, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,\n",
            "           1.86755799, -0.97727788,  0.95008842, -0.1513... [-0.13010695,  0.09395323,  0.94304609, -2.73967717,\n",
            "          -0.56931205,  0.26990435, -0.46684555, -1.41690611]]]])\n",
            "_B         = array([[[[ 0.57659082, -0.20829876,  0.39600671, -1.09306151,\n",
            "          -1.49125759,  0.4393917 ,  0.1666735 ,  0.6350... [ 0.68981816,  1.30184623, -0.62808756, -0.48102712,\n",
            "           2.3039167 , -1.06001582, -0.1359497 ,  1.13689136]]]])\n",
            "axes       = (1, 2)\n",
            "device     = cuda()\n",
            "params     = {'axes': (1, 2), 'shape': (3, 3, 6, 8)}\n",
            "shape      = (3, 3, 6, 8)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:122: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,\n",
            "           1.86755799, -0.97727788,  0.95008842, -0.1513... [-0.13010695,  0.09395323,  0.94304609, -2.73967717,\n",
            "          -0.56931205,  0.26990435, -0.46684555, -1.41690611]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7f7af94e6510>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,\n",
            "           1.86755799, -0.97727788,  0.95008842, -0.1513... [-0.13010695,  0.09395323,  0.94304609, -2.73967717,\n",
            "          -0.56931205,  0.26990435, -0.46684555, -1.41690611]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:724: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,\n",
            "           1.86755799, -0.97727788,  0.95008842, -0.1513... [-0.13010695,  0.09395323,  0.94304609, -2.73967717,\n",
            "          -0.56931205,  0.26990435, -0.46684555, -1.41690611]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,\n",
            "           1.86755799, -0.97727788,  0.95008842, -0.1513... [-0.13010695,  0.09395323,  0.94304609, -2.73967717,\n",
            "          -0.56931205,  0.26990435, -0.46684555, -1.41690611]]]])\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7f7af94e60f0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 3, 6, 8), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7f7af94e4aa0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 3, 6, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m____ test_flip_forward[params7-needle.backend_ndarray.ndarray_backend_cuda] ____\u001b[0m\n",
            "\n",
            "params = {'axes': (2, 3), 'shape': (10, 32, 32, 8)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, flip_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_flip_forward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape)\u001b[90m\u001b[39;49;00m\n",
            "        _B = np.flip(_A, axes)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(_A, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[[ 1.76405235e+00,  4.00157208e-01,  9.78737984e-01, ...,\n",
            "          -9.77277880e-01,  9.50088418e-01, -1.51357...4.08956722e-01, -2.06575306e-01,  1.22084664e+00, ...,\n",
            "           3.40539329e-01,  6.47998581e-02,  8.28751864e-01]]]])\n",
            "_B         = array([[[[ 6.94749144e-01,  6.91538751e-01, -3.19328417e-01, ...,\n",
            "           5.21064876e-01, -1.46642433e+00, -8.13364...8.18787218e-01,  5.84919249e-01,  9.36113484e-01, ...,\n",
            "          -4.17631359e-01,  1.09525980e+00,  1.67386460e+00]]]])\n",
            "axes       = (2, 3)\n",
            "device     = cuda()\n",
            "params     = {'axes': (2, 3), 'shape': (10, 32, 32, 8)}\n",
            "shape      = (10, 32, 32, 8)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:122: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 1.76405235e+00,  4.00157208e-01,  9.78737984e-01, ...,\n",
            "          -9.77277880e-01,  9.50088418e-01, -1.51357...4.08956722e-01, -2.06575306e-01,  1.22084664e+00, ...,\n",
            "           3.40539329e-01,  6.47998581e-02,  8.28751864e-01]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7f7af94e66f0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 1.76405235e+00,  4.00157208e-01,  9.78737984e-01, ...,\n",
            "          -9.77277880e-01,  9.50088418e-01, -1.51357...4.08956722e-01, -2.06575306e-01,  1.22084664e+00, ...,\n",
            "           3.40539329e-01,  6.47998581e-02,  8.28751864e-01]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:724: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 1.76405235e+00,  4.00157208e-01,  9.78737984e-01, ...,\n",
            "          -9.77277880e-01,  9.50088418e-01, -1.51357...4.08956722e-01, -2.06575306e-01,  1.22084664e+00, ...,\n",
            "           3.40539329e-01,  6.47998581e-02,  8.28751864e-01]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 1.76405235e+00,  4.00157208e-01,  9.78737984e-01, ...,\n",
            "          -9.77277880e-01,  9.50088418e-01, -1.51357...4.08956722e-01, -2.06575306e-01,  1.22084664e+00, ...,\n",
            "           3.40539329e-01,  6.47998581e-02,  8.28751864e-01]]]])\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7f7af94e6c60>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (10, 32, 32, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7f7af94e51f0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (10, 32, 32, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m____ test_flip_forward[params8-needle.backend_ndarray.ndarray_backend_cuda] ____\u001b[0m\n",
            "\n",
            "params = {'axes': (2, 3), 'shape': (3, 3, 6, 8)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, flip_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_flip_forward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape)\u001b[90m\u001b[39;49;00m\n",
            "        _B = np.flip(_A, axes)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(_A, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,\n",
            "           1.86755799, -0.97727788,  0.95008842, -0.1513... [-0.13010695,  0.09395323,  0.94304609, -2.73967717,\n",
            "          -0.56931205,  0.26990435, -0.46684555, -1.41690611]]]])\n",
            "_B         = array([[[[ 0.77749036, -1.25279536, -0.4380743 , -0.50965218,\n",
            "           1.9507754 , -1.70627019, -1.42001794, -1.0485... [-0.2226751 ,  0.56729028,  0.16422776,  1.64813493,\n",
            "          -1.47183501, -0.98551074, -1.6567151 ,  0.03863055]]]])\n",
            "axes       = (2, 3)\n",
            "device     = cuda()\n",
            "params     = {'axes': (2, 3), 'shape': (3, 3, 6, 8)}\n",
            "shape      = (3, 3, 6, 8)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:122: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,\n",
            "           1.86755799, -0.97727788,  0.95008842, -0.1513... [-0.13010695,  0.09395323,  0.94304609, -2.73967717,\n",
            "          -0.56931205,  0.26990435, -0.46684555, -1.41690611]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7f7af94fcc20>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,\n",
            "           1.86755799, -0.97727788,  0.95008842, -0.1513... [-0.13010695,  0.09395323,  0.94304609, -2.73967717,\n",
            "          -0.56931205,  0.26990435, -0.46684555, -1.41690611]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:724: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,\n",
            "           1.86755799, -0.97727788,  0.95008842, -0.1513... [-0.13010695,  0.09395323,  0.94304609, -2.73967717,\n",
            "          -0.56931205,  0.26990435, -0.46684555, -1.41690611]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,\n",
            "           1.86755799, -0.97727788,  0.95008842, -0.1513... [-0.13010695,  0.09395323,  0.94304609, -2.73967717,\n",
            "          -0.56931205,  0.26990435, -0.46684555, -1.41690611]]]])\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7f7af94fdb20>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 3, 6, 8), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7f7af94fcdd0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 3, 6, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m____ test_flip_forward[params9-needle.backend_ndarray.ndarray_backend_cuda] ____\u001b[0m\n",
            "\n",
            "params = {'axes': (0, 1, 2, 3), 'shape': (10, 32, 32, 8)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, flip_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_flip_forward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(*shape)\u001b[90m\u001b[39;49;00m\n",
            "        _B = np.flip(_A, axes)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(_A, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[[ 1.76405235e+00,  4.00157208e-01,  9.78737984e-01, ...,\n",
            "          -9.77277880e-01,  9.50088418e-01, -1.51357...4.08956722e-01, -2.06575306e-01,  1.22084664e+00, ...,\n",
            "           3.40539329e-01,  6.47998581e-02,  8.28751864e-01]]]])\n",
            "_B         = array([[[[ 8.28751864e-01,  6.47998581e-02,  3.40539329e-01, ...,\n",
            "           1.22084664e+00, -2.06575306e-01,  4.08956...1.51357208e-01,  9.50088418e-01, -9.77277880e-01, ...,\n",
            "           9.78737984e-01,  4.00157208e-01,  1.76405235e+00]]]])\n",
            "axes       = (0, 1, 2, 3)\n",
            "device     = cuda()\n",
            "params     = {'axes': (0, 1, 2, 3), 'shape': (10, 32, 32, 8)}\n",
            "shape      = (10, 32, 32, 8)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:122: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 1.76405235e+00,  4.00157208e-01,  9.78737984e-01, ...,\n",
            "          -9.77277880e-01,  9.50088418e-01, -1.51357...4.08956722e-01, -2.06575306e-01,  1.22084664e+00, ...,\n",
            "           3.40539329e-01,  6.47998581e-02,  8.28751864e-01]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7f7af94fdc70>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 1.76405235e+00,  4.00157208e-01,  9.78737984e-01, ...,\n",
            "          -9.77277880e-01,  9.50088418e-01, -1.51357...4.08956722e-01, -2.06575306e-01,  1.22084664e+00, ...,\n",
            "           3.40539329e-01,  6.47998581e-02,  8.28751864e-01]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:724: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 1.76405235e+00,  4.00157208e-01,  9.78737984e-01, ...,\n",
            "          -9.77277880e-01,  9.50088418e-01, -1.51357...4.08956722e-01, -2.06575306e-01,  1.22084664e+00, ...,\n",
            "           3.40539329e-01,  6.47998581e-02,  8.28751864e-01]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 1.76405235e+00,  4.00157208e-01,  9.78737984e-01, ...,\n",
            "          -9.77277880e-01,  9.50088418e-01, -1.51357...4.08956722e-01, -2.06575306e-01,  1.22084664e+00, ...,\n",
            "           3.40539329e-01,  6.47998581e-02,  8.28751864e-01]]]])\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7f7af94fd1f0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (10, 32, 32, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7f7af94feae0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (10, 32, 32, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m___ test_flip_backward[params0-needle.backend_ndarray.ndarray_backend_cuda] ____\u001b[0m\n",
            "\n",
            "params = {'axes': (0,), 'shape': (10, 5)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, flip_backward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_flip_backward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            ">       backward_check(ndl.flip, ndl.Tensor(np.random.randn(*shape), device=device), axes=axes)\u001b[90m\u001b[39;49;00m\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "axes       = (0,)\n",
            "device     = cuda()\n",
            "params     = {'axes': (0,), 'shape': (10, 5)}\n",
            "shape      = (10, 5)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:145: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7f7af94c7290>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:724: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7f7af94c4d70>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (10, 5), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7f7af94c4b90>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (10, 5)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m___ test_flip_backward[params1-needle.backend_ndarray.ndarray_backend_cuda] ____\u001b[0m\n",
            "\n",
            "params = {'axes': (1,), 'shape': (10, 5)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, flip_backward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_flip_backward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            ">       backward_check(ndl.flip, ndl.Tensor(np.random.randn(*shape), device=device), axes=axes)\u001b[90m\u001b[39;49;00m\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "axes       = (1,)\n",
            "device     = cuda()\n",
            "params     = {'axes': (1,), 'shape': (10, 5)}\n",
            "shape      = (10, 5)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:145: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7f7af94c5d90>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:724: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7f7af94c7c20>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (10, 5), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7f7af94c7fe0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (10, 5)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m___ test_flip_backward[params2-needle.backend_ndarray.ndarray_backend_cuda] ____\u001b[0m\n",
            "\n",
            "params = {'axes': (0, 1), 'shape': (10, 5)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, flip_backward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_flip_backward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            ">       backward_check(ndl.flip, ndl.Tensor(np.random.randn(*shape), device=device), axes=axes)\u001b[90m\u001b[39;49;00m\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "axes       = (0, 1)\n",
            "device     = cuda()\n",
            "params     = {'axes': (0, 1), 'shape': (10, 5)}\n",
            "shape      = (10, 5)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:145: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7f7bd8211610>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:724: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,  1.86755799],\n",
            "       [-0.97727788,  0.95008842, -0.1513572...794, -1.70627019,  1.9507754 , -0.50965218],\n",
            "       [-0.4380743 , -1.25279536,  0.77749036, -1.61389785, -0.21274028]])\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7f7bde832750>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (10, 5), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7f7bde8328d0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (10, 5)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m___ test_flip_backward[params3-needle.backend_ndarray.ndarray_backend_cuda] ____\u001b[0m\n",
            "\n",
            "params = {'axes': (0, 1), 'shape': (2, 3, 3, 8)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, flip_backward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_flip_backward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            ">       backward_check(ndl.flip, ndl.Tensor(np.random.randn(*shape), device=device), axes=axes)\u001b[90m\u001b[39;49;00m\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "axes       = (0, 1)\n",
            "device     = cuda()\n",
            "params     = {'axes': (0, 1), 'shape': (2, 3, 3, 8)}\n",
            "shape      = (2, 3, 3, 8)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:145: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,\n",
            "           1.86755799, -0.97727788,  0.95008842, -0.1513... [ 0.57659082, -0.20829876,  0.39600671, -1.09306151,\n",
            "          -1.49125759,  0.4393917 ,  0.1666735 ,  0.63503144]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7f7af94c47a0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,\n",
            "           1.86755799, -0.97727788,  0.95008842, -0.1513... [ 0.57659082, -0.20829876,  0.39600671, -1.09306151,\n",
            "          -1.49125759,  0.4393917 ,  0.1666735 ,  0.63503144]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:724: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,\n",
            "           1.86755799, -0.97727788,  0.95008842, -0.1513... [ 0.57659082, -0.20829876,  0.39600671, -1.09306151,\n",
            "          -1.49125759,  0.4393917 ,  0.1666735 ,  0.63503144]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ,\n",
            "           1.86755799, -0.97727788,  0.95008842, -0.1513... [ 0.57659082, -0.20829876,  0.39600671, -1.09306151,\n",
            "          -1.49125759,  0.4393917 ,  0.1666735 ,  0.63503144]]]])\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7f7af94c55b0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (2, 3, 3, 8), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7f7af94c7f50>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (2, 3, 3, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m___ test_flip_backward[params4-needle.backend_ndarray.ndarray_backend_cuda] ____\u001b[0m\n",
            "\n",
            "params = {'axes': (0, 1), 'shape': (3, 3, 6, 4)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, flip_backward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_flip_backward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            ">       backward_check(ndl.flip, ndl.Tensor(np.random.randn(*shape), device=device), axes=axes)\u001b[90m\u001b[39;49;00m\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "axes       = (0, 1)\n",
            "device     = cuda()\n",
            "params     = {'axes': (0, 1), 'shape': (3, 3, 6, 4)}\n",
            "shape      = (3, 3, 6, 4)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:145: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
            "         [ 1.86755799, -0.97727788,  0.95008842, -0.151...[ 0.2799246 , -0.09815039,  0.91017891,  0.31721822],\n",
            "         [ 0.78632796, -0.4664191 , -0.94444626, -0.41004969]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7f7af94c6810>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
            "         [ 1.86755799, -0.97727788,  0.95008842, -0.151...[ 0.2799246 , -0.09815039,  0.91017891,  0.31721822],\n",
            "         [ 0.78632796, -0.4664191 , -0.94444626, -0.41004969]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:724: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
            "         [ 1.86755799, -0.97727788,  0.95008842, -0.151...[ 0.2799246 , -0.09815039,  0.91017891,  0.31721822],\n",
            "         [ 0.78632796, -0.4664191 , -0.94444626, -0.41004969]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
            "         [ 1.86755799, -0.97727788,  0.95008842, -0.151...[ 0.2799246 , -0.09815039,  0.91017891,  0.31721822],\n",
            "         [ 0.78632796, -0.4664191 , -0.94444626, -0.41004969]]]])\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7f7af94c6b70>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 3, 6, 4), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7f7af94c6f00>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 3, 6, 4)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m___ test_flip_backward[params5-needle.backend_ndarray.ndarray_backend_cuda] ____\u001b[0m\n",
            "\n",
            "params = {'axes': (1, 2), 'shape': (2, 3, 3, 4)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, flip_backward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_flip_backward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            ">       backward_check(ndl.flip, ndl.Tensor(np.random.randn(*shape), device=device), axes=axes)\u001b[90m\u001b[39;49;00m\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "axes       = (1, 2)\n",
            "device     = cuda()\n",
            "params     = {'axes': (1, 2), 'shape': (2, 3, 3, 4)}\n",
            "shape      = (2, 3, 3, 4)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:145: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
            "         [ 1.86755799, -0.97727788,  0.95008842, -0.151...[ 0.17742614, -0.40178094, -1.63019835,  0.46278226],\n",
            "         [-0.90729836,  0.0519454 ,  0.72909056,  0.12898291]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7f7af94c5af0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
            "         [ 1.86755799, -0.97727788,  0.95008842, -0.151...[ 0.17742614, -0.40178094, -1.63019835,  0.46278226],\n",
            "         [-0.90729836,  0.0519454 ,  0.72909056,  0.12898291]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:724: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
            "         [ 1.86755799, -0.97727788,  0.95008842, -0.151...[ 0.17742614, -0.40178094, -1.63019835,  0.46278226],\n",
            "         [-0.90729836,  0.0519454 ,  0.72909056,  0.12898291]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
            "         [ 1.86755799, -0.97727788,  0.95008842, -0.151...[ 0.17742614, -0.40178094, -1.63019835,  0.46278226],\n",
            "         [-0.90729836,  0.0519454 ,  0.72909056,  0.12898291]]]])\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7f7af94c7830>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (2, 3, 3, 4), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7f7af94c4560>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (2, 3, 3, 4)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m___ test_flip_backward[params6-needle.backend_ndarray.ndarray_backend_cuda] ____\u001b[0m\n",
            "\n",
            "params = {'axes': (1, 2), 'shape': (3, 3, 6, 4)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, flip_backward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_flip_backward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            ">       backward_check(ndl.flip, ndl.Tensor(np.random.randn(*shape), device=device), axes=axes)\u001b[90m\u001b[39;49;00m\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "axes       = (1, 2)\n",
            "device     = cuda()\n",
            "params     = {'axes': (1, 2), 'shape': (3, 3, 6, 4)}\n",
            "shape      = (3, 3, 6, 4)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:145: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
            "         [ 1.86755799, -0.97727788,  0.95008842, -0.151...[ 0.2799246 , -0.09815039,  0.91017891,  0.31721822],\n",
            "         [ 0.78632796, -0.4664191 , -0.94444626, -0.41004969]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7f7af94c5040>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
            "         [ 1.86755799, -0.97727788,  0.95008842, -0.151...[ 0.2799246 , -0.09815039,  0.91017891,  0.31721822],\n",
            "         [ 0.78632796, -0.4664191 , -0.94444626, -0.41004969]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:724: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
            "         [ 1.86755799, -0.97727788,  0.95008842, -0.151...[ 0.2799246 , -0.09815039,  0.91017891,  0.31721822],\n",
            "         [ 0.78632796, -0.4664191 , -0.94444626, -0.41004969]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
            "         [ 1.86755799, -0.97727788,  0.95008842, -0.151...[ 0.2799246 , -0.09815039,  0.91017891,  0.31721822],\n",
            "         [ 0.78632796, -0.4664191 , -0.94444626, -0.41004969]]]])\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7f7af94c6240>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 3, 6, 4), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7f7af94c48c0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 3, 6, 4)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m___ test_flip_backward[params7-needle.backend_ndarray.ndarray_backend_cuda] ____\u001b[0m\n",
            "\n",
            "params = {'axes': (2, 3), 'shape': (2, 3, 3, 4)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, flip_backward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_flip_backward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            ">       backward_check(ndl.flip, ndl.Tensor(np.random.randn(*shape), device=device), axes=axes)\u001b[90m\u001b[39;49;00m\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "axes       = (2, 3)\n",
            "device     = cuda()\n",
            "params     = {'axes': (2, 3), 'shape': (2, 3, 3, 4)}\n",
            "shape      = (2, 3, 3, 4)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:145: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
            "         [ 1.86755799, -0.97727788,  0.95008842, -0.151...[ 0.17742614, -0.40178094, -1.63019835,  0.46278226],\n",
            "         [-0.90729836,  0.0519454 ,  0.72909056,  0.12898291]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7f7af94c41d0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
            "         [ 1.86755799, -0.97727788,  0.95008842, -0.151...[ 0.17742614, -0.40178094, -1.63019835,  0.46278226],\n",
            "         [-0.90729836,  0.0519454 ,  0.72909056,  0.12898291]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:724: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
            "         [ 1.86755799, -0.97727788,  0.95008842, -0.151...[ 0.17742614, -0.40178094, -1.63019835,  0.46278226],\n",
            "         [-0.90729836,  0.0519454 ,  0.72909056,  0.12898291]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
            "         [ 1.86755799, -0.97727788,  0.95008842, -0.151...[ 0.17742614, -0.40178094, -1.63019835,  0.46278226],\n",
            "         [-0.90729836,  0.0519454 ,  0.72909056,  0.12898291]]]])\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7f7af94c6180>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (2, 3, 3, 4), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7f7af94c78f0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (2, 3, 3, 4)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m___ test_flip_backward[params8-needle.backend_ndarray.ndarray_backend_cuda] ____\u001b[0m\n",
            "\n",
            "params = {'axes': (2, 3), 'shape': (3, 3, 6, 4)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, flip_backward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_flip_backward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            ">       backward_check(ndl.flip, ndl.Tensor(np.random.randn(*shape), device=device), axes=axes)\u001b[90m\u001b[39;49;00m\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "axes       = (2, 3)\n",
            "device     = cuda()\n",
            "params     = {'axes': (2, 3), 'shape': (3, 3, 6, 4)}\n",
            "shape      = (3, 3, 6, 4)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:145: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
            "         [ 1.86755799, -0.97727788,  0.95008842, -0.151...[ 0.2799246 , -0.09815039,  0.91017891,  0.31721822],\n",
            "         [ 0.78632796, -0.4664191 , -0.94444626, -0.41004969]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7f7af94b28d0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
            "         [ 1.86755799, -0.97727788,  0.95008842, -0.151...[ 0.2799246 , -0.09815039,  0.91017891,  0.31721822],\n",
            "         [ 0.78632796, -0.4664191 , -0.94444626, -0.41004969]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:724: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
            "         [ 1.86755799, -0.97727788,  0.95008842, -0.151...[ 0.2799246 , -0.09815039,  0.91017891,  0.31721822],\n",
            "         [ 0.78632796, -0.4664191 , -0.94444626, -0.41004969]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
            "         [ 1.86755799, -0.97727788,  0.95008842, -0.151...[ 0.2799246 , -0.09815039,  0.91017891,  0.31721822],\n",
            "         [ 0.78632796, -0.4664191 , -0.94444626, -0.41004969]]]])\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7f7af94b3da0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 3, 6, 4), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7f7af94b0230>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 3, 6, 4)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m___ test_flip_backward[params9-needle.backend_ndarray.ndarray_backend_cuda] ____\u001b[0m\n",
            "\n",
            "params = {'axes': (0, 1, 2, 3), 'shape': (2, 3, 3, 4)}, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, flip_backward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_flip_backward\u001b[39;49;00m(params, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        shape, axes = params[\u001b[33m'\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], params[\u001b[33m'\u001b[39;49;00m\u001b[33maxes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            ">       backward_check(ndl.flip, ndl.Tensor(np.random.randn(*shape), device=device), axes=axes)\u001b[90m\u001b[39;49;00m\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "axes       = (0, 1, 2, 3)\n",
            "device     = cuda()\n",
            "params     = {'axes': (0, 1, 2, 3), 'shape': (2, 3, 3, 4)}\n",
            "shape      = (2, 3, 3, 4)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:145: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
            "         [ 1.86755799, -0.97727788,  0.95008842, -0.151...[ 0.17742614, -0.40178094, -1.63019835,  0.46278226],\n",
            "         [-0.90729836,  0.0519454 ,  0.72909056,  0.12898291]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7f7af94b0ad0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
            "         [ 1.86755799, -0.97727788,  0.95008842, -0.151...[ 0.17742614, -0.40178094, -1.63019835,  0.46278226],\n",
            "         [-0.90729836,  0.0519454 ,  0.72909056,  0.12898291]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:724: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
            "         [ 1.86755799, -0.97727788,  0.95008842, -0.151...[ 0.17742614, -0.40178094, -1.63019835,  0.46278226],\n",
            "         [-0.90729836,  0.0519454 ,  0.72909056,  0.12898291]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
            "         [ 1.86755799, -0.97727788,  0.95008842, -0.151...[ 0.17742614, -0.40178094, -1.63019835,  0.46278226],\n",
            "         [-0.90729836,  0.0519454 ,  0.72909056,  0.12898291]]]])\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7f7af94b18b0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (2, 3, 3, 4), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7f7af94b2210>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (2, 3, 3, 4)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_flip_forward[params0-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_flip_forward[params1-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_flip_forward[params2-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_flip_forward[params3-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_flip_forward[params4-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_flip_forward[params5-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_flip_forward[params6-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_flip_forward[params7-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_flip_forward[params8-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_flip_forward[params9-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_flip_backward[params0-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_flip_backward[params1-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_flip_backward[params2-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_flip_backward[params3-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_flip_backward[params4-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_flip_backward[params5-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_flip_backward[params6-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_flip_backward[params7-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_flip_backward[params8-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_flip_backward[params9-needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31m================ \u001b[31m\u001b[1m20 failed\u001b[0m, \u001b[32m20 passed\u001b[0m, \u001b[33m1763 deselected\u001b[0m\u001b[31m in 7.96s\u001b[0m\u001b[31m ================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"flip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4blkFAc66oV"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VKMd-BA66oV"
      },
      "source": [
        "### Dilation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BHvrnZA66oW"
      },
      "source": [
        "The dilation operator puts zeros between elements of an ndarray. We will need it for computing the backward pass of convolution when the stride of the convolution is greater than 1. As an example, dilation should do the following to a 2x2 matrix when dilated by 1 on both axes:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "1 & 2 \\\\\n",
        "3 & 4\n",
        "\\end{bmatrix}\n",
        "\\Longrightarrow\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 2 & 0 \\\\\n",
        "0 & 0 & 0 & 0 \\\\\n",
        "3 & 0 & 4 & 0 \\\\\n",
        "0 & 0 & 0 & 0\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "To get some intuition for why we need dilation for the backward pass of strided convolution, consider a  `stride=2`, `padding=\"same\"`, `input_channels=output_channels=8` convolution applied to an input of size (10, 32, 32, 8). The resulting output will be of size (10, 16, 16, 8) due to the stride, and thus `out_grad` will have shape (10, 16, 16, 8). Yet, the gradient of the input needs to, of course, have shape (10, 32, 32, 8) -- so we must need to increase the size of `out_grad` in some way. Consider also that you could implement strided convolution as `Conv(x)[:, ::2, ::2, :]`, i.e., only keeping every other pixel in the spatial dimension.\n",
        "\n",
        "\n",
        "Implement `Dilate` and `UnDilate` in `ops_mathematic.py`. Each operator takes two additional parameters (in attrs): the `dilation` amount and the `axes` to dilate. You must also implement the corresponding op `UnDilate`, whose forward pass will be used to implement the gradient of `Dilate`. (This is so we do not have to implement `GetItem` and `SetItem` ops, which can be highly inefficient to backprop through without additional optimizations.)\n",
        "\n",
        "**Note**: The dilation amount is additive, not multiplicative. In the example above, a dilation of `1` implies adding one row/column of zeros between each element along each dilated axis (and one removed row/column for each undilated axis). A dilation of `0` means no change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWCzzEoo66oW",
        "outputId": "675b27d4-7cae-4bd9-ba37-9f403d800f95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: langsmith-0.4.42, typeguard-4.4.4, anyio-4.11.0\n",
            "collected 1803 items / 1777 deselected / 26 selected                           \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py::test_dilate_forward[needle.backend_ndarray.ndarray_backend_cpu] \u001b[31mFAILED\u001b[0m\u001b[31m [  3%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_forward[needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [  7%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_dilate_backward[params0-needle.backend_ndarray.ndarray_backend_cpu] Fatal Python error: Segmentation fault\n",
            "\n",
            "Current thread 0x0000792666517000 (most recent call first):\n",
            "  File \"/content/drive/MyDrive/10714/hw4/python/needle/backend_ndarray/ndarray.py\", line 231 in compact\n",
            "  File \"/content/drive/MyDrive/10714/hw4/python/needle/backend_ndarray/ndarray.py\", line 490 in ewise_or_scalar\n",
            "  File \"/content/drive/MyDrive/10714/hw4/python/needle/backend_ndarray/ndarray.py\", line 494 in __add__\n",
            "  File \"/content/drive/MyDrive/10714/hw4/tests/hw4/test_conv.py\", line 26 in backward_check\n",
            "  File \"/content/drive/MyDrive/10714/hw4/tests/hw4/test_conv.py\", line 296 in test_dilate_backward\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/_pytest/python.py\", line 157 in pytest_pyfunc_call\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pluggy/_callers.py\", line 121 in _multicall\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pluggy/_manager.py\", line 120 in _hookexec\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pluggy/_hooks.py\", line 512 in __call__\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/_pytest/python.py\", line 1671 in runtest\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/_pytest/runner.py\", line 178 in pytest_runtest_call\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pluggy/_callers.py\", line 121 in _multicall\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pluggy/_manager.py\", line 120 in _hookexec\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pluggy/_hooks.py\", line 512 in __call__\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/_pytest/runner.py\", line 246 in <lambda>\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/_pytest/runner.py\", line 344 in from_call\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/_pytest/runner.py\", line 245 in call_and_report\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/_pytest/runner.py\", line 136 in runtestprotocol\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/_pytest/runner.py\", line 117 in pytest_runtest_protocol\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pluggy/_callers.py\", line 121 in _multicall\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pluggy/_manager.py\", line 120 in _hookexec\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pluggy/_hooks.py\", line 512 in __call__\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/_pytest/main.py\", line 367 in pytest_runtestloop\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pluggy/_callers.py\", line 121 in _multicall\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pluggy/_manager.py\", line 120 in _hookexec\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pluggy/_hooks.py\", line 512 in __call__\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/_pytest/main.py\", line 343 in _main\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/_pytest/main.py\", line 289 in wrap_session\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/_pytest/main.py\", line 336 in pytest_cmdline_main\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pluggy/_callers.py\", line 121 in _multicall\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pluggy/_manager.py\", line 120 in _hookexec\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pluggy/_hooks.py\", line 512 in __call__\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/_pytest/config/__init__.py\", line 175 in main\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/_pytest/config/__init__.py\", line 201 in console_main\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytest/__main__.py\", line 9 in <module>\n",
            "  File \"<frozen runpy>\", line 88 in _run_code\n",
            "  File \"<frozen runpy>\", line 198 in _run_module_as_main\n",
            "\n",
            "Extension modules: _brotli, zstandard.backend_c, simplejson._speedups, charset_normalizer.md, cython.cimports.libc.math, psutil._psutil_linux, psutil._psutil_posix, numpy._core._multiarray_umath, numpy._core._multiarray_tests, numpy.linalg._umath_linalg, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special (total: 30)\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"dilate\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1EKIJLG66oW"
      },
      "source": [
        "---------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SarFpnB366oW"
      },
      "source": [
        "### Submit new ops (flip/dilation) to mugrade [10 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FdKhqi966oW",
        "outputId": "c41f901d-a8f2-45ad-eb6e-e9085d6545d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submit\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: langsmith-0.4.42, typeguard-4.4.4, anyio-4.11.0\n",
            "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
            "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py \n",
            "Submitting new_ops...\n",
            "Grader test 1 passed\n",
            "Grader test 2 passed\n",
            "Grader test 3 passed\n",
            "Grader test 4 passed\n",
            "Grader test 5 passed\n",
            "\u001b[31mF\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m________________________________ submit_new_ops ________________________________\u001b[0m\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92msubmit_new_ops\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# pad\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m1337\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randint(low=\u001b[94m1\u001b[39;49;00m, high=\u001b[94m10\u001b[39;49;00m, size=(\u001b[94m2\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        A  = nd.NDArray(_A, device=nd.cpu())\u001b[90m\u001b[39;49;00m\n",
            "        MugradeSubmit(A.pad(( (\u001b[94m0\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m), (\u001b[94m1\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), (\u001b[94m2\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), (\u001b[94m0\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m))))\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mDoFlip\u001b[39;49;00m(shape, axes, backward=\u001b[94mFalse\u001b[39;49;00m, device=ndl.cpu()):\u001b[90m\u001b[39;49;00m\n",
            "            X = Rand(*shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            X.requires_grad = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            Y = ndl.flip(X, axes=axes)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "                V = Rand(*shape, device=device, entropy=\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "                Z = (V*Y).sum()\u001b[90m\u001b[39;49;00m\n",
            "                Z.backward()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m X.grad\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m Y\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mDoDilate\u001b[39;49;00m(shape, axes, dilation, backward=\u001b[94mFalse\u001b[39;49;00m, device=ndl.cpu()):\u001b[90m\u001b[39;49;00m\n",
            "            X = Rand(*shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            X.requires_grad = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            Y = ndl.dilate(X, dilation=dilation, axes=axes)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m backward:\u001b[90m\u001b[39;49;00m\n",
            "                V = Rand(*Y.shape, device=device, entropy=\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "                Z = (V*Y).sum()\u001b[90m\u001b[39;49;00m\n",
            "                Z.backward()\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m X.grad\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m Y\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# flip\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        MugradeSubmit(DoFlip((\u001b[94m2\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), (\u001b[94m1\u001b[39;49;00m,\u001b[94m2\u001b[39;49;00m)))\u001b[90m\u001b[39;49;00m\n",
            "        MugradeSubmit(DoFlip((\u001b[94m2\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m), (\u001b[94m0\u001b[39;49;00m,\u001b[94m1\u001b[39;49;00m,\u001b[94m2\u001b[39;49;00m,\u001b[94m3\u001b[39;49;00m)))\u001b[90m\u001b[39;49;00m\n",
            "        MugradeSubmit(DoFlip((\u001b[94m8\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m), (\u001b[94m1\u001b[39;49;00m,)))\u001b[90m\u001b[39;49;00m\n",
            "        MugradeSubmit(DoFlip((\u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m), (\u001b[94m0\u001b[39;49;00m,)))\u001b[90m\u001b[39;49;00m\n",
            ">       MugradeSubmit(DoFlip((\u001b[94m2\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m), (\u001b[94m2\u001b[39;49;00m,\u001b[94m3\u001b[39;49;00m), backward=\u001b[94mTrue\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:641: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:619: in DoFlip\n",
            "    \u001b[0mZ.backward()\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:297: in backward\n",
            "    \u001b[0mcompute_gradient_of_variables(\u001b[96mself\u001b[39;49;00m, out_grad)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:381: in compute_gradient_of_variables\n",
            "    \u001b[0mreverse_topo_order = \u001b[96mlist\u001b[39;49;00m(\u001b[96mreversed\u001b[39;49;00m(find_topo_sort([output_tensor])))\u001b[90m\u001b[39;49;00m\n",
            "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "node_list = [needle.Tensor([212.])]\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mfind_topo_sort\u001b[39;49;00m(node_list: List[Value]) -> List[Value]:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Given a list of nodes, return a topological sort list of nodes ending in them.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    A simple algorithm is to do a post-order DFS traversal on the given nodes,\u001b[39;49;00m\n",
            "    \u001b[33m    going backwards based on input edges. Since a node is added to the ordering\u001b[39;49;00m\n",
            "    \u001b[33m    after all its predecessors are traversed due to post-order DFS, we get a topological\u001b[39;49;00m\n",
            "    \u001b[33m    sort.\u001b[39;49;00m\n",
            "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:397: NotImplementedError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1msubmit_new_ops\u001b[0m - NotImplementedError\n",
            "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[31m in 4.25s\u001b[0m\u001b[31m ========================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"new_ops\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2s4v0qR66oW"
      },
      "source": [
        "-----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHN_yL9V66oW"
      },
      "source": [
        "### Convolution forward\n",
        "\n",
        "Implement the forward pass of 2D multi-channel convolution in `ops_mathematic.py`. You should probably refer to [this notebook](https://github.com/dlsyscourse/public_notebooks/blob/main/convolution_implementation.ipynb) from lecture, which implements 2D multi-channel convolution using im2col in numpy.\n",
        "\n",
        "**Note:** Your convolution op should accept tensors in the NHWC format, as in the example above, and weights in the format (kernel_size, kernel_size, input_channels, output_channels).\n",
        "\n",
        "However, you will need to add two additional features. Your convolution function should accept arguments for `padding` (default 0) and `stride` (default 1). For `padding`, you should simply apply your padding function to the spatial dimensions (i.e., axes 1 and 2).\n",
        "\n",
        "Implementing strided convolution should consist of a relatively small set of changes to your plain convolution implementation.\n",
        "\n",
        "We recommend working your way up through the full feature set: Implement convolution without stride first, ensuring you pass some of the tests below, and then add in support for stride."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppXWM3xV66oW",
        "outputId": "f169a567-f03d-4003-a490-0a211cdf10a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: langsmith-0.4.42, typeguard-4.4.4, anyio-4.11.0\n",
            "collected 1803 items / 1769 deselected / 34 selected                           \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape0-W_shape0-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [  2%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape1-W_shape1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  5%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape2-W_shape2-1-2] \u001b[31mFAILED\u001b[0m\u001b[31m [  8%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape3-W_shape3-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 11%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape4-W_shape4-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 14%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape5-W_shape5-2-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 17%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape6-W_shape6-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 20%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape7-W_shape7-2-2] \u001b[31mFAILED\u001b[0m\u001b[31m [ 23%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape8-W_shape8-2-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 26%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape9-W_shape9-2-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 29%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape10-W_shape10-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 32%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape11-W_shape11-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 35%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape12-W_shape12-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 38%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape13-W_shape13-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 41%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape14-W_shape14-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 44%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape15-W_shape15-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 47%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape16-W_shape16-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape0-W_shape0-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 52%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape1-W_shape1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 55%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape2-W_shape2-1-2] \u001b[31mFAILED\u001b[0m\u001b[31m [ 58%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape3-W_shape3-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 61%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape4-W_shape4-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 64%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape5-W_shape5-2-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 67%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape6-W_shape6-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 70%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape7-W_shape7-2-2] \u001b[31mFAILED\u001b[0m\u001b[31m [ 73%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape8-W_shape8-2-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 76%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape9-W_shape9-2-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 79%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape10-W_shape10-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 82%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape11-W_shape11-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 85%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape12-W_shape12-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 88%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape13-W_shape13-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 91%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape14-W_shape14-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 94%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape15-W_shape15-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 97%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape16-W_shape16-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape0-W_shape0-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 1, padding = 0\n",
            "backward = False, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.245844...2.618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]])\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
            "            2.1704152 ,  -0.38803983],\n",
            "        ... [ -4.09374   ,   3.7291534 , -10.551835  , ...,   0.31741843,\n",
            "            0.03223436,   2.0512383 ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "        b          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.245844...2.618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]])\n",
            "        padding    = 0\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048....618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x7c2736e436b0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048....618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x7c2736e436b0>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c2736e40500>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c2736e40500>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x7c2736e436b0>\n",
            "A = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "B = NDArray([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.2458448   -0....71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "B          = NDArray([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.2458448   -0....71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[  4.282669     8.133604    -4.6223483  ...   2.0798197    2.1704152\n",
            "   -0.38803983]\n",
            " [  2.2458448   -0.65650...\n",
            "    0.71487164]\n",
            " [ -4.09374      3.7291534  -10.551835   ...   0.31741843   0.03223436\n",
            "    2.0512383 ]], device=cpu())\n",
            "cols       = NDArray([[ 8.820262    2.000786    4.89369    ... -8.380019    5.7616577\n",
            "   5.3980927 ]\n",
            " [-0.51609427  2.0529926   0.7....3520528\n",
            "   2.6459963 ]\n",
            " [-4.257232   -1.6909163   3.8448386  ... -0.6230901  -0.8482267\n",
            "  -2.2998476 ]], device=cpu())\n",
            "out_h      = 12\n",
            "out_w      = 12\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x7c2736e436b0>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape1-W_shape1-1-1] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 1, padding = 1\n",
            "backward = False, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.245844...2.618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]])\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
            "            2.1704152 ,  -0.38803983],\n",
            "        ... [ -4.09374   ,   3.7291534 , -10.551835  , ...,   0.31741843,\n",
            "            0.03223436,   2.0512383 ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cpu()\n",
            "padding    = 1\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "        b          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.245844...2.618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]])\n",
            "        padding    = 1\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048....618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f6427b0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048....618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x7c264f6427b0>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f642810>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f642810>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x7c264f6427b0>\n",
            "A = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "B = NDArray([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.2458448   -0....71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
            "     0.0000000e+00  0.0000000e+00]\n",
            "   [ 0....  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
            "     0.0000000e+00  0.0000000e+00]]]], device=cpu())\n",
            "B          = NDArray([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.2458448   -0....71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[  4.282669     8.133604    -4.6223483  ...   2.0798197    2.1704152\n",
            "   -0.38803983]\n",
            " [  2.2458448   -0.65650...\n",
            "    0.71487164]\n",
            " [ -4.09374      3.7291534  -10.551835   ...   0.31741843   0.03223436\n",
            "    2.0512383 ]], device=cpu())\n",
            "cols       = NDArray([[ 0.          0.          0.         ... -0.7481727  -2.1757677\n",
            "   9.246319  ]\n",
            " [ 0.          0.          0. ... 0.          0.\n",
            "   0.        ]\n",
            " [ 5.346782   -1.7781421  -5.3473854  ...  0.          0.\n",
            "   0.        ]], device=cpu())\n",
            "out_h      = 14\n",
            "out_w      = 14\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f6427b0>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape2-W_shape2-1-2] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 16), stride = 1, padding = 2\n",
            "backward = False, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[  0.40910086  -0.64982927  11.320294   ...  -0.12077556\n",
            "      1.428692    -5.5845156 ]\n",
            "   [ -6.89178...-1.5437248  -10.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]])\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...5e+00]\n",
            "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]])\n",
            "Z_shape    = (3, 16, 16, 8)\n",
            "_W         = array([[[[  0.40910086,  -0.64982927,  11.320294  , ...,  -0.12077556,\n",
            "            1.428692  ,  -5.5845156 ],\n",
            "        ... [  1.1511405 ,   0.7441038 ,  16.463472  , ...,  -6.8931007 ,\n",
            "           -0.5833115 ,  -2.504636  ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cpu()\n",
            "padding    = 2\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...5e+00]\n",
            "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]])\n",
            "        b          = needle.Tensor([[[[  0.40910086  -0.64982927  11.320294   ...  -0.12077556\n",
            "      1.428692    -5.5845156 ]\n",
            "   [ -6.89178...-1.5437248  -10.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]])\n",
            "        padding    = 2\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048...1.5437248  -10.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f6d5ee0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048...1.5437248  -10.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x7c264f6d5ee0>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f6d4da0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f6d4da0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x7c264f6d5ee0>\n",
            "A = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]], device=cpu())\n",
            "B = NDArray([[[[  0.40910086  -0.64982927  11.320294   ...  -0.12077556\n",
            "      1.428692    -5.5845156 ]\n",
            "   [ -6.891782    -...0.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.  ...     0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]]]], device=cpu())\n",
            "B          = NDArray([[[[  0.40910086  -0.64982927  11.320294   ...  -0.12077556\n",
            "      1.428692    -5.5845156 ]\n",
            "   [ -6.891782    -...0.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[  0.40910086  -0.64982927  11.320294   ...  -0.12077556   1.428692\n",
            "   -5.5845156 ]\n",
            " [ -6.891782    -9.38364 ...8\n",
            "  -10.136281  ]\n",
            " [  1.1511405    0.7441038   16.463472   ...  -6.8931007   -0.5833115\n",
            "   -2.504636  ]], device=cpu())\n",
            "cols       = NDArray([[ 0.          0.          0.         ... -4.8863893   4.750442\n",
            "  -0.75678605]\n",
            " [ 0.          0.          0.  ... 0.          0.\n",
            "   0.        ]\n",
            " [ 6.1036735  -2.0543451  -4.413845   ...  0.          0.\n",
            "   0.        ]], device=cpu())\n",
            "out_h      = 18\n",
            "out_w      = 18\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f6d5ee0>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape3-W_shape3-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 14), stride = 1, padding = 0\n",
            "backward = False, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[ 4.09100860e-01 -6.49829268e-01  1.13202944e+01 ... -5.56089449e+00\n",
            "    -4.84385538e+00 -1.20775558e...5e+00]\n",
            "   [-1.10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]])\n",
            "W_shape    = (3, 3, 8, 14)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...5e+00]\n",
            "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]])\n",
            "Z_shape    = (3, 16, 16, 8)\n",
            "_W         = array([[[[ 4.09100860e-01, -6.49829268e-01,  1.13202944e+01, ...,\n",
            "          -5.56089449e+00, -4.84385538e+00, -1.20775...448557e+00, -7.73867989e+00, ...,\n",
            "          -1.13336074e+00, -1.21658230e+00, -4.79330921e+00]]]],\n",
            "      dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...5e+00]\n",
            "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]])\n",
            "        b          = needle.Tensor([[[[ 4.09100860e-01 -6.49829268e-01  1.13202944e+01 ... -5.56089449e+00\n",
            "    -4.84385538e+00 -1.20775558e...5e+00]\n",
            "   [-1.10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]])\n",
            "        padding    = 0\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048...e+00]\n",
            "   [-1.10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f6932c0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048...e+00]\n",
            "   [-1.10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x7c264f6932c0>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f693560>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f693560>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x7c264f6932c0>\n",
            "A = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]], device=cpu())\n",
            "B = NDArray([[[[ 4.09100860e-01 -6.49829268e-01  1.13202944e+01 ... -5.56089449e+00\n",
            "    -4.84385538e+00 -1.20775558e-01]\n",
            " ...10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]], device=cpu())\n",
            "B          = NDArray([[[[ 4.09100860e-01 -6.49829268e-01  1.13202944e+01 ... -5.56089449e+00\n",
            "    -4.84385538e+00 -1.20775558e-01]\n",
            " ...10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[ 0.40910086 -0.64982927 11.320294   ... -5.5608945  -4.8438554\n",
            "  -0.12077556]\n",
            " [ 1.428692   -5.5845156  -6.8...6.206461\n",
            "   7.476679  ]\n",
            " [-1.1071408   2.5444856  -7.73868    ... -1.1333607  -1.2165823\n",
            "  -4.793309  ]], device=cpu())\n",
            "cols       = NDArray([[  8.820262     2.000786     4.89369    ...  -0.5805197  -10.153422\n",
            "   10.322464  ]\n",
            " [ -0.51609427   2.052992...6\n",
            "   -3.4337142 ]\n",
            " [ -1.0374745    1.4560792    4.767398   ...  -6.1524563    3.3351467\n",
            "   -1.3563056 ]], device=cpu())\n",
            "out_h      = 14\n",
            "out_w      = 14\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f6932c0>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape4-W_shape4-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 2), W_shape = (3, 3, 2, 14), stride = 1, padding = 0\n",
            "backward = False, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
            "     -0.28521433   4.383634    -9.13...727333   0.22582927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]])\n",
            "W_shape    = (3, 3, 2, 14)\n",
            "Z          = needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   [...   -5.112822  ]\n",
            "   ...\n",
            "   [ -7.922368     4.2222714 ]\n",
            "   [ -6.064339     1.4188478 ]\n",
            "   [ -1.4109794   -5.791016  ]]]])\n",
            "Z_shape    = (3, 16, 16, 2)\n",
            "_W         = array([[[[ -8.0968    ,  -2.5552022 ,   8.703147  ,  -1.4674252 ,\n",
            "            4.5861077 ,  -0.28521433,   4.383634  , ...        -8.13161   ,  -0.67411226,  -2.9204676 ,   1.675528  ,\n",
            "          -12.187821  ,   5.5746226 ]]]], dtype=float32)\n",
            "_Z         = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "backward   = False\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   [...   -5.112822  ]\n",
            "   ...\n",
            "   [ -7.922368     4.2222714 ]\n",
            "   [ -6.064339     1.4188478 ]\n",
            "   [ -1.4109794   -5.791016  ]]]])\n",
            "        b          = needle.Tensor([[[[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
            "     -0.28521433   4.383634    -9.13...727333   0.22582927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]])\n",
            "        padding    = 0\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   ...27333   0.22582927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f6f55b0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   ...27333   0.22582927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x7c264f6f55b0>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f6f4650>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f6f4650>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x7c264f6f55b0>\n",
            "A = NDArray([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   [  0.22...]\n",
            "   ...\n",
            "   [ -7.922368     4.2222714 ]\n",
            "   [ -6.064339     1.4188478 ]\n",
            "   [ -1.4109794   -5.791016  ]]]], device=cpu())\n",
            "B = NDArray([[[[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
            "     -0.28521433   4.383634    -9.134557  ...82927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   [  0.22...]\n",
            "   ...\n",
            "   [ -7.922368     4.2222714 ]\n",
            "   [ -6.064339     1.4188478 ]\n",
            "   [ -1.4109794   -5.791016  ]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   [  0.22...]\n",
            "   ...\n",
            "   [ -7.922368     4.2222714 ]\n",
            "   [ -6.064339     1.4188478 ]\n",
            "   [ -1.4109794   -5.791016  ]]]], device=cpu())\n",
            "B          = NDArray([[[[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
            "     -0.28521433   4.383634    -9.134557  ...82927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
            "   -0.28521433   4.383634    -9.134557    -2....22582927   9.296732    -8.13161     -0.67411226\n",
            "   -2.9204676    1.675528   -12.187821     5.5746226 ]], device=cpu())\n",
            "cols       = NDArray([[ 8.820262    2.000786    4.89369    ...  2.3139112  -4.536492\n",
            "   0.25972697]\n",
            " [ 4.89369    11.204466    9.33...6.064339\n",
            "   1.4188478 ]\n",
            " [ 0.3375843   3.8880208  -0.17871366 ...  1.4188478  -1.4109794\n",
            "  -5.791016  ]], device=cpu())\n",
            "out_h      = 14\n",
            "out_w      = 14\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f6f55b0>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape5-W_shape5-2-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 2, padding = 0\n",
            "backward = False, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.245844...2.618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]])\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
            "            2.1704152 ,  -0.38803983],\n",
            "        ... [ -4.09374   ,   3.7291534 , -10.551835  , ...,   0.31741843,\n",
            "            0.03223436,   2.0512383 ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "        b          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.245844...2.618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]])\n",
            "        padding    = 0\n",
            "        stride     = 2\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048....618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f6f6660>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048....618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x7c264f6f6660>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f6f6ea0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f6f6ea0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x7c264f6f6660>\n",
            "A = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "B = NDArray([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.2458448   -0....71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "B          = NDArray([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.2458448   -0....71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[  4.282669     8.133604    -4.6223483  ...   2.0798197    2.1704152\n",
            "   -0.38803983]\n",
            " [  2.2458448   -0.65650...\n",
            "    0.71487164]\n",
            " [ -4.09374      3.7291534  -10.551835   ...   0.31741843   0.03223436\n",
            "    2.0512383 ]], device=cpu())\n",
            "cols       = NDArray([[  8.820262     2.000786     4.89369    ...  -8.380019     5.7616577\n",
            "    5.3980927 ]\n",
            " [  7.4703956   -1.02579...56\n",
            "    6.0469246 ]\n",
            " [  1.1145538  -14.462599     1.6968298  ...   2.5371516  -10.818328\n",
            "    1.5426137 ]], device=cpu())\n",
            "out_h      = 6\n",
            "out_w      = 6\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f6f6660>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape6-W_shape6-2-1] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 2, padding = 1\n",
            "backward = False, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.245844...2.618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]])\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
            "            2.1704152 ,  -0.38803983],\n",
            "        ... [ -4.09374   ,   3.7291534 , -10.551835  , ...,   0.31741843,\n",
            "            0.03223436,   2.0512383 ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cpu()\n",
            "padding    = 1\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "        b          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.245844...2.618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]])\n",
            "        padding    = 1\n",
            "        stride     = 2\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048....618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f664b90>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048....618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x7c264f664b90>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f666a80>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f666a80>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x7c264f664b90>\n",
            "A = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "B = NDArray([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.2458448   -0....71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
            "     0.0000000e+00  0.0000000e+00]\n",
            "   [ 0....  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
            "     0.0000000e+00  0.0000000e+00]]]], device=cpu())\n",
            "B          = NDArray([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.2458448   -0....71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[  4.282669     8.133604    -4.6223483  ...   2.0798197    2.1704152\n",
            "   -0.38803983]\n",
            " [  2.2458448   -0.65650...\n",
            "    0.71487164]\n",
            " [ -4.09374      3.7291534  -10.551835   ...   0.31741843   0.03223436\n",
            "    2.0512383 ]], device=cpu())\n",
            "cols       = NDArray([[ 0.          0.          0.         ... -0.7481727  -2.1757677\n",
            "   9.246319  ]\n",
            " [ 0.          0.          0. ...49081123\n",
            "  -5.8721123 ]\n",
            " [-4.257232   -1.6909163   3.8448386  ... -0.6230901  -0.8482267\n",
            "  -2.2998476 ]], device=cpu())\n",
            "out_h      = 7\n",
            "out_w      = 7\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f664b90>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape7-W_shape7-2-2] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 16), stride = 2, padding = 2\n",
            "backward = False, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[  0.40910086  -0.64982927  11.320294   ...  -0.12077556\n",
            "      1.428692    -5.5845156 ]\n",
            "   [ -6.89178...-1.5437248  -10.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]])\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...5e+00]\n",
            "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]])\n",
            "Z_shape    = (3, 16, 16, 8)\n",
            "_W         = array([[[[  0.40910086,  -0.64982927,  11.320294  , ...,  -0.12077556,\n",
            "            1.428692  ,  -5.5845156 ],\n",
            "        ... [  1.1511405 ,   0.7441038 ,  16.463472  , ...,  -6.8931007 ,\n",
            "           -0.5833115 ,  -2.504636  ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cpu()\n",
            "padding    = 2\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...5e+00]\n",
            "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]])\n",
            "        b          = needle.Tensor([[[[  0.40910086  -0.64982927  11.320294   ...  -0.12077556\n",
            "      1.428692    -5.5845156 ]\n",
            "   [ -6.89178...-1.5437248  -10.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]])\n",
            "        padding    = 2\n",
            "        stride     = 2\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048...1.5437248  -10.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f6420f0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048...1.5437248  -10.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x7c264f6420f0>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f6414f0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f6414f0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x7c264f6420f0>\n",
            "A = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]], device=cpu())\n",
            "B = NDArray([[[[  0.40910086  -0.64982927  11.320294   ...  -0.12077556\n",
            "      1.428692    -5.5845156 ]\n",
            "   [ -6.891782    -...0.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.  ...     0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]]]], device=cpu())\n",
            "B          = NDArray([[[[  0.40910086  -0.64982927  11.320294   ...  -0.12077556\n",
            "      1.428692    -5.5845156 ]\n",
            "   [ -6.891782    -...0.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[  0.40910086  -0.64982927  11.320294   ...  -0.12077556   1.428692\n",
            "   -5.5845156 ]\n",
            " [ -6.891782    -9.38364 ...8\n",
            "  -10.136281  ]\n",
            " [  1.1511405    0.7441038   16.463472   ...  -6.8931007   -0.5833115\n",
            "   -2.504636  ]], device=cpu())\n",
            "cols       = NDArray([[ 0.          0.          0.         ... -4.8863893   4.750442\n",
            "  -0.75678605]\n",
            " [ 0.          0.          0.  ... 0.          0.\n",
            "   0.        ]\n",
            " [10.212681   -4.597306    0.57335013 ...  0.          0.\n",
            "   0.        ]], device=cpu())\n",
            "out_h      = 9\n",
            "out_w      = 9\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f6420f0>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape8-W_shape8-2-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 14), stride = 2, padding = 0\n",
            "backward = False, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[ 4.09100860e-01 -6.49829268e-01  1.13202944e+01 ... -5.56089449e+00\n",
            "    -4.84385538e+00 -1.20775558e...5e+00]\n",
            "   [-1.10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]])\n",
            "W_shape    = (3, 3, 8, 14)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...5e+00]\n",
            "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]])\n",
            "Z_shape    = (3, 16, 16, 8)\n",
            "_W         = array([[[[ 4.09100860e-01, -6.49829268e-01,  1.13202944e+01, ...,\n",
            "          -5.56089449e+00, -4.84385538e+00, -1.20775...448557e+00, -7.73867989e+00, ...,\n",
            "          -1.13336074e+00, -1.21658230e+00, -4.79330921e+00]]]],\n",
            "      dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...5e+00]\n",
            "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]])\n",
            "        b          = needle.Tensor([[[[ 4.09100860e-01 -6.49829268e-01  1.13202944e+01 ... -5.56089449e+00\n",
            "    -4.84385538e+00 -1.20775558e...5e+00]\n",
            "   [-1.10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]])\n",
            "        padding    = 0\n",
            "        stride     = 2\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048...e+00]\n",
            "   [-1.10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f6b9880>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048...e+00]\n",
            "   [-1.10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x7c264f6b9880>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f6bbe90>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f6bbe90>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x7c264f6b9880>\n",
            "A = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]], device=cpu())\n",
            "B = NDArray([[[[ 4.09100860e-01 -6.49829268e-01  1.13202944e+01 ... -5.56089449e+00\n",
            "    -4.84385538e+00 -1.20775558e-01]\n",
            " ...10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]], device=cpu())\n",
            "B          = NDArray([[[[ 4.09100860e-01 -6.49829268e-01  1.13202944e+01 ... -5.56089449e+00\n",
            "    -4.84385538e+00 -1.20775558e-01]\n",
            " ...10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[ 0.40910086 -0.64982927 11.320294   ... -5.5608945  -4.8438554\n",
            "  -0.12077556]\n",
            " [ 1.428692   -5.5845156  -6.8...6.206461\n",
            "   7.476679  ]\n",
            " [-1.1071408   2.5444856  -7.73868    ... -1.1333607  -1.2165823\n",
            "  -4.793309  ]], device=cpu())\n",
            "cols       = NDArray([[  8.820262     2.000786     4.89369    ...  -0.5805197  -10.153422\n",
            "   10.322464  ]\n",
            " [  7.4703956   -1.025791...7\n",
            "   -0.05607079]\n",
            " [ -0.1376712   -1.7998276   -1.3146799  ...  -1.3081918   -6.4312043\n",
            "   -8.273288  ]], device=cpu())\n",
            "out_h      = 7\n",
            "out_w      = 7\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f6b9880>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape9-W_shape9-2-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 2), W_shape = (3, 3, 2, 14), stride = 2, padding = 0\n",
            "backward = False, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
            "     -0.28521433   4.383634    -9.13...727333   0.22582927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]])\n",
            "W_shape    = (3, 3, 2, 14)\n",
            "Z          = needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   [...   -5.112822  ]\n",
            "   ...\n",
            "   [ -7.922368     4.2222714 ]\n",
            "   [ -6.064339     1.4188478 ]\n",
            "   [ -1.4109794   -5.791016  ]]]])\n",
            "Z_shape    = (3, 16, 16, 2)\n",
            "_W         = array([[[[ -8.0968    ,  -2.5552022 ,   8.703147  ,  -1.4674252 ,\n",
            "            4.5861077 ,  -0.28521433,   4.383634  , ...        -8.13161   ,  -0.67411226,  -2.9204676 ,   1.675528  ,\n",
            "          -12.187821  ,   5.5746226 ]]]], dtype=float32)\n",
            "_Z         = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "backward   = False\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   [...   -5.112822  ]\n",
            "   ...\n",
            "   [ -7.922368     4.2222714 ]\n",
            "   [ -6.064339     1.4188478 ]\n",
            "   [ -1.4109794   -5.791016  ]]]])\n",
            "        b          = needle.Tensor([[[[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
            "     -0.28521433   4.383634    -9.13...727333   0.22582927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]])\n",
            "        padding    = 0\n",
            "        stride     = 2\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   ...27333   0.22582927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f640590>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   ...27333   0.22582927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x7c264f640590>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f641250>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f641250>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x7c264f640590>\n",
            "A = NDArray([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   [  0.22...]\n",
            "   ...\n",
            "   [ -7.922368     4.2222714 ]\n",
            "   [ -6.064339     1.4188478 ]\n",
            "   [ -1.4109794   -5.791016  ]]]], device=cpu())\n",
            "B = NDArray([[[[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
            "     -0.28521433   4.383634    -9.134557  ...82927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   [  0.22...]\n",
            "   ...\n",
            "   [ -7.922368     4.2222714 ]\n",
            "   [ -6.064339     1.4188478 ]\n",
            "   [ -1.4109794   -5.791016  ]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   [  0.22...]\n",
            "   ...\n",
            "   [ -7.922368     4.2222714 ]\n",
            "   [ -6.064339     1.4188478 ]\n",
            "   [ -1.4109794   -5.791016  ]]]], device=cpu())\n",
            "B          = NDArray([[[[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
            "     -0.28521433   4.383634    -9.134557  ...82927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
            "   -0.28521433   4.383634    -9.134557    -2....22582927   9.296732    -8.13161     -0.67411226\n",
            "   -2.9204676    1.675528   -12.187821     5.5746226 ]], device=cpu())\n",
            "cols       = NDArray([[ 8.820262    2.000786    4.89369    ...  2.3139112  -4.536492\n",
            "   0.25972697]\n",
            " [ 9.33779    -4.8863893   4.75...1964829\n",
            "  -1.2339678 ]\n",
            " [-6.875922    2.5049613  -2.401245   ... -0.5711278   0.06619884\n",
            "  -0.60972464]], device=cpu())\n",
            "out_h      = 7\n",
            "out_w      = 7\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f640590>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape10-W_shape10-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 24), W_shape = (3, 3, 24, 14), stride = 1, padding = 0\n",
            "backward = False, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[ -1.3245817    1.0111231   -1.9236585  ...  -2.5907016\n",
            "     -0.36175704   4.6234684 ]\n",
            "   [  5.279258... -4.82095      4.98517   ]\n",
            "   [  3.2300415   -2.4161792   -3.420825   ...  -9.444658\n",
            "      8.537833     2.3818388 ]]]])\n",
            "W_shape    = (3, 3, 24, 14)\n",
            "Z          = needle.Tensor([[[[  8.820262     2.000786     4.89369    ...   3.2680929\n",
            "      4.322181    -3.7108252 ]\n",
            "   [ 11.348773...4.207389     8.935435  ]\n",
            "   [  2.5084004    3.1399443   -0.12958507 ...   0.13740699\n",
            "     -1.400853     0.07475674]]]])\n",
            "Z_shape    = (3, 16, 16, 24)\n",
            "_W         = array([[[[ -1.3245817 ,   1.0111231 ,  -1.9236585 , ...,  -2.5907016 ,\n",
            "           -0.36175704,   4.6234684 ],\n",
            "        ... [  3.2300415 ,  -2.4161792 ,  -3.420825  , ...,  -9.444658  ,\n",
            "            8.537833  ,   2.3818388 ]]]], dtype=float32)\n",
            "_Z         = array([[[[  8.820262  ,   2.000786  ,   4.89369   , ...,   3.2680929 ,\n",
            "            4.322181  ,  -3.7108252 ],\n",
            "        ... [  2.5084004 ,   3.1399443 ,  -0.12958507, ...,   0.13740699,\n",
            "           -1.400853  ,   0.07475674]]]], dtype=float32)\n",
            "backward   = False\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[  8.820262     2.000786     4.89369    ...   3.2680929\n",
            "      4.322181    -3.7108252 ]\n",
            "   [ 11.348773...4.207389     8.935435  ]\n",
            "   [  2.5084004    3.1399443   -0.12958507 ...   0.13740699\n",
            "     -1.400853     0.07475674]]]])\n",
            "        b          = needle.Tensor([[[[ -1.3245817    1.0111231   -1.9236585  ...  -2.5907016\n",
            "     -0.36175704   4.6234684 ]\n",
            "   [  5.279258... -4.82095      4.98517   ]\n",
            "   [  3.2300415   -2.4161792   -3.420825   ...  -9.444658\n",
            "      8.537833     2.3818388 ]]]])\n",
            "        padding    = 0\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[  8.820262     2.000786     4.89369    ...   3.2680929\n",
            "      4.322181    -3.7108252 ]\n",
            "   [ 11.34877...-4.82095      4.98517   ]\n",
            "   [  3.2300415   -2.4161792   -3.420825   ...  -9.444658\n",
            "      8.537833     2.3818388 ]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x7c2734cfb170>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[  8.820262     2.000786     4.89369    ...   3.2680929\n",
            "      4.322181    -3.7108252 ]\n",
            "   [ 11.34877...-4.82095      4.98517   ]\n",
            "   [  3.2300415   -2.4161792   -3.420825   ...  -9.444658\n",
            "      8.537833     2.3818388 ]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x7c2734cfb170>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c2734cfb440>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c2734cfb440>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x7c2734cfb170>\n",
            "A = NDArray([[[[  8.820262     2.000786     4.89369    ...   3.2680929\n",
            "      4.322181    -3.7108252 ]\n",
            "   [ 11.348773    -7....935435  ]\n",
            "   [  2.5084004    3.1399443   -0.12958507 ...   0.13740699\n",
            "     -1.400853     0.07475674]]]], device=cpu())\n",
            "B = NDArray([[[[ -1.3245817    1.0111231   -1.9236585  ...  -2.5907016\n",
            "     -0.36175704   4.6234684 ]\n",
            "   [  5.2792587   -1... 4.98517   ]\n",
            "   [  3.2300415   -2.4161792   -3.420825   ...  -9.444658\n",
            "      8.537833     2.3818388 ]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[  8.820262     2.000786     4.89369    ...   3.2680929\n",
            "      4.322181    -3.7108252 ]\n",
            "   [ 11.348773    -7....935435  ]\n",
            "   [  2.5084004    3.1399443   -0.12958507 ...   0.13740699\n",
            "     -1.400853     0.07475674]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[  8.820262     2.000786     4.89369    ...   3.2680929\n",
            "      4.322181    -3.7108252 ]\n",
            "   [ 11.348773    -7....935435  ]\n",
            "   [  2.5084004    3.1399443   -0.12958507 ...   0.13740699\n",
            "     -1.400853     0.07475674]]]], device=cpu())\n",
            "B          = NDArray([[[[ -1.3245817    1.0111231   -1.9236585  ...  -2.5907016\n",
            "     -0.36175704   4.6234684 ]\n",
            "   [  5.2792587   -1... 4.98517   ]\n",
            "   [  3.2300415   -2.4161792   -3.420825   ...  -9.444658\n",
            "      8.537833     2.3818388 ]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[-1.3245817   1.0111231  -1.9236585  ... -2.5907016  -0.36175704\n",
            "   4.6234684 ]\n",
            " [ 5.2792587  -1.3089544   0.... -4.82095\n",
            "   4.98517   ]\n",
            " [ 3.2300415  -2.4161792  -3.420825   ... -9.444658    8.537833\n",
            "   2.3818388 ]], device=cpu())\n",
            "cols       = NDArray([[ 8.820262    2.000786    4.89369    ... -1.6283474   2.3521657\n",
            "   1.5572354 ]\n",
            " [11.348773   -7.271828    0.2... 4.207389\n",
            "   8.935435  ]\n",
            " [ 4.376834    6.916924    4.14586    ...  0.13740699 -1.400853\n",
            "   0.07475674]], device=cpu())\n",
            "out_h      = 14\n",
            "out_w      = 14\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x7c2734cfb170>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape11-W_shape11-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (5, 5, 8, 16), stride = 1, padding = 0\n",
            "backward = False, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[ 4.28266907e+00  8.13360405e+00 -4.62234831e+00 ...  2.07981968e+00\n",
            "     2.17041516e+00 -3.88039827e...7e+00]\n",
            "   [-7.86027253e-01  4.30947495e+00 -4.97804356e+00 ... -5.69430470e-01\n",
            "     4.27775383e-01 -3.84437203e+00]]]])\n",
            "W_shape    = (5, 5, 8, 16)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "_W         = array([[[[ 4.28266907e+00,  8.13360405e+00, -4.62234831e+00, ...,\n",
            "           2.07981968e+00,  2.17041516e+00, -3.88039...947495e+00, -4.97804356e+00, ...,\n",
            "          -5.69430470e-01,  4.27775383e-01, -3.84437203e+00]]]],\n",
            "      dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "        b          = needle.Tensor([[[[ 4.28266907e+00  8.13360405e+00 -4.62234831e+00 ...  2.07981968e+00\n",
            "     2.17041516e+00 -3.88039827e...7e+00]\n",
            "   [-7.86027253e-01  4.30947495e+00 -4.97804356e+00 ... -5.69430470e-01\n",
            "     4.27775383e-01 -3.84437203e+00]]]])\n",
            "        padding    = 0\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048...e+00]\n",
            "   [-7.86027253e-01  4.30947495e+00 -4.97804356e+00 ... -5.69430470e-01\n",
            "     4.27775383e-01 -3.84437203e+00]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f6f4d70>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048...e+00]\n",
            "   [-7.86027253e-01  4.30947495e+00 -4.97804356e+00 ... -5.69430470e-01\n",
            "     4.27775383e-01 -3.84437203e+00]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x7c264f6f4d70>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f6f68a0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f6f68a0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x7c264f6f4d70>\n",
            "A = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "B = NDArray([[[[ 4.28266907e+00  8.13360405e+00 -4.62234831e+00 ...  2.07981968e+00\n",
            "     2.17041516e+00 -3.88039827e-01]\n",
            " ...86027253e-01  4.30947495e+00 -4.97804356e+00 ... -5.69430470e-01\n",
            "     4.27775383e-01 -3.84437203e+00]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "B          = NDArray([[[[ 4.28266907e+00  8.13360405e+00 -4.62234831e+00 ...  2.07981968e+00\n",
            "     2.17041516e+00 -3.88039827e-01]\n",
            " ...86027253e-01  4.30947495e+00 -4.97804356e+00 ... -5.69430470e-01\n",
            "     4.27775383e-01 -3.84437203e+00]]]], device=cpu())\n",
            "K          = 5\n",
            "W_col      = NDArray([[ 4.2826691e+00  8.1336040e+00 -4.6223483e+00 ...  2.0798197e+00\n",
            "   2.1704152e+00 -3.8803983e-01]\n",
            " [ 2.245844...+00]\n",
            " [-7.8602725e-01  4.3094749e+00 -4.9780436e+00 ... -5.6943047e-01\n",
            "   4.2777538e-01 -3.8443720e+00]], device=cpu())\n",
            "cols       = NDArray([[  8.820262     2.000786     4.89369    ... -13.278095     7.5666404\n",
            "    2.7656603 ]\n",
            " [ -0.51609427   2.05299...8\n",
            "    2.6459963 ]\n",
            " [ -8.464558     0.2118057    6.9135523  ...  -0.6230901   -0.8482267\n",
            "   -2.2998476 ]], device=cpu())\n",
            "out_h      = 10\n",
            "out_w      = 10\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f6f4d70>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape12-W_shape12-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 17, 17, 8), W_shape = (5, 5, 8, 16), stride = 1, padding = 0\n",
            "backward = False, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[ 5.93117094e+00 -4.61600447e+00 -7.43411541e+00 ...  9.49053860e+00\n",
            "     6.47611380e+00 -3.38525438e...7e+00]\n",
            "   [-3.93575430e+00 -6.98609781e+00  1.63659811e+00 ...  8.22474575e+00\n",
            "     2.56555057e+00  1.63004756e+00]]]])\n",
            "W_shape    = (5, 5, 8, 16)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...8e+00]\n",
            "   [ 2.80155873e+00  3.11298299e+00 -3.24756050e+00 ... -7.96233535e-01\n",
            "     4.72636795e+00 -5.75466204e+00]]]])\n",
            "Z_shape    = (3, 17, 17, 8)\n",
            "_W         = array([[[[ 5.93117094e+00, -4.61600447e+00, -7.43411541e+00, ...,\n",
            "           9.49053860e+00,  6.47611380e+00, -3.38525...609781e+00,  1.63659811e+00, ...,\n",
            "           8.22474575e+00,  2.56555057e+00,  1.63004756e+00]]]],\n",
            "      dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...298299e+00, -3.24756050e+00, ...,\n",
            "          -7.96233535e-01,  4.72636795e+00, -5.75466204e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...8e+00]\n",
            "   [ 2.80155873e+00  3.11298299e+00 -3.24756050e+00 ... -7.96233535e-01\n",
            "     4.72636795e+00 -5.75466204e+00]]]])\n",
            "        b          = needle.Tensor([[[[ 5.93117094e+00 -4.61600447e+00 -7.43411541e+00 ...  9.49053860e+00\n",
            "     6.47611380e+00 -3.38525438e...7e+00]\n",
            "   [-3.93575430e+00 -6.98609781e+00  1.63659811e+00 ...  8.22474575e+00\n",
            "     2.56555057e+00  1.63004756e+00]]]])\n",
            "        padding    = 0\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048...e+00]\n",
            "   [-3.93575430e+00 -6.98609781e+00  1.63659811e+00 ...  8.22474575e+00\n",
            "     2.56555057e+00  1.63004756e+00]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f693080>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048...e+00]\n",
            "   [-3.93575430e+00 -6.98609781e+00  1.63659811e+00 ...  8.22474575e+00\n",
            "     2.56555057e+00  1.63004756e+00]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x7c264f693080>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f6907d0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f6907d0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x7c264f693080>\n",
            "A = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...80155873e+00  3.11298299e+00 -3.24756050e+00 ... -7.96233535e-01\n",
            "     4.72636795e+00 -5.75466204e+00]]]], device=cpu())\n",
            "B = NDArray([[[[ 5.93117094e+00 -4.61600447e+00 -7.43411541e+00 ...  9.49053860e+00\n",
            "     6.47611380e+00 -3.38525438e+00]\n",
            " ...93575430e+00 -6.98609781e+00  1.63659811e+00 ...  8.22474575e+00\n",
            "     2.56555057e+00  1.63004756e+00]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...80155873e+00  3.11298299e+00 -3.24756050e+00 ... -7.96233535e-01\n",
            "     4.72636795e+00 -5.75466204e+00]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...80155873e+00  3.11298299e+00 -3.24756050e+00 ... -7.96233535e-01\n",
            "     4.72636795e+00 -5.75466204e+00]]]], device=cpu())\n",
            "B          = NDArray([[[[ 5.93117094e+00 -4.61600447e+00 -7.43411541e+00 ...  9.49053860e+00\n",
            "     6.47611380e+00 -3.38525438e+00]\n",
            " ...93575430e+00 -6.98609781e+00  1.63659811e+00 ...  8.22474575e+00\n",
            "     2.56555057e+00  1.63004756e+00]]]], device=cpu())\n",
            "K          = 5\n",
            "W_col      = NDArray([[ 5.931171   -4.6160045  -7.4341154  ...  9.490539    6.476114\n",
            "  -3.3852544 ]\n",
            " [-0.17156623  0.21220385  0.29...0.531189\n",
            "   4.472448  ]\n",
            " [-3.9357543  -6.986098    1.6365981  ...  8.224746    2.5655506\n",
            "   1.6300476 ]], device=cpu())\n",
            "cols       = NDArray([[  8.820262     2.000786     4.89369    ...  -3.2994587   -5.6990123\n",
            "    3.9247875 ]\n",
            " [ -0.51609427   2.05299...17\n",
            "    3.9570265 ]\n",
            " [  3.2858942    3.4523911    4.7947583  ...  -0.79623353   4.726368\n",
            "   -5.754662  ]], device=cpu())\n",
            "out_h      = 13\n",
            "out_w      = 13\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f693080>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape13-W_shape13-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 17, 17, 1), W_shape = (5, 5, 1, 16), stride = 1, padding = 0\n",
            "backward = False, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[  1.5437562   -6.8538       4.3282647    5.4068804   -3.15688\n",
            "     -1.206689    -4.3909516    3.4969...448   -2.242325     0.6578698\n",
            "     -7.0278      -1.7489109   10.11736      2.5269346    1.7962458\n",
            "     -7.9124722 ]]]])\n",
            "W_shape    = (5, 5, 1, 16)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00]\n",
            "   [ 2.00078607e+00]\n",
            "   [ 4.89369011e+00]\n",
            "   [ 1.12044659e+01]\n",
            "   [ 9.33778954e+00]...22066e-01]\n",
            "   [ 1.05310105e-01]\n",
            "   [ 4.97272283e-01]\n",
            "   [ 1.13696384e+00]\n",
            "   [-5.08369303e+00]\n",
            "   [-5.73876619e-01]]]])\n",
            "Z_shape    = (3, 17, 17, 1)\n",
            "_W         = array([[[[  1.5437562 ,  -6.8538    ,   4.3282647 ,   5.4068804 ,\n",
            "           -3.15688   ,  -1.206689  ,  -4.3909516 , ...  -7.0278    ,  -1.7489109 ,\n",
            "           10.11736   ,   2.5269346 ,   1.7962458 ,  -7.9124722 ]]]],\n",
            "      dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00],\n",
            "         [ 2.00078607e+00],\n",
            "         [ 4.89369011e+00],\n",
            "         [ 1.12044659e+01],\n",
            "      ... 4.97272283e-01],\n",
            "         [ 1.13696384e+00],\n",
            "         [-5.08369303e+00],\n",
            "         [-5.73876619e-01]]]], dtype=float32)\n",
            "backward   = False\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00]\n",
            "   [ 2.00078607e+00]\n",
            "   [ 4.89369011e+00]\n",
            "   [ 1.12044659e+01]\n",
            "   [ 9.33778954e+00]...22066e-01]\n",
            "   [ 1.05310105e-01]\n",
            "   [ 4.97272283e-01]\n",
            "   [ 1.13696384e+00]\n",
            "   [-5.08369303e+00]\n",
            "   [-5.73876619e-01]]]])\n",
            "        b          = needle.Tensor([[[[  1.5437562   -6.8538       4.3282647    5.4068804   -3.15688\n",
            "     -1.206689    -4.3909516    3.4969...448   -2.242325     0.6578698\n",
            "     -7.0278      -1.7489109   10.11736      2.5269346    1.7962458\n",
            "     -7.9124722 ]]]])\n",
            "        padding    = 0\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00]\n",
            "   [ 2.00078607e+00]\n",
            "   [ 4.89369011e+00]\n",
            "   [ 1.12044659e+01]\n",
            "   [ 9.33778954e+00...48   -2.242325     0.6578698\n",
            "     -7.0278      -1.7489109   10.11736      2.5269346    1.7962458\n",
            "     -7.9124722 ]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f641d30>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00]\n",
            "   [ 2.00078607e+00]\n",
            "   [ 4.89369011e+00]\n",
            "   [ 1.12044659e+01]\n",
            "   [ 9.33778954e+00...48   -2.242325     0.6578698\n",
            "     -7.0278      -1.7489109   10.11736      2.5269346    1.7962458\n",
            "     -7.9124722 ]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x7c264f641d30>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f641340>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f641340>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x7c264f641d30>\n",
            "A = NDArray([[[[ 8.82026196e+00]\n",
            "   [ 2.00078607e+00]\n",
            "   [ 4.89369011e+00]\n",
            "   [ 1.12044659e+01]\n",
            "   [ 9.33778954e+00]\n",
            "   [-...[ 1.05310105e-01]\n",
            "   [ 4.97272283e-01]\n",
            "   [ 1.13696384e+00]\n",
            "   [-5.08369303e+00]\n",
            "   [-5.73876619e-01]]]], device=cpu())\n",
            "B = NDArray([[[[  1.5437562   -6.8538       4.3282647    5.4068804   -3.15688\n",
            "     -1.206689    -4.3909516    3.4969025   ...5     0.6578698\n",
            "     -7.0278      -1.7489109   10.11736      2.5269346    1.7962458\n",
            "     -7.9124722 ]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00]\n",
            "   [ 2.00078607e+00]\n",
            "   [ 4.89369011e+00]\n",
            "   [ 1.12044659e+01]\n",
            "   [ 9.33778954e+00]\n",
            "   [-...[ 1.05310105e-01]\n",
            "   [ 4.97272283e-01]\n",
            "   [ 1.13696384e+00]\n",
            "   [-5.08369303e+00]\n",
            "   [-5.73876619e-01]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 8.82026196e+00]\n",
            "   [ 2.00078607e+00]\n",
            "   [ 4.89369011e+00]\n",
            "   [ 1.12044659e+01]\n",
            "   [ 9.33778954e+00]\n",
            "   [-...[ 1.05310105e-01]\n",
            "   [ 4.97272283e-01]\n",
            "   [ 1.13696384e+00]\n",
            "   [-5.08369303e+00]\n",
            "   [-5.73876619e-01]]]], device=cpu())\n",
            "B          = NDArray([[[[  1.5437562   -6.8538       4.3282647    5.4068804   -3.15688\n",
            "     -1.206689    -4.3909516    3.4969025   ...5     0.6578698\n",
            "     -7.0278      -1.7489109   10.11736      2.5269346    1.7962458\n",
            "     -7.9124722 ]]]], device=cpu())\n",
            "K          = 5\n",
            "W_col      = NDArray([[  1.5437562   -6.8538       4.3282647    5.4068804   -3.15688\n",
            "   -1.206689    -4.3909516    3.4969025   -5.3....242325     0.6578698\n",
            "   -7.0278      -1.7489109   10.11736      2.5269346    1.7962458\n",
            "   -7.9124722 ]], device=cpu())\n",
            "cols       = NDArray([[ 8.820262    2.000786    4.89369    ...  3.6454527   0.64491457\n",
            "   5.6970034 ]\n",
            " [ 2.000786    4.89369    11....1.1369638\n",
            "  -5.083693  ]\n",
            " [-4.294862   -4.494711    0.37293205 ...  1.1369638  -5.083693\n",
            "  -0.5738766 ]], device=cpu())\n",
            "out_h      = 13\n",
            "out_w      = 13\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f641d30>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape14-W_shape14-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 17, 17, 16), W_shape = (5, 5, 16, 1), stride = 1, padding = 0\n",
            "backward = False, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[ 1.55579513e-02]\n",
            "   [-3.04658723e+00]\n",
            "   [ 4.09725952e+00]\n",
            "   [ 1.29906273e+00]\n",
            "   [-7.50546598e+00]...75421e+00]\n",
            "   [ 3.02805209e+00]\n",
            "   [-4.20992136e+00]\n",
            "   [ 4.11707735e+00]\n",
            "   [ 4.99041653e+00]\n",
            "   [ 5.11040497e+00]]]])\n",
            "W_shape    = (5, 5, 16, 1)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168e...3e+00]\n",
            "   [-1.25365603e+00 -1.71452928e+00  1.35930243e+01 ...  3.13170171e+00\n",
            "    -1.35708165e+00  1.29997072e+01]]]])\n",
            "Z_shape    = (3, 17, 17, 16)\n",
            "_W         = array([[[[ 1.55579513e-02],\n",
            "         [-3.04658723e+00],\n",
            "         [ 4.09725952e+00],\n",
            "         [ 1.29906273e+00],\n",
            "      ...-4.20992136e+00],\n",
            "         [ 4.11707735e+00],\n",
            "         [ 4.99041653e+00],\n",
            "         [ 5.11040497e+00]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "           6.08375072e-01,  2.21931624e+00,  1.66837...452928e+00,  1.35930243e+01, ...,\n",
            "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168e...3e+00]\n",
            "   [-1.25365603e+00 -1.71452928e+00  1.35930243e+01 ...  3.13170171e+00\n",
            "    -1.35708165e+00  1.29997072e+01]]]])\n",
            "        b          = needle.Tensor([[[[ 1.55579513e-02]\n",
            "   [-3.04658723e+00]\n",
            "   [ 4.09725952e+00]\n",
            "   [ 1.29906273e+00]\n",
            "   [-7.50546598e+00]...75421e+00]\n",
            "   [ 3.02805209e+00]\n",
            "   [-4.20992136e+00]\n",
            "   [ 4.11707735e+00]\n",
            "   [ 4.99041653e+00]\n",
            "   [ 5.11040497e+00]]]])\n",
            "        padding    = 0\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168...5421e+00]\n",
            "   [ 3.02805209e+00]\n",
            "   [-4.20992136e+00]\n",
            "   [ 4.11707735e+00]\n",
            "   [ 4.99041653e+00]\n",
            "   [ 5.11040497e+00]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f491e50>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168...5421e+00]\n",
            "   [ 3.02805209e+00]\n",
            "   [-4.20992136e+00]\n",
            "   [ 4.11707735e+00]\n",
            "   [ 4.99041653e+00]\n",
            "   [ 5.11040497e+00]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x7c264f491e50>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f491430>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f491430>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x7c264f491e50>\n",
            "A = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168e+00]\n",
            " ...25365603e+00 -1.71452928e+00  1.35930243e+01 ...  3.13170171e+00\n",
            "    -1.35708165e+00  1.29997072e+01]]]], device=cpu())\n",
            "B = NDArray([[[[ 1.55579513e-02]\n",
            "   [-3.04658723e+00]\n",
            "   [ 4.09725952e+00]\n",
            "   [ 1.29906273e+00]\n",
            "   [-7.50546598e+00]\n",
            "   [-...[ 3.02805209e+00]\n",
            "   [-4.20992136e+00]\n",
            "   [ 4.11707735e+00]\n",
            "   [ 4.99041653e+00]\n",
            "   [ 5.11040497e+00]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168e+00]\n",
            " ...25365603e+00 -1.71452928e+00  1.35930243e+01 ...  3.13170171e+00\n",
            "    -1.35708165e+00  1.29997072e+01]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168e+00]\n",
            " ...25365603e+00 -1.71452928e+00  1.35930243e+01 ...  3.13170171e+00\n",
            "    -1.35708165e+00  1.29997072e+01]]]], device=cpu())\n",
            "B          = NDArray([[[[ 1.55579513e-02]\n",
            "   [-3.04658723e+00]\n",
            "   [ 4.09725952e+00]\n",
            "   [ 1.29906273e+00]\n",
            "   [-7.50546598e+00]\n",
            "   [-...[ 3.02805209e+00]\n",
            "   [-4.20992136e+00]\n",
            "   [ 4.11707735e+00]\n",
            "   [ 4.99041653e+00]\n",
            "   [ 5.11040497e+00]]]], device=cpu())\n",
            "K          = 5\n",
            "W_col      = NDArray([[ 1.55579513e-02]\n",
            " [-3.04658723e+00]\n",
            " [ 4.09725952e+00]\n",
            " [ 1.29906273e+00]\n",
            " [-7.50546598e+00]\n",
            " [-1.73352385e+...421e+00]\n",
            " [ 3.02805209e+00]\n",
            " [-4.20992136e+00]\n",
            " [ 4.11707735e+00]\n",
            " [ 4.99041653e+00]\n",
            " [ 5.11040497e+00]], device=cpu())\n",
            "cols       = NDArray([[  8.820262    2.000786    4.89369   ...   1.635331    8.157988\n",
            "    1.8887959]\n",
            " [  7.4703956  -1.0257913   1....2434509\n",
            "    3.5898256]\n",
            " [  5.264912    6.3784637  -2.9336812 ...   3.1317017  -1.3570817\n",
            "   12.999707 ]], device=cpu())\n",
            "out_h      = 13\n",
            "out_w      = 13\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f491e50>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape15-W_shape15-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 17, 17, 16), W_shape = (1, 1, 16, 1), stride = 1, padding = 0\n",
            "backward = False, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[ 0.01555795]\n",
            "   [-3.0465872 ]\n",
            "   [ 4.0972595 ]\n",
            "   [ 1.2990627 ]\n",
            "   [-7.505466  ]\n",
            "   [-1.7335238 ]\n",
            "  ...[ 5.6893935 ]\n",
            "   [ 2.267663  ]\n",
            "   [-1.0709513 ]\n",
            "   [-5.0566583 ]\n",
            "   [-0.23777105]\n",
            "   [-9.931785  ]\n",
            "   [-0.44905776]]]])\n",
            "W_shape    = (1, 1, 16, 1)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168e...3e+00]\n",
            "   [-1.25365603e+00 -1.71452928e+00  1.35930243e+01 ...  3.13170171e+00\n",
            "    -1.35708165e+00  1.29997072e+01]]]])\n",
            "Z_shape    = (3, 17, 17, 16)\n",
            "_W         = array([[[[ 0.01555795],\n",
            "         [-3.0465872 ],\n",
            "         [ 4.0972595 ],\n",
            "         [ 1.2990627 ],\n",
            "         [-7.505466  ]...13 ],\n",
            "         [-5.0566583 ],\n",
            "         [-0.23777105],\n",
            "         [-9.931785  ],\n",
            "         [-0.44905776]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "           6.08375072e-01,  2.21931624e+00,  1.66837...452928e+00,  1.35930243e+01, ...,\n",
            "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168e...3e+00]\n",
            "   [-1.25365603e+00 -1.71452928e+00  1.35930243e+01 ...  3.13170171e+00\n",
            "    -1.35708165e+00  1.29997072e+01]]]])\n",
            "        b          = needle.Tensor([[[[ 0.01555795]\n",
            "   [-3.0465872 ]\n",
            "   [ 4.0972595 ]\n",
            "   [ 1.2990627 ]\n",
            "   [-7.505466  ]\n",
            "   [-1.7335238 ]\n",
            "  ...[ 5.6893935 ]\n",
            "   [ 2.267663  ]\n",
            "   [-1.0709513 ]\n",
            "   [-5.0566583 ]\n",
            "   [-0.23777105]\n",
            "   [-9.931785  ]\n",
            "   [-0.44905776]]]])\n",
            "        padding    = 0\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168... 5.6893935 ]\n",
            "   [ 2.267663  ]\n",
            "   [-1.0709513 ]\n",
            "   [-5.0566583 ]\n",
            "   [-0.23777105]\n",
            "   [-9.931785  ]\n",
            "   [-0.44905776]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f6400e0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168... 5.6893935 ]\n",
            "   [ 2.267663  ]\n",
            "   [-1.0709513 ]\n",
            "   [-5.0566583 ]\n",
            "   [-0.23777105]\n",
            "   [-9.931785  ]\n",
            "   [-0.44905776]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x7c264f6400e0>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f643230>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f643230>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x7c264f6400e0>\n",
            "A = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168e+00]\n",
            " ...25365603e+00 -1.71452928e+00  1.35930243e+01 ...  3.13170171e+00\n",
            "    -1.35708165e+00  1.29997072e+01]]]], device=cpu())\n",
            "B = NDArray([[[[ 0.01555795]\n",
            "   [-3.0465872 ]\n",
            "   [ 4.0972595 ]\n",
            "   [ 1.2990627 ]\n",
            "   [-7.505466  ]\n",
            "   [-1.7335238 ]\n",
            "   [-2.5...   [ 2.267663  ]\n",
            "   [-1.0709513 ]\n",
            "   [-5.0566583 ]\n",
            "   [-0.23777105]\n",
            "   [-9.931785  ]\n",
            "   [-0.44905776]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168e+00]\n",
            " ...25365603e+00 -1.71452928e+00  1.35930243e+01 ...  3.13170171e+00\n",
            "    -1.35708165e+00  1.29997072e+01]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168e+00]\n",
            " ...25365603e+00 -1.71452928e+00  1.35930243e+01 ...  3.13170171e+00\n",
            "    -1.35708165e+00  1.29997072e+01]]]], device=cpu())\n",
            "B          = NDArray([[[[ 0.01555795]\n",
            "   [-3.0465872 ]\n",
            "   [ 4.0972595 ]\n",
            "   [ 1.2990627 ]\n",
            "   [-7.505466  ]\n",
            "   [-1.7335238 ]\n",
            "   [-2.5...   [ 2.267663  ]\n",
            "   [-1.0709513 ]\n",
            "   [-5.0566583 ]\n",
            "   [-0.23777105]\n",
            "   [-9.931785  ]\n",
            "   [-0.44905776]]]], device=cpu())\n",
            "K          = 1\n",
            "W_col      = NDArray([[ 0.01555795]\n",
            " [-3.0465872 ]\n",
            " [ 4.0972595 ]\n",
            " [ 1.2990627 ]\n",
            " [-7.505466  ]\n",
            " [-1.7335238 ]\n",
            " [-2.5728364 ]\n",
            " [ 4....[ 5.6893935 ]\n",
            " [ 2.267663  ]\n",
            " [-1.0709513 ]\n",
            " [-5.0566583 ]\n",
            " [-0.23777105]\n",
            " [-9.931785  ]\n",
            " [-0.44905776]], device=cpu())\n",
            "cols       = NDArray([[ 8.820262   2.000786   4.89369   ...  0.6083751  2.2193162  1.6683717]\n",
            " [ 7.4703956 -1.0257913  1.5653385 .....3207941  2.2434509  3.5898256]\n",
            " [-1.253656  -1.7145293 13.593024  ...  3.1317017 -1.3570817 12.999707 ]], device=cpu())\n",
            "out_h      = 17\n",
            "out_w      = 17\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f6400e0>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape16-W_shape16-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (1, 14, 14, 2), W_shape = (3, 3, 2, 2), stride = 1, padding = 0\n",
            "backward = False, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[ -1.7671587   -8.082371  ]\n",
            "   [ -1.4591868   -3.807461  ]]\n",
            "\n",
            "  [[  4.2896194    5.705509  ]\n",
            "   [  7.3...7526     2.911123  ]\n",
            "   [-10.473016     0.61860955]]\n",
            "\n",
            "  [[ -0.65053475   0.46976614]\n",
            "   [  4.7152305  -13.698386  ]]]])\n",
            "W_shape    = (3, 3, 2, 2)\n",
            "Z          = needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   [  4.750...19315276  -8.283575  ]\n",
            "   [ -4.9275537   -7.359175  ]\n",
            "   [  8.240675     0.8211388 ]\n",
            "   [  2.8364513   -1.1133755 ]]]])\n",
            "Z_shape    = (1, 14, 14, 2)\n",
            "_W         = array([[[[ -1.7671587 ,  -8.082371  ],\n",
            "         [ -1.4591868 ,  -3.807461  ]],\n",
            "\n",
            "        [[  4.2896194 ,   5.705509  ],...016  ,   0.61860955]],\n",
            "\n",
            "        [[ -0.65053475,   0.46976614],\n",
            "         [  4.7152305 , -13.698386  ]]]], dtype=float32)\n",
            "_Z         = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...275537 ,  -7.359175  ],\n",
            "         [  8.240675  ,   0.8211388 ],\n",
            "         [  2.8364513 ,  -1.1133755 ]]]], dtype=float32)\n",
            "backward   = False\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   [  4.750...19315276  -8.283575  ]\n",
            "   [ -4.9275537   -7.359175  ]\n",
            "   [  8.240675     0.8211388 ]\n",
            "   [  2.8364513   -1.1133755 ]]]])\n",
            "        b          = needle.Tensor([[[[ -1.7671587   -8.082371  ]\n",
            "   [ -1.4591868   -3.807461  ]]\n",
            "\n",
            "  [[  4.2896194    5.705509  ]\n",
            "   [  7.3...7526     2.911123  ]\n",
            "   [-10.473016     0.61860955]]\n",
            "\n",
            "  [[ -0.65053475   0.46976614]\n",
            "   [  4.7152305  -13.698386  ]]]])\n",
            "        padding    = 0\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   [  4.75...526     2.911123  ]\n",
            "   [-10.473016     0.61860955]]\n",
            "\n",
            "  [[ -0.65053475   0.46976614]\n",
            "   [  4.7152305  -13.698386  ]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f642ae0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   [  4.75...526     2.911123  ]\n",
            "   [-10.473016     0.61860955]]\n",
            "\n",
            "  [[ -0.65053475   0.46976614]\n",
            "   [  4.7152305  -13.698386  ]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x7c264f642ae0>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f640d40>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7c264f640d40>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x7c264f642ae0>\n",
            "A = NDArray([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   [  4.750442   ...83575  ]\n",
            "   [ -4.9275537   -7.359175  ]\n",
            "   [  8.240675     0.8211388 ]\n",
            "   [  2.8364513   -1.1133755 ]]]], device=cpu())\n",
            "B = NDArray([[[[ -1.7671587   -8.082371  ]\n",
            "   [ -1.4591868   -3.807461  ]]\n",
            "\n",
            "  [[  4.2896194    5.705509  ]\n",
            "   [  7.3328934...123  ]\n",
            "   [-10.473016     0.61860955]]\n",
            "\n",
            "  [[ -0.65053475   0.46976614]\n",
            "   [  4.7152305  -13.698386  ]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   [  4.750442   ...83575  ]\n",
            "   [ -4.9275537   -7.359175  ]\n",
            "   [  8.240675     0.8211388 ]\n",
            "   [  2.8364513   -1.1133755 ]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   [  4.750442   ...83575  ]\n",
            "   [ -4.9275537   -7.359175  ]\n",
            "   [  8.240675     0.8211388 ]\n",
            "   [  2.8364513   -1.1133755 ]]]], device=cpu())\n",
            "B          = NDArray([[[[ -1.7671587   -8.082371  ]\n",
            "   [ -1.4591868   -3.807461  ]]\n",
            "\n",
            "  [[  4.2896194    5.705509  ]\n",
            "   [  7.3328934...123  ]\n",
            "   [-10.473016     0.61860955]]\n",
            "\n",
            "  [[ -0.65053475   0.46976614]\n",
            "   [  4.7152305  -13.698386  ]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[ -1.7671587   -8.082371  ]\n",
            " [ -1.4591868   -3.807461  ]\n",
            " [  4.2896194    5.705509  ]\n",
            " [  7.3328934    4.2627...     2.911123  ]\n",
            " [-10.473016     0.61860955]\n",
            " [ -0.65053475   0.46976614]\n",
            " [  4.7152305  -13.698386  ]], device=cpu())\n",
            "cols       = NDArray([[ 8.820262    2.000786    4.89369    ... -1.8137058  -3.3623023\n",
            "  -1.7977659 ]\n",
            " [ 4.89369    11.204466    9.3...8.240675\n",
            "   0.8211388 ]\n",
            " [ 3.7359416  -5.9447246   3.8662648  ...  0.8211388   2.8364513\n",
            "  -1.1133755 ]], device=cpu())\n",
            "out_h      = 12\n",
            "out_w      = 12\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x7c264f642ae0>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape0-W_shape0-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 1, padding = 0\n",
            "backward = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
            "            2.1704152 ,  -0.38803983],\n",
            "        ... [ -4.09374   ,   3.7291534 , -10.551835  , ...,   0.31741843,\n",
            "            0.03223436,   2.0512383 ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c264f490e90>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c264f491520>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 14, 14, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c264f493c50>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 14, 14, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape1-W_shape1-1-1] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 1, padding = 1\n",
            "backward = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
            "            2.1704152 ,  -0.38803983],\n",
            "        ... [ -4.09374   ,   3.7291534 , -10.551835  , ...,   0.31741843,\n",
            "            0.03223436,   2.0512383 ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cuda()\n",
            "padding    = 1\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c264f6f45f0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c264f6f6b10>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 14, 14, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c264f6f7980>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 14, 14, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape2-W_shape2-1-2] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 16), stride = 1, padding = 2\n",
            "backward = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Z_shape    = (3, 16, 16, 8)\n",
            "_W         = array([[[[  0.40910086,  -0.64982927,  11.320294  , ...,  -0.12077556,\n",
            "            1.428692  ,  -5.5845156 ],\n",
            "        ... [  1.1511405 ,   0.7441038 ,  16.463472  , ...,  -6.8931007 ,\n",
            "           -0.5833115 ,  -2.504636  ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cuda()\n",
            "padding    = 2\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c264f5bdc70>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c264f5bd010>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 16, 16, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c264f5bd340>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 16, 16, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape3-W_shape3-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 14), stride = 1, padding = 0\n",
            "backward = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (3, 3, 8, 14)\n",
            "Z_shape    = (3, 16, 16, 8)\n",
            "_W         = array([[[[ 4.09100860e-01, -6.49829268e-01,  1.13202944e+01, ...,\n",
            "          -5.56089449e+00, -4.84385538e+00, -1.20775...448557e+00, -7.73867989e+00, ...,\n",
            "          -1.13336074e+00, -1.21658230e+00, -4.79330921e+00]]]],\n",
            "      dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c264f490fe0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c264f4935f0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 16, 16, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c264f493770>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 16, 16, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape4-W_shape4-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 2), W_shape = (3, 3, 2, 14), stride = 1, padding = 0\n",
            "backward = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (3, 3, 2, 14)\n",
            "Z_shape    = (3, 16, 16, 2)\n",
            "_W         = array([[[[ -8.0968    ,  -2.5552022 ,   8.703147  ,  -1.4674252 ,\n",
            "            4.5861077 ,  -0.28521433,   4.383634  , ...        -8.13161   ,  -0.67411226,  -2.9204676 ,   1.675528  ,\n",
            "          -12.187821  ,   5.5746226 ]]]], dtype=float32)\n",
            "_Z         = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "backward   = False\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c264f6ba210>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c264f6b9730>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 16, 16, 2), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c264f6b8290>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 16, 16, 2)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape5-W_shape5-2-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 2, padding = 0\n",
            "backward = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
            "            2.1704152 ,  -0.38803983],\n",
            "        ... [ -4.09374   ,   3.7291534 , -10.551835  , ...,   0.31741843,\n",
            "            0.03223436,   2.0512383 ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c264f6b81a0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c264f6b9880>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 14, 14, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c264f6bb650>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 14, 14, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape6-W_shape6-2-1] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 2, padding = 1\n",
            "backward = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
            "            2.1704152 ,  -0.38803983],\n",
            "        ... [ -4.09374   ,   3.7291534 , -10.551835  , ...,   0.31741843,\n",
            "            0.03223436,   2.0512383 ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cuda()\n",
            "padding    = 1\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c264f6d7bf0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c264f6d51f0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 14, 14, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c264f6d4680>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 14, 14, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape7-W_shape7-2-2] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 16), stride = 2, padding = 2\n",
            "backward = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Z_shape    = (3, 16, 16, 8)\n",
            "_W         = array([[[[  0.40910086,  -0.64982927,  11.320294  , ...,  -0.12077556,\n",
            "            1.428692  ,  -5.5845156 ],\n",
            "        ... [  1.1511405 ,   0.7441038 ,  16.463472  , ...,  -6.8931007 ,\n",
            "           -0.5833115 ,  -2.504636  ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cuda()\n",
            "padding    = 2\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c264f6433b0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c264f641520>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 16, 16, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c264f640410>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 16, 16, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape8-W_shape8-2-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 14), stride = 2, padding = 0\n",
            "backward = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (3, 3, 8, 14)\n",
            "Z_shape    = (3, 16, 16, 8)\n",
            "_W         = array([[[[ 4.09100860e-01, -6.49829268e-01,  1.13202944e+01, ...,\n",
            "          -5.56089449e+00, -4.84385538e+00, -1.20775...448557e+00, -7.73867989e+00, ...,\n",
            "          -1.13336074e+00, -1.21658230e+00, -4.79330921e+00]]]],\n",
            "      dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c264f6f43e0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c264f6f6090>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 16, 16, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c264f6f5970>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 16, 16, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape9-W_shape9-2-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 2), W_shape = (3, 3, 2, 14), stride = 2, padding = 0\n",
            "backward = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (3, 3, 2, 14)\n",
            "Z_shape    = (3, 16, 16, 2)\n",
            "_W         = array([[[[ -8.0968    ,  -2.5552022 ,   8.703147  ,  -1.4674252 ,\n",
            "            4.5861077 ,  -0.28521433,   4.383634  , ...        -8.13161   ,  -0.67411226,  -2.9204676 ,   1.675528  ,\n",
            "          -12.187821  ,   5.5746226 ]]]], dtype=float32)\n",
            "_Z         = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "backward   = False\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c264f6bb770>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c264f6b9730>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 16, 16, 2), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c264f6b9d30>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 16, 16, 2)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape10-W_shape10-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 24), W_shape = (3, 3, 24, 14), stride = 1, padding = 0\n",
            "backward = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (3, 3, 24, 14)\n",
            "Z_shape    = (3, 16, 16, 24)\n",
            "_W         = array([[[[ -1.3245817 ,   1.0111231 ,  -1.9236585 , ...,  -2.5907016 ,\n",
            "           -0.36175704,   4.6234684 ],\n",
            "        ... [  3.2300415 ,  -2.4161792 ,  -3.420825  , ...,  -9.444658  ,\n",
            "            8.537833  ,   2.3818388 ]]]], dtype=float32)\n",
            "_Z         = array([[[[  8.820262  ,   2.000786  ,   4.89369   , ...,   3.2680929 ,\n",
            "            4.322181  ,  -3.7108252 ],\n",
            "        ... [  2.5084004 ,   3.1399443 ,  -0.12958507, ...,   0.13740699,\n",
            "           -1.400853  ,   0.07475674]]]], dtype=float32)\n",
            "backward   = False\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[  8.820262  ,   2.000786  ,   4.89369   , ...,   3.2680929 ,\n",
            "            4.322181  ,  -3.7108252 ],\n",
            "        ... [  2.5084004 ,   3.1399443 ,  -0.12958507, ...,   0.13740699,\n",
            "           -1.400853  ,   0.07475674]]]], dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c264f6bb950>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[  8.820262  ,   2.000786  ,   4.89369   , ...,   3.2680929 ,\n",
            "            4.322181  ,  -3.7108252 ],\n",
            "        ... [  2.5084004 ,   3.1399443 ,  -0.12958507, ...,   0.13740699,\n",
            "           -1.400853  ,   0.07475674]]]], dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[  8.820262  ,   2.000786  ,   4.89369   , ...,   3.2680929 ,\n",
            "            4.322181  ,  -3.7108252 ],\n",
            "        ... [  2.5084004 ,   3.1399443 ,  -0.12958507, ...,   0.13740699,\n",
            "           -1.400853  ,   0.07475674]]]], dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[  8.820262  ,   2.000786  ,   4.89369   , ...,   3.2680929 ,\n",
            "            4.322181  ,  -3.7108252 ],\n",
            "        ... [  2.5084004 ,   3.1399443 ,  -0.12958507, ...,   0.13740699,\n",
            "           -1.400853  ,   0.07475674]]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c264f6ba210>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 16, 16, 24), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c264f6b8140>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 16, 16, 24)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape11-W_shape11-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (5, 5, 8, 16), stride = 1, padding = 0\n",
            "backward = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (5, 5, 8, 16)\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "_W         = array([[[[ 4.28266907e+00,  8.13360405e+00, -4.62234831e+00, ...,\n",
            "           2.07981968e+00,  2.17041516e+00, -3.88039...947495e+00, -4.97804356e+00, ...,\n",
            "          -5.69430470e-01,  4.27775383e-01, -3.84437203e+00]]]],\n",
            "      dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c264f5b84a0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c264f5b90a0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 14, 14, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c264f5b83b0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 14, 14, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape12-W_shape12-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 17, 17, 8), W_shape = (5, 5, 8, 16), stride = 1, padding = 0\n",
            "backward = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (5, 5, 8, 16)\n",
            "Z_shape    = (3, 17, 17, 8)\n",
            "_W         = array([[[[ 5.93117094e+00, -4.61600447e+00, -7.43411541e+00, ...,\n",
            "           9.49053860e+00,  6.47611380e+00, -3.38525...609781e+00,  1.63659811e+00, ...,\n",
            "           8.22474575e+00,  2.56555057e+00,  1.63004756e+00]]]],\n",
            "      dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...298299e+00, -3.24756050e+00, ...,\n",
            "          -7.96233535e-01,  4.72636795e+00, -5.75466204e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...298299e+00, -3.24756050e+00, ...,\n",
            "          -7.96233535e-01,  4.72636795e+00, -5.75466204e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c264f6bb980>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...298299e+00, -3.24756050e+00, ...,\n",
            "          -7.96233535e-01,  4.72636795e+00, -5.75466204e+00]]]],\n",
            "      dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...298299e+00, -3.24756050e+00, ...,\n",
            "          -7.96233535e-01,  4.72636795e+00, -5.75466204e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...298299e+00, -3.24756050e+00, ...,\n",
            "          -7.96233535e-01,  4.72636795e+00, -5.75466204e+00]]]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c264f6baab0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 17, 17, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c264f6b9820>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 17, 17, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape13-W_shape13-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 17, 17, 1), W_shape = (5, 5, 1, 16), stride = 1, padding = 0\n",
            "backward = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (5, 5, 1, 16)\n",
            "Z_shape    = (3, 17, 17, 1)\n",
            "_W         = array([[[[  1.5437562 ,  -6.8538    ,   4.3282647 ,   5.4068804 ,\n",
            "           -3.15688   ,  -1.206689  ,  -4.3909516 , ...  -7.0278    ,  -1.7489109 ,\n",
            "           10.11736   ,   2.5269346 ,   1.7962458 ,  -7.9124722 ]]]],\n",
            "      dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00],\n",
            "         [ 2.00078607e+00],\n",
            "         [ 4.89369011e+00],\n",
            "         [ 1.12044659e+01],\n",
            "      ... 4.97272283e-01],\n",
            "         [ 1.13696384e+00],\n",
            "         [-5.08369303e+00],\n",
            "         [-5.73876619e-01]]]], dtype=float32)\n",
            "backward   = False\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00],\n",
            "         [ 2.00078607e+00],\n",
            "         [ 4.89369011e+00],\n",
            "         [ 1.12044659e+01],\n",
            "      ... 4.97272283e-01],\n",
            "         [ 1.13696384e+00],\n",
            "         [-5.08369303e+00],\n",
            "         [-5.73876619e-01]]]], dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c264f690e30>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00],\n",
            "         [ 2.00078607e+00],\n",
            "         [ 4.89369011e+00],\n",
            "         [ 1.12044659e+01],\n",
            "      ... 4.97272283e-01],\n",
            "         [ 1.13696384e+00],\n",
            "         [-5.08369303e+00],\n",
            "         [-5.73876619e-01]]]], dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00],\n",
            "         [ 2.00078607e+00],\n",
            "         [ 4.89369011e+00],\n",
            "         [ 1.12044659e+01],\n",
            "      ... 4.97272283e-01],\n",
            "         [ 1.13696384e+00],\n",
            "         [-5.08369303e+00],\n",
            "         [-5.73876619e-01]]]], dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00],\n",
            "         [ 2.00078607e+00],\n",
            "         [ 4.89369011e+00],\n",
            "         [ 1.12044659e+01],\n",
            "      ... 4.97272283e-01],\n",
            "         [ 1.13696384e+00],\n",
            "         [-5.08369303e+00],\n",
            "         [-5.73876619e-01]]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c264f692750>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 17, 17, 1), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c264f692150>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 17, 17, 1)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape14-W_shape14-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 17, 17, 16), W_shape = (5, 5, 16, 1), stride = 1, padding = 0\n",
            "backward = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (5, 5, 16, 1)\n",
            "Z_shape    = (3, 17, 17, 16)\n",
            "_W         = array([[[[ 1.55579513e-02],\n",
            "         [-3.04658723e+00],\n",
            "         [ 4.09725952e+00],\n",
            "         [ 1.29906273e+00],\n",
            "      ...-4.20992136e+00],\n",
            "         [ 4.11707735e+00],\n",
            "         [ 4.99041653e+00],\n",
            "         [ 5.11040497e+00]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "           6.08375072e-01,  2.21931624e+00,  1.66837...452928e+00,  1.35930243e+01, ...,\n",
            "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "           6.08375072e-01,  2.21931624e+00,  1.66837...452928e+00,  1.35930243e+01, ...,\n",
            "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c264f5bb590>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "           6.08375072e-01,  2.21931624e+00,  1.66837...452928e+00,  1.35930243e+01, ...,\n",
            "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
            "      dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "           6.08375072e-01,  2.21931624e+00,  1.66837...452928e+00,  1.35930243e+01, ...,\n",
            "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "           6.08375072e-01,  2.21931624e+00,  1.66837...452928e+00,  1.35930243e+01, ...,\n",
            "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c264f5b8d10>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 17, 17, 16), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c264f5bb950>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 17, 17, 16)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape15-W_shape15-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 17, 17, 16), W_shape = (1, 1, 16, 1), stride = 1, padding = 0\n",
            "backward = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (1, 1, 16, 1)\n",
            "Z_shape    = (3, 17, 17, 16)\n",
            "_W         = array([[[[ 0.01555795],\n",
            "         [-3.0465872 ],\n",
            "         [ 4.0972595 ],\n",
            "         [ 1.2990627 ],\n",
            "         [-7.505466  ]...13 ],\n",
            "         [-5.0566583 ],\n",
            "         [-0.23777105],\n",
            "         [-9.931785  ],\n",
            "         [-0.44905776]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "           6.08375072e-01,  2.21931624e+00,  1.66837...452928e+00,  1.35930243e+01, ...,\n",
            "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
            "      dtype=float32)\n",
            "backward   = False\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "           6.08375072e-01,  2.21931624e+00,  1.66837...452928e+00,  1.35930243e+01, ...,\n",
            "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c264f6f4b30>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "           6.08375072e-01,  2.21931624e+00,  1.66837...452928e+00,  1.35930243e+01, ...,\n",
            "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
            "      dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "           6.08375072e-01,  2.21931624e+00,  1.66837...452928e+00,  1.35930243e+01, ...,\n",
            "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "           6.08375072e-01,  2.21931624e+00,  1.66837...452928e+00,  1.35930243e+01, ...,\n",
            "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c264f6f6bd0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 17, 17, 16), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c264f6f4b60>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 17, 17, 16)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape16-W_shape16-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (1, 14, 14, 2), W_shape = (3, 3, 2, 2), stride = 1, padding = 0\n",
            "backward = False, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (3, 3, 2, 2)\n",
            "Z_shape    = (1, 14, 14, 2)\n",
            "_W         = array([[[[ -1.7671587 ,  -8.082371  ],\n",
            "         [ -1.4591868 ,  -3.807461  ]],\n",
            "\n",
            "        [[  4.2896194 ,   5.705509  ],...016  ,   0.61860955]],\n",
            "\n",
            "        [[ -0.65053475,   0.46976614],\n",
            "         [  4.7152305 , -13.698386  ]]]], dtype=float32)\n",
            "_Z         = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...275537 ,  -7.359175  ],\n",
            "         [  8.240675  ,   0.8211388 ],\n",
            "         [  2.8364513 ,  -1.1133755 ]]]], dtype=float32)\n",
            "backward   = False\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...275537 ,  -7.359175  ],\n",
            "         [  8.240675  ,   0.8211388 ],\n",
            "         [  2.8364513 ,  -1.1133755 ]]]], dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x7c264f6d4cb0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...275537 ,  -7.359175  ],\n",
            "         [  8.240675  ,   0.8211388 ],\n",
            "         [  2.8364513 ,  -1.1133755 ]]]], dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...275537 ,  -7.359175  ],\n",
            "         [  8.240675  ,   0.8211388 ],\n",
            "         [  2.8364513 ,  -1.1133755 ]]]], dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...275537 ,  -7.359175  ],\n",
            "         [  8.240675  ,   0.8211388 ],\n",
            "         [  2.8364513 ,  -1.1133755 ]]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x7c264f6d7290>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (1, 14, 14, 2), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x7c264f6d4950>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (1, 14, 14, 2)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape0-W_shape0-1-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape1-W_shape1-1-1]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape2-W_shape2-1-2]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape3-W_shape3-1-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape4-W_shape4-1-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape5-W_shape5-2-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape6-W_shape6-2-1]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape7-W_shape7-2-2]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape8-W_shape8-2-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape9-W_shape9-2-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape10-W_shape10-1-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape11-W_shape11-1-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape12-W_shape12-1-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape13-W_shape13-1-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape14-W_shape14-1-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape15-W_shape15-1-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape16-W_shape16-1-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape0-W_shape0-1-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape1-W_shape1-1-1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape2-W_shape2-1-2]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape3-W_shape3-1-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape4-W_shape4-1-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape5-W_shape5-2-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape6-W_shape6-2-1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape7-W_shape7-2-2]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape8-W_shape8-2-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape9-W_shape9-2-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape10-W_shape10-1-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape11-W_shape11-1-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape12-W_shape12-1-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape13-W_shape13-1-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape14-W_shape14-1-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape15-W_shape15-1-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[forward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape16-W_shape16-1-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31m===================== \u001b[31m\u001b[1m34 failed\u001b[0m, \u001b[33m1769 deselected\u001b[0m\u001b[31m in 9.60s\u001b[0m\u001b[31m ======================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"op_conv and forward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHxV8ijJ66oW"
      },
      "source": [
        "-----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4QIBm9J66oW"
      },
      "source": [
        "### Convolution backward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY_WFida66oW"
      },
      "source": [
        "Finding the gradients of 2D multi-channel convolution can be technically quite challenging (especially \"rigorously\"). We will try to provide some useful hints here. Basically, we encourage you to make use of the surprising fact that _whatever makes the dimensions work out is typically right_.\n",
        "\n",
        "Ultimately, the backward pass of convolution can be done in terms of the convolution operator itself, with some clever manipulations using `flip`, `dilate`, and multiple applications of `transpose` to both the arguments and the results.\n",
        "\n",
        "In the last section, we essentially implemented convolution as a matrix product: ignoring the various restride and reshape operations, we basically have something like `X @ W`, where `X` is the input and `W` is the weight. We also have `out_grad`, which is the same shape as `X @ W`. Now, you have already implemented the backward pass of matrix multiplication in a previous assignment, and we can use this knowledge to get some insight into the backward pass of convolution. In particular, referencing your matmul backward implementation, you may notice (heuristically speaking here):\n",
        "\n",
        "`X.grad = out_grad @ W.transpose` \\\n",
        "`W.grad = X.transpose @ out_grad`\n",
        "\n",
        "Surprisingly enough, things work out if we just assume that these are also convolutions (and now assuming that `out_grad`, `W`, and `X` are tensors amenable to 2D multi-channel convolution instead of matrices):\n",
        "\n",
        "`X.grad = conv(out_grad, W)` \\\n",
        "`W.grad = conv(X, out_grad)`\n",
        "\n",
        "In which the \"\" indicates that you need to apply some additional operators to these terms in order to get the dimensions to work out, such as permuting/transposing axes, dilating, changing the `padding=` argument to the convolution function, or permuting/transposing axes of the resulting convolution.\n",
        "\n",
        "As we saw on the [last few slides here](https://dlsyscourse.org/slides/conv_nets.pdf) in class, the transpose of a convolution can be found by simply flipping the kernel. Since we're working in 2D instead of 1D, this means flipping the kernel both vertically and horizontally (thus why we implemented `flip`).\n",
        "\n",
        "Summarizing some hints for both `X.grad` and `W.grad`:\n",
        "\n",
        "`X.grad`\n",
        "- The convolution of `out_grad` and `W`, with some operations applied to those\n",
        "- `W` should be flipped over both the kernel dimensions\n",
        "- If the convolution is strided, increase the size of `out_grad` with a corresponding dilation\n",
        "- Do an example to analyze dimensions: note the shape you want for `X.grad`, and think about how you must permute/transpose the arguments and add padding to the convolution to achieve this shape\n",
        "    - This padding depends on both the kernel size and the `padding` argument to the convolution\n",
        "\n",
        "`W.grad`\n",
        "- The convolution of `X` and `out_grad`, with some operations applied to those\n",
        "- The gradients of `W` must be accumulated over the batches; how can you make the conv operator itself do this accumulation?\n",
        "    - Consider turning batches into channels via transpose/permute\n",
        "- Analyze dimensions: how can you modify `X` and `out_grad` so that the shape of their convolution matches the shape of `W`? You may need to transpose/permute the result.\n",
        "    - Remember to account for the `padding` argument passed to convolution\n",
        "\n",
        "General tips\n",
        "- Deal with strided convolutions last (you should be able to just drop in `dilate` when you've passed most of the tests)\n",
        "- Start with the case where `padding=0`, then consider changing `padding` arguments\n",
        "- You can \"permute\" axes with multiple calls to `transpose`\n",
        "\n",
        "It might also be useful to skip ahead to nn.Conv, pass the forward tests, and then use both the tests below and the nn.Conv backward tests to debug your implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwtmZd6Y66oW",
        "outputId": "02248525-6ab0-46d0-8d18-0562237ce757"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: langsmith-0.4.42, typeguard-4.4.4, anyio-4.11.0\n",
            "collected 1803 items / 1769 deselected / 34 selected                           \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape0-W_shape0-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [  2%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape1-W_shape1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  5%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape2-W_shape2-1-2] \u001b[31mFAILED\u001b[0m\u001b[31m [  8%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape3-W_shape3-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 11%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape4-W_shape4-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 14%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape5-W_shape5-2-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 17%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape6-W_shape6-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 20%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape7-W_shape7-2-2] \u001b[31mFAILED\u001b[0m\u001b[31m [ 23%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape8-W_shape8-2-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 26%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape9-W_shape9-2-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 29%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape10-W_shape10-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 32%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape11-W_shape11-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 35%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape12-W_shape12-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 38%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape13-W_shape13-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 41%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape14-W_shape14-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 44%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape15-W_shape15-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 47%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape16-W_shape16-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape0-W_shape0-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 52%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape1-W_shape1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 55%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape2-W_shape2-1-2] \u001b[31mFAILED\u001b[0m\u001b[31m [ 58%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape3-W_shape3-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 61%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape4-W_shape4-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 64%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape5-W_shape5-2-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 67%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape6-W_shape6-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 70%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape7-W_shape7-2-2] \u001b[31mFAILED\u001b[0m\u001b[31m [ 73%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape8-W_shape8-2-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 76%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape9-W_shape9-2-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 79%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape10-W_shape10-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 82%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape11-W_shape11-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 85%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape12-W_shape12-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 88%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape13-W_shape13-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 91%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape14-W_shape14-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 94%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape15-W_shape15-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [ 97%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape16-W_shape16-1-0] \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape0-W_shape0-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 1, padding = 0\n",
            "backward = True, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.245844...2.618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]])\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
            "            2.1704152 ,  -0.38803983],\n",
            "        ... [ -4.09374   ,   3.7291534 , -10.551835  , ...,   0.31741843,\n",
            "            0.03223436,   2.0512383 ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "        b          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.245844...2.618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]])\n",
            "        padding    = 0\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048....618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x79493b4f0ef0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048....618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x79493b4f0ef0>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493bac18e0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493bac18e0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x79493b4f0ef0>\n",
            "A = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "B = NDArray([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.2458448   -0....71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "B          = NDArray([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.2458448   -0....71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[  4.282669     8.133604    -4.6223483  ...   2.0798197    2.1704152\n",
            "   -0.38803983]\n",
            " [  2.2458448   -0.65650...\n",
            "    0.71487164]\n",
            " [ -4.09374      3.7291534  -10.551835   ...   0.31741843   0.03223436\n",
            "    2.0512383 ]], device=cpu())\n",
            "cols       = NDArray([[ 8.820262    2.000786    4.89369    ... -8.380019    5.7616577\n",
            "   5.3980927 ]\n",
            " [-0.51609427  2.0529926   0.7....3520528\n",
            "   2.6459963 ]\n",
            " [-4.257232   -1.6909163   3.8448386  ... -0.6230901  -0.8482267\n",
            "  -2.2998476 ]], device=cpu())\n",
            "out_h      = 12\n",
            "out_w      = 12\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x79493b4f0ef0>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape1-W_shape1-1-1] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 1, padding = 1\n",
            "backward = True, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.245844...2.618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]])\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
            "            2.1704152 ,  -0.38803983],\n",
            "        ... [ -4.09374   ,   3.7291534 , -10.551835  , ...,   0.31741843,\n",
            "            0.03223436,   2.0512383 ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cpu()\n",
            "padding    = 1\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "        b          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.245844...2.618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]])\n",
            "        padding    = 1\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048....618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x79493aa8fc80>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048....618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x79493aa8fc80>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493aa8fd10>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493aa8fd10>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x79493aa8fc80>\n",
            "A = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "B = NDArray([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.2458448   -0....71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
            "     0.0000000e+00  0.0000000e+00]\n",
            "   [ 0....  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
            "     0.0000000e+00  0.0000000e+00]]]], device=cpu())\n",
            "B          = NDArray([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.2458448   -0....71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[  4.282669     8.133604    -4.6223483  ...   2.0798197    2.1704152\n",
            "   -0.38803983]\n",
            " [  2.2458448   -0.65650...\n",
            "    0.71487164]\n",
            " [ -4.09374      3.7291534  -10.551835   ...   0.31741843   0.03223436\n",
            "    2.0512383 ]], device=cpu())\n",
            "cols       = NDArray([[ 0.          0.          0.         ... -0.7481727  -2.1757677\n",
            "   9.246319  ]\n",
            " [ 0.          0.          0. ... 0.          0.\n",
            "   0.        ]\n",
            " [ 5.346782   -1.7781421  -5.3473854  ...  0.          0.\n",
            "   0.        ]], device=cpu())\n",
            "out_h      = 14\n",
            "out_w      = 14\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x79493aa8fc80>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape2-W_shape2-1-2] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 16), stride = 1, padding = 2\n",
            "backward = True, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[  0.40910086  -0.64982927  11.320294   ...  -0.12077556\n",
            "      1.428692    -5.5845156 ]\n",
            "   [ -6.89178...-1.5437248  -10.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]])\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...5e+00]\n",
            "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]])\n",
            "Z_shape    = (3, 16, 16, 8)\n",
            "_W         = array([[[[  0.40910086,  -0.64982927,  11.320294  , ...,  -0.12077556,\n",
            "            1.428692  ,  -5.5845156 ],\n",
            "        ... [  1.1511405 ,   0.7441038 ,  16.463472  , ...,  -6.8931007 ,\n",
            "           -0.5833115 ,  -2.504636  ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cpu()\n",
            "padding    = 2\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...5e+00]\n",
            "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]])\n",
            "        b          = needle.Tensor([[[[  0.40910086  -0.64982927  11.320294   ...  -0.12077556\n",
            "      1.428692    -5.5845156 ]\n",
            "   [ -6.89178...-1.5437248  -10.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]])\n",
            "        padding    = 2\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048...1.5437248  -10.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x79493aad99a0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048...1.5437248  -10.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x79493aad99a0>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493aadacf0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493aadacf0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x79493aad99a0>\n",
            "A = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]], device=cpu())\n",
            "B = NDArray([[[[  0.40910086  -0.64982927  11.320294   ...  -0.12077556\n",
            "      1.428692    -5.5845156 ]\n",
            "   [ -6.891782    -...0.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.  ...     0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]]]], device=cpu())\n",
            "B          = NDArray([[[[  0.40910086  -0.64982927  11.320294   ...  -0.12077556\n",
            "      1.428692    -5.5845156 ]\n",
            "   [ -6.891782    -...0.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[  0.40910086  -0.64982927  11.320294   ...  -0.12077556   1.428692\n",
            "   -5.5845156 ]\n",
            " [ -6.891782    -9.38364 ...8\n",
            "  -10.136281  ]\n",
            " [  1.1511405    0.7441038   16.463472   ...  -6.8931007   -0.5833115\n",
            "   -2.504636  ]], device=cpu())\n",
            "cols       = NDArray([[ 0.          0.          0.         ... -4.8863893   4.750442\n",
            "  -0.75678605]\n",
            " [ 0.          0.          0.  ... 0.          0.\n",
            "   0.        ]\n",
            " [ 6.1036735  -2.0543451  -4.413845   ...  0.          0.\n",
            "   0.        ]], device=cpu())\n",
            "out_h      = 18\n",
            "out_w      = 18\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x79493aad99a0>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape3-W_shape3-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 14), stride = 1, padding = 0\n",
            "backward = True, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[ 4.09100860e-01 -6.49829268e-01  1.13202944e+01 ... -5.56089449e+00\n",
            "    -4.84385538e+00 -1.20775558e...5e+00]\n",
            "   [-1.10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]])\n",
            "W_shape    = (3, 3, 8, 14)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...5e+00]\n",
            "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]])\n",
            "Z_shape    = (3, 16, 16, 8)\n",
            "_W         = array([[[[ 4.09100860e-01, -6.49829268e-01,  1.13202944e+01, ...,\n",
            "          -5.56089449e+00, -4.84385538e+00, -1.20775...448557e+00, -7.73867989e+00, ...,\n",
            "          -1.13336074e+00, -1.21658230e+00, -4.79330921e+00]]]],\n",
            "      dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...5e+00]\n",
            "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]])\n",
            "        b          = needle.Tensor([[[[ 4.09100860e-01 -6.49829268e-01  1.13202944e+01 ... -5.56089449e+00\n",
            "    -4.84385538e+00 -1.20775558e...5e+00]\n",
            "   [-1.10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]])\n",
            "        padding    = 0\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048...e+00]\n",
            "   [-1.10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x79493aafbc50>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048...e+00]\n",
            "   [-1.10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x79493aafbc50>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493aafa2a0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493aafa2a0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x79493aafbc50>\n",
            "A = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]], device=cpu())\n",
            "B = NDArray([[[[ 4.09100860e-01 -6.49829268e-01  1.13202944e+01 ... -5.56089449e+00\n",
            "    -4.84385538e+00 -1.20775558e-01]\n",
            " ...10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]], device=cpu())\n",
            "B          = NDArray([[[[ 4.09100860e-01 -6.49829268e-01  1.13202944e+01 ... -5.56089449e+00\n",
            "    -4.84385538e+00 -1.20775558e-01]\n",
            " ...10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[ 0.40910086 -0.64982927 11.320294   ... -5.5608945  -4.8438554\n",
            "  -0.12077556]\n",
            " [ 1.428692   -5.5845156  -6.8...6.206461\n",
            "   7.476679  ]\n",
            " [-1.1071408   2.5444856  -7.73868    ... -1.1333607  -1.2165823\n",
            "  -4.793309  ]], device=cpu())\n",
            "cols       = NDArray([[  8.820262     2.000786     4.89369    ...  -0.5805197  -10.153422\n",
            "   10.322464  ]\n",
            " [ -0.51609427   2.052992...6\n",
            "   -3.4337142 ]\n",
            " [ -1.0374745    1.4560792    4.767398   ...  -6.1524563    3.3351467\n",
            "   -1.3563056 ]], device=cpu())\n",
            "out_h      = 14\n",
            "out_w      = 14\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x79493aafbc50>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape4-W_shape4-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 2), W_shape = (3, 3, 2, 14), stride = 1, padding = 0\n",
            "backward = True, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
            "     -0.28521433   4.383634    -9.13...727333   0.22582927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]])\n",
            "W_shape    = (3, 3, 2, 14)\n",
            "Z          = needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   [...   -5.112822  ]\n",
            "   ...\n",
            "   [ -7.922368     4.2222714 ]\n",
            "   [ -6.064339     1.4188478 ]\n",
            "   [ -1.4109794   -5.791016  ]]]])\n",
            "Z_shape    = (3, 16, 16, 2)\n",
            "_W         = array([[[[ -8.0968    ,  -2.5552022 ,   8.703147  ,  -1.4674252 ,\n",
            "            4.5861077 ,  -0.28521433,   4.383634  , ...        -8.13161   ,  -0.67411226,  -2.9204676 ,   1.675528  ,\n",
            "          -12.187821  ,   5.5746226 ]]]], dtype=float32)\n",
            "_Z         = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "backward   = True\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   [...   -5.112822  ]\n",
            "   ...\n",
            "   [ -7.922368     4.2222714 ]\n",
            "   [ -6.064339     1.4188478 ]\n",
            "   [ -1.4109794   -5.791016  ]]]])\n",
            "        b          = needle.Tensor([[[[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
            "     -0.28521433   4.383634    -9.13...727333   0.22582927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]])\n",
            "        padding    = 0\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   ...27333   0.22582927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x79493aaf9f70>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   ...27333   0.22582927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x79493aaf9f70>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493aaf9a00>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493aaf9a00>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x79493aaf9f70>\n",
            "A = NDArray([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   [  0.22...]\n",
            "   ...\n",
            "   [ -7.922368     4.2222714 ]\n",
            "   [ -6.064339     1.4188478 ]\n",
            "   [ -1.4109794   -5.791016  ]]]], device=cpu())\n",
            "B = NDArray([[[[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
            "     -0.28521433   4.383634    -9.134557  ...82927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   [  0.22...]\n",
            "   ...\n",
            "   [ -7.922368     4.2222714 ]\n",
            "   [ -6.064339     1.4188478 ]\n",
            "   [ -1.4109794   -5.791016  ]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   [  0.22...]\n",
            "   ...\n",
            "   [ -7.922368     4.2222714 ]\n",
            "   [ -6.064339     1.4188478 ]\n",
            "   [ -1.4109794   -5.791016  ]]]], device=cpu())\n",
            "B          = NDArray([[[[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
            "     -0.28521433   4.383634    -9.134557  ...82927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
            "   -0.28521433   4.383634    -9.134557    -2....22582927   9.296732    -8.13161     -0.67411226\n",
            "   -2.9204676    1.675528   -12.187821     5.5746226 ]], device=cpu())\n",
            "cols       = NDArray([[ 8.820262    2.000786    4.89369    ...  2.3139112  -4.536492\n",
            "   0.25972697]\n",
            " [ 4.89369    11.204466    9.33...6.064339\n",
            "   1.4188478 ]\n",
            " [ 0.3375843   3.8880208  -0.17871366 ...  1.4188478  -1.4109794\n",
            "  -5.791016  ]], device=cpu())\n",
            "out_h      = 14\n",
            "out_w      = 14\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x79493aaf9f70>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape5-W_shape5-2-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 2, padding = 0\n",
            "backward = True, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.245844...2.618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]])\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
            "            2.1704152 ,  -0.38803983],\n",
            "        ... [ -4.09374   ,   3.7291534 , -10.551835  , ...,   0.31741843,\n",
            "            0.03223436,   2.0512383 ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "        b          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.245844...2.618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]])\n",
            "        padding    = 0\n",
            "        stride     = 2\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048....618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x79493aaf9880>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048....618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x79493aaf9880>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493aaf9610>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493aaf9610>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x79493aaf9880>\n",
            "A = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "B = NDArray([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.2458448   -0....71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "B          = NDArray([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.2458448   -0....71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[  4.282669     8.133604    -4.6223483  ...   2.0798197    2.1704152\n",
            "   -0.38803983]\n",
            " [  2.2458448   -0.65650...\n",
            "    0.71487164]\n",
            " [ -4.09374      3.7291534  -10.551835   ...   0.31741843   0.03223436\n",
            "    2.0512383 ]], device=cpu())\n",
            "cols       = NDArray([[  8.820262     2.000786     4.89369    ...  -8.380019     5.7616577\n",
            "    5.3980927 ]\n",
            " [  7.4703956   -1.02579...56\n",
            "    6.0469246 ]\n",
            " [  1.1145538  -14.462599     1.6968298  ...   2.5371516  -10.818328\n",
            "    1.5426137 ]], device=cpu())\n",
            "out_h      = 6\n",
            "out_w      = 6\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x79493aaf9880>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape6-W_shape6-2-1] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 2, padding = 1\n",
            "backward = True, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.245844...2.618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]])\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
            "            2.1704152 ,  -0.38803983],\n",
            "        ... [ -4.09374   ,   3.7291534 , -10.551835  , ...,   0.31741843,\n",
            "            0.03223436,   2.0512383 ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cpu()\n",
            "padding    = 1\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "        b          = needle.Tensor([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.245844...2.618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]])\n",
            "        padding    = 1\n",
            "        stride     = 2\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048....618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x79493aafb0e0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048....618842     0.71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x79493aafb0e0>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493aafa810>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493aafa810>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x79493aafb0e0>\n",
            "A = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "B = NDArray([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.2458448   -0....71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
            "     0.0000000e+00  0.0000000e+00]\n",
            "   [ 0....  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
            "     0.0000000e+00  0.0000000e+00]]]], device=cpu())\n",
            "B          = NDArray([[[[  4.282669     8.133604    -4.6223483  ...   2.0798197\n",
            "      2.1704152   -0.38803983]\n",
            "   [  2.2458448   -0....71487164]\n",
            "   [ -4.09374      3.7291534  -10.551835   ...   0.31741843\n",
            "      0.03223436   2.0512383 ]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[  4.282669     8.133604    -4.6223483  ...   2.0798197    2.1704152\n",
            "   -0.38803983]\n",
            " [  2.2458448   -0.65650...\n",
            "    0.71487164]\n",
            " [ -4.09374      3.7291534  -10.551835   ...   0.31741843   0.03223436\n",
            "    2.0512383 ]], device=cpu())\n",
            "cols       = NDArray([[ 0.          0.          0.         ... -0.7481727  -2.1757677\n",
            "   9.246319  ]\n",
            " [ 0.          0.          0. ...49081123\n",
            "  -5.8721123 ]\n",
            " [-4.257232   -1.6909163   3.8448386  ... -0.6230901  -0.8482267\n",
            "  -2.2998476 ]], device=cpu())\n",
            "out_h      = 7\n",
            "out_w      = 7\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x79493aafb0e0>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape7-W_shape7-2-2] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 16), stride = 2, padding = 2\n",
            "backward = True, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[  0.40910086  -0.64982927  11.320294   ...  -0.12077556\n",
            "      1.428692    -5.5845156 ]\n",
            "   [ -6.89178...-1.5437248  -10.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]])\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...5e+00]\n",
            "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]])\n",
            "Z_shape    = (3, 16, 16, 8)\n",
            "_W         = array([[[[  0.40910086,  -0.64982927,  11.320294  , ...,  -0.12077556,\n",
            "            1.428692  ,  -5.5845156 ],\n",
            "        ... [  1.1511405 ,   0.7441038 ,  16.463472  , ...,  -6.8931007 ,\n",
            "           -0.5833115 ,  -2.504636  ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cpu()\n",
            "padding    = 2\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...5e+00]\n",
            "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]])\n",
            "        b          = needle.Tensor([[[[  0.40910086  -0.64982927  11.320294   ...  -0.12077556\n",
            "      1.428692    -5.5845156 ]\n",
            "   [ -6.89178...-1.5437248  -10.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]])\n",
            "        padding    = 2\n",
            "        stride     = 2\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048...1.5437248  -10.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x79493aa94b00>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048...1.5437248  -10.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x79493aa94b00>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493aa97680>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493aa97680>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x79493aa94b00>\n",
            "A = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]], device=cpu())\n",
            "B = NDArray([[[[  0.40910086  -0.64982927  11.320294   ...  -0.12077556\n",
            "      1.428692    -5.5845156 ]\n",
            "   [ -6.891782    -...0.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.  ...     0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]]]], device=cpu())\n",
            "B          = NDArray([[[[  0.40910086  -0.64982927  11.320294   ...  -0.12077556\n",
            "      1.428692    -5.5845156 ]\n",
            "   [ -6.891782    -...0.136281  ]\n",
            "   [  1.1511405    0.7441038   16.463472   ...  -6.8931007\n",
            "     -0.5833115   -2.504636  ]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[  0.40910086  -0.64982927  11.320294   ...  -0.12077556   1.428692\n",
            "   -5.5845156 ]\n",
            " [ -6.891782    -9.38364 ...8\n",
            "  -10.136281  ]\n",
            " [  1.1511405    0.7441038   16.463472   ...  -6.8931007   -0.5833115\n",
            "   -2.504636  ]], device=cpu())\n",
            "cols       = NDArray([[ 0.          0.          0.         ... -4.8863893   4.750442\n",
            "  -0.75678605]\n",
            " [ 0.          0.          0.  ... 0.          0.\n",
            "   0.        ]\n",
            " [10.212681   -4.597306    0.57335013 ...  0.          0.\n",
            "   0.        ]], device=cpu())\n",
            "out_h      = 9\n",
            "out_w      = 9\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x79493aa94b00>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape8-W_shape8-2-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 14), stride = 2, padding = 0\n",
            "backward = True, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[ 4.09100860e-01 -6.49829268e-01  1.13202944e+01 ... -5.56089449e+00\n",
            "    -4.84385538e+00 -1.20775558e...5e+00]\n",
            "   [-1.10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]])\n",
            "W_shape    = (3, 3, 8, 14)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...5e+00]\n",
            "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]])\n",
            "Z_shape    = (3, 16, 16, 8)\n",
            "_W         = array([[[[ 4.09100860e-01, -6.49829268e-01,  1.13202944e+01, ...,\n",
            "          -5.56089449e+00, -4.84385538e+00, -1.20775...448557e+00, -7.73867989e+00, ...,\n",
            "          -1.13336074e+00, -1.21658230e+00, -4.79330921e+00]]]],\n",
            "      dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...5e+00]\n",
            "   [ 6.10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]])\n",
            "        b          = needle.Tensor([[[[ 4.09100860e-01 -6.49829268e-01  1.13202944e+01 ... -5.56089449e+00\n",
            "    -4.84385538e+00 -1.20775558e...5e+00]\n",
            "   [-1.10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]])\n",
            "        padding    = 0\n",
            "        stride     = 2\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048...e+00]\n",
            "   [-1.10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x79493aaa94f0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048...e+00]\n",
            "   [-1.10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x79493aaa94f0>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493aaab200>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493aaab200>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x79493aaa94f0>\n",
            "A = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]], device=cpu())\n",
            "B = NDArray([[[[ 4.09100860e-01 -6.49829268e-01  1.13202944e+01 ... -5.56089449e+00\n",
            "    -4.84385538e+00 -1.20775558e-01]\n",
            " ...10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...10367346e+00 -2.05434513e+00 -4.41384506e+00 ... -6.15245628e+00\n",
            "     3.33514667e+00 -1.35630560e+00]]]], device=cpu())\n",
            "B          = NDArray([[[[ 4.09100860e-01 -6.49829268e-01  1.13202944e+01 ... -5.56089449e+00\n",
            "    -4.84385538e+00 -1.20775558e-01]\n",
            " ...10714078e+00  2.54448557e+00 -7.73867989e+00 ... -1.13336074e+00\n",
            "    -1.21658230e+00 -4.79330921e+00]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[ 0.40910086 -0.64982927 11.320294   ... -5.5608945  -4.8438554\n",
            "  -0.12077556]\n",
            " [ 1.428692   -5.5845156  -6.8...6.206461\n",
            "   7.476679  ]\n",
            " [-1.1071408   2.5444856  -7.73868    ... -1.1333607  -1.2165823\n",
            "  -4.793309  ]], device=cpu())\n",
            "cols       = NDArray([[  8.820262     2.000786     4.89369    ...  -0.5805197  -10.153422\n",
            "   10.322464  ]\n",
            " [  7.4703956   -1.025791...7\n",
            "   -0.05607079]\n",
            " [ -0.1376712   -1.7998276   -1.3146799  ...  -1.3081918   -6.4312043\n",
            "   -8.273288  ]], device=cpu())\n",
            "out_h      = 7\n",
            "out_w      = 7\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x79493aaa94f0>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape9-W_shape9-2-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 2), W_shape = (3, 3, 2, 14), stride = 2, padding = 0\n",
            "backward = True, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
            "     -0.28521433   4.383634    -9.13...727333   0.22582927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]])\n",
            "W_shape    = (3, 3, 2, 14)\n",
            "Z          = needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   [...   -5.112822  ]\n",
            "   ...\n",
            "   [ -7.922368     4.2222714 ]\n",
            "   [ -6.064339     1.4188478 ]\n",
            "   [ -1.4109794   -5.791016  ]]]])\n",
            "Z_shape    = (3, 16, 16, 2)\n",
            "_W         = array([[[[ -8.0968    ,  -2.5552022 ,   8.703147  ,  -1.4674252 ,\n",
            "            4.5861077 ,  -0.28521433,   4.383634  , ...        -8.13161   ,  -0.67411226,  -2.9204676 ,   1.675528  ,\n",
            "          -12.187821  ,   5.5746226 ]]]], dtype=float32)\n",
            "_Z         = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "backward   = True\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   [...   -5.112822  ]\n",
            "   ...\n",
            "   [ -7.922368     4.2222714 ]\n",
            "   [ -6.064339     1.4188478 ]\n",
            "   [ -1.4109794   -5.791016  ]]]])\n",
            "        b          = needle.Tensor([[[[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
            "     -0.28521433   4.383634    -9.13...727333   0.22582927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]])\n",
            "        padding    = 0\n",
            "        stride     = 2\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   ...27333   0.22582927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x79493aa8c560>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   ...27333   0.22582927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x79493aa8c560>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493aa8e810>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493aa8e810>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x79493aa8c560>\n",
            "A = NDArray([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   [  0.22...]\n",
            "   ...\n",
            "   [ -7.922368     4.2222714 ]\n",
            "   [ -6.064339     1.4188478 ]\n",
            "   [ -1.4109794   -5.791016  ]]]], device=cpu())\n",
            "B = NDArray([[[[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
            "     -0.28521433   4.383634    -9.134557  ...82927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   [  0.22...]\n",
            "   ...\n",
            "   [ -7.922368     4.2222714 ]\n",
            "   [ -6.064339     1.4188478 ]\n",
            "   [ -1.4109794   -5.791016  ]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   ...\n",
            "   [  0.22...]\n",
            "   ...\n",
            "   [ -7.922368     4.2222714 ]\n",
            "   [ -6.064339     1.4188478 ]\n",
            "   [ -1.4109794   -5.791016  ]]]], device=cpu())\n",
            "B          = NDArray([[[[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
            "     -0.28521433   4.383634    -9.134557  ...82927   9.296732    -8.13161     -0.67411226\n",
            "     -2.9204676    1.675528   -12.187821     5.5746226 ]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[ -8.0968      -2.5552022    8.703147    -1.4674252    4.5861077\n",
            "   -0.28521433   4.383634    -9.134557    -2....22582927   9.296732    -8.13161     -0.67411226\n",
            "   -2.9204676    1.675528   -12.187821     5.5746226 ]], device=cpu())\n",
            "cols       = NDArray([[ 8.820262    2.000786    4.89369    ...  2.3139112  -4.536492\n",
            "   0.25972697]\n",
            " [ 9.33779    -4.8863893   4.75...1964829\n",
            "  -1.2339678 ]\n",
            " [-6.875922    2.5049613  -2.401245   ... -0.5711278   0.06619884\n",
            "  -0.60972464]], device=cpu())\n",
            "out_h      = 7\n",
            "out_w      = 7\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x79493aa8c560>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape10-W_shape10-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 24), W_shape = (3, 3, 24, 14), stride = 1, padding = 0\n",
            "backward = True, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[ -1.3245817    1.0111231   -1.9236585  ...  -2.5907016\n",
            "     -0.36175704   4.6234684 ]\n",
            "   [  5.279258... -4.82095      4.98517   ]\n",
            "   [  3.2300415   -2.4161792   -3.420825   ...  -9.444658\n",
            "      8.537833     2.3818388 ]]]])\n",
            "W_shape    = (3, 3, 24, 14)\n",
            "Z          = needle.Tensor([[[[  8.820262     2.000786     4.89369    ...   3.2680929\n",
            "      4.322181    -3.7108252 ]\n",
            "   [ 11.348773...4.207389     8.935435  ]\n",
            "   [  2.5084004    3.1399443   -0.12958507 ...   0.13740699\n",
            "     -1.400853     0.07475674]]]])\n",
            "Z_shape    = (3, 16, 16, 24)\n",
            "_W         = array([[[[ -1.3245817 ,   1.0111231 ,  -1.9236585 , ...,  -2.5907016 ,\n",
            "           -0.36175704,   4.6234684 ],\n",
            "        ... [  3.2300415 ,  -2.4161792 ,  -3.420825  , ...,  -9.444658  ,\n",
            "            8.537833  ,   2.3818388 ]]]], dtype=float32)\n",
            "_Z         = array([[[[  8.820262  ,   2.000786  ,   4.89369   , ...,   3.2680929 ,\n",
            "            4.322181  ,  -3.7108252 ],\n",
            "        ... [  2.5084004 ,   3.1399443 ,  -0.12958507, ...,   0.13740699,\n",
            "           -1.400853  ,   0.07475674]]]], dtype=float32)\n",
            "backward   = True\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[  8.820262     2.000786     4.89369    ...   3.2680929\n",
            "      4.322181    -3.7108252 ]\n",
            "   [ 11.348773...4.207389     8.935435  ]\n",
            "   [  2.5084004    3.1399443   -0.12958507 ...   0.13740699\n",
            "     -1.400853     0.07475674]]]])\n",
            "        b          = needle.Tensor([[[[ -1.3245817    1.0111231   -1.9236585  ...  -2.5907016\n",
            "     -0.36175704   4.6234684 ]\n",
            "   [  5.279258... -4.82095      4.98517   ]\n",
            "   [  3.2300415   -2.4161792   -3.420825   ...  -9.444658\n",
            "      8.537833     2.3818388 ]]]])\n",
            "        padding    = 0\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[  8.820262     2.000786     4.89369    ...   3.2680929\n",
            "      4.322181    -3.7108252 ]\n",
            "   [ 11.34877...-4.82095      4.98517   ]\n",
            "   [  3.2300415   -2.4161792   -3.420825   ...  -9.444658\n",
            "      8.537833     2.3818388 ]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x79493abffb60>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[  8.820262     2.000786     4.89369    ...   3.2680929\n",
            "      4.322181    -3.7108252 ]\n",
            "   [ 11.34877...-4.82095      4.98517   ]\n",
            "   [  3.2300415   -2.4161792   -3.420825   ...  -9.444658\n",
            "      8.537833     2.3818388 ]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x79493abffb60>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493abffa40>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493abffa40>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x79493abffb60>\n",
            "A = NDArray([[[[  8.820262     2.000786     4.89369    ...   3.2680929\n",
            "      4.322181    -3.7108252 ]\n",
            "   [ 11.348773    -7....935435  ]\n",
            "   [  2.5084004    3.1399443   -0.12958507 ...   0.13740699\n",
            "     -1.400853     0.07475674]]]], device=cpu())\n",
            "B = NDArray([[[[ -1.3245817    1.0111231   -1.9236585  ...  -2.5907016\n",
            "     -0.36175704   4.6234684 ]\n",
            "   [  5.2792587   -1... 4.98517   ]\n",
            "   [  3.2300415   -2.4161792   -3.420825   ...  -9.444658\n",
            "      8.537833     2.3818388 ]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[  8.820262     2.000786     4.89369    ...   3.2680929\n",
            "      4.322181    -3.7108252 ]\n",
            "   [ 11.348773    -7....935435  ]\n",
            "   [  2.5084004    3.1399443   -0.12958507 ...   0.13740699\n",
            "     -1.400853     0.07475674]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[  8.820262     2.000786     4.89369    ...   3.2680929\n",
            "      4.322181    -3.7108252 ]\n",
            "   [ 11.348773    -7....935435  ]\n",
            "   [  2.5084004    3.1399443   -0.12958507 ...   0.13740699\n",
            "     -1.400853     0.07475674]]]], device=cpu())\n",
            "B          = NDArray([[[[ -1.3245817    1.0111231   -1.9236585  ...  -2.5907016\n",
            "     -0.36175704   4.6234684 ]\n",
            "   [  5.2792587   -1... 4.98517   ]\n",
            "   [  3.2300415   -2.4161792   -3.420825   ...  -9.444658\n",
            "      8.537833     2.3818388 ]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[-1.3245817   1.0111231  -1.9236585  ... -2.5907016  -0.36175704\n",
            "   4.6234684 ]\n",
            " [ 5.2792587  -1.3089544   0.... -4.82095\n",
            "   4.98517   ]\n",
            " [ 3.2300415  -2.4161792  -3.420825   ... -9.444658    8.537833\n",
            "   2.3818388 ]], device=cpu())\n",
            "cols       = NDArray([[ 8.820262    2.000786    4.89369    ... -1.6283474   2.3521657\n",
            "   1.5572354 ]\n",
            " [11.348773   -7.271828    0.2... 4.207389\n",
            "   8.935435  ]\n",
            " [ 4.376834    6.916924    4.14586    ...  0.13740699 -1.400853\n",
            "   0.07475674]], device=cpu())\n",
            "out_h      = 14\n",
            "out_w      = 14\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x79493abffb60>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape11-W_shape11-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (5, 5, 8, 16), stride = 1, padding = 0\n",
            "backward = True, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[ 4.28266907e+00  8.13360405e+00 -4.62234831e+00 ...  2.07981968e+00\n",
            "     2.17041516e+00 -3.88039827e...7e+00]\n",
            "   [-7.86027253e-01  4.30947495e+00 -4.97804356e+00 ... -5.69430470e-01\n",
            "     4.27775383e-01 -3.84437203e+00]]]])\n",
            "W_shape    = (5, 5, 8, 16)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "_W         = array([[[[ 4.28266907e+00,  8.13360405e+00, -4.62234831e+00, ...,\n",
            "           2.07981968e+00,  2.17041516e+00, -3.88039...947495e+00, -4.97804356e+00, ...,\n",
            "          -5.69430470e-01,  4.27775383e-01, -3.84437203e+00]]]],\n",
            "      dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...3e+00]\n",
            "   [ 1.09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]])\n",
            "        b          = needle.Tensor([[[[ 4.28266907e+00  8.13360405e+00 -4.62234831e+00 ...  2.07981968e+00\n",
            "     2.17041516e+00 -3.88039827e...7e+00]\n",
            "   [-7.86027253e-01  4.30947495e+00 -4.97804356e+00 ... -5.69430470e-01\n",
            "     4.27775383e-01 -3.84437203e+00]]]])\n",
            "        padding    = 0\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048...e+00]\n",
            "   [-7.86027253e-01  4.30947495e+00 -4.97804356e+00 ... -5.69430470e-01\n",
            "     4.27775383e-01 -3.84437203e+00]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x79493aa8d070>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048...e+00]\n",
            "   [-7.86027253e-01  4.30947495e+00 -4.97804356e+00 ... -5.69430470e-01\n",
            "     4.27775383e-01 -3.84437203e+00]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x79493aa8d070>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493aa8c2f0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493aa8c2f0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x79493aa8d070>\n",
            "A = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "B = NDArray([[[[ 4.28266907e+00  8.13360405e+00 -4.62234831e+00 ...  2.07981968e+00\n",
            "     2.17041516e+00 -3.88039827e-01]\n",
            " ...86027253e-01  4.30947495e+00 -4.97804356e+00 ... -5.69430470e-01\n",
            "     4.27775383e-01 -3.84437203e+00]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...09905624e+01  2.23166728e+00  4.62055349e+00 ... -6.23090088e-01\n",
            "    -8.48226726e-01 -2.29984760e+00]]]], device=cpu())\n",
            "B          = NDArray([[[[ 4.28266907e+00  8.13360405e+00 -4.62234831e+00 ...  2.07981968e+00\n",
            "     2.17041516e+00 -3.88039827e-01]\n",
            " ...86027253e-01  4.30947495e+00 -4.97804356e+00 ... -5.69430470e-01\n",
            "     4.27775383e-01 -3.84437203e+00]]]], device=cpu())\n",
            "K          = 5\n",
            "W_col      = NDArray([[ 4.2826691e+00  8.1336040e+00 -4.6223483e+00 ...  2.0798197e+00\n",
            "   2.1704152e+00 -3.8803983e-01]\n",
            " [ 2.245844...+00]\n",
            " [-7.8602725e-01  4.3094749e+00 -4.9780436e+00 ... -5.6943047e-01\n",
            "   4.2777538e-01 -3.8443720e+00]], device=cpu())\n",
            "cols       = NDArray([[  8.820262     2.000786     4.89369    ... -13.278095     7.5666404\n",
            "    2.7656603 ]\n",
            " [ -0.51609427   2.05299...8\n",
            "    2.6459963 ]\n",
            " [ -8.464558     0.2118057    6.9135523  ...  -0.6230901   -0.8482267\n",
            "   -2.2998476 ]], device=cpu())\n",
            "out_h      = 10\n",
            "out_w      = 10\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x79493aa8d070>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape12-W_shape12-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 17, 17, 8), W_shape = (5, 5, 8, 16), stride = 1, padding = 0\n",
            "backward = True, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[ 5.93117094e+00 -4.61600447e+00 -7.43411541e+00 ...  9.49053860e+00\n",
            "     6.47611380e+00 -3.38525438e...7e+00]\n",
            "   [-3.93575430e+00 -6.98609781e+00  1.63659811e+00 ...  8.22474575e+00\n",
            "     2.56555057e+00  1.63004756e+00]]]])\n",
            "W_shape    = (5, 5, 8, 16)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...8e+00]\n",
            "   [ 2.80155873e+00  3.11298299e+00 -3.24756050e+00 ... -7.96233535e-01\n",
            "     4.72636795e+00 -5.75466204e+00]]]])\n",
            "Z_shape    = (3, 17, 17, 8)\n",
            "_W         = array([[[[ 5.93117094e+00, -4.61600447e+00, -7.43411541e+00, ...,\n",
            "           9.49053860e+00,  6.47611380e+00, -3.38525...609781e+00,  1.63659811e+00, ...,\n",
            "           8.22474575e+00,  2.56555057e+00,  1.63004756e+00]]]],\n",
            "      dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...298299e+00, -3.24756050e+00, ...,\n",
            "          -7.96233535e-01,  4.72636795e+00, -5.75466204e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e...8e+00]\n",
            "   [ 2.80155873e+00  3.11298299e+00 -3.24756050e+00 ... -7.96233535e-01\n",
            "     4.72636795e+00 -5.75466204e+00]]]])\n",
            "        b          = needle.Tensor([[[[ 5.93117094e+00 -4.61600447e+00 -7.43411541e+00 ...  9.49053860e+00\n",
            "     6.47611380e+00 -3.38525438e...7e+00]\n",
            "   [-3.93575430e+00 -6.98609781e+00  1.63659811e+00 ...  8.22474575e+00\n",
            "     2.56555057e+00  1.63004756e+00]]]])\n",
            "        padding    = 0\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048...e+00]\n",
            "   [-3.93575430e+00 -6.98609781e+00  1.63659811e+00 ...  8.22474575e+00\n",
            "     2.56555057e+00  1.63004756e+00]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x79493aaaaab0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048...e+00]\n",
            "   [-3.93575430e+00 -6.98609781e+00  1.63659811e+00 ...  8.22474575e+00\n",
            "     2.56555057e+00  1.63004756e+00]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x79493aaaaab0>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493aaa9520>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493aaa9520>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x79493aaaaab0>\n",
            "A = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...80155873e+00  3.11298299e+00 -3.24756050e+00 ... -7.96233535e-01\n",
            "     4.72636795e+00 -5.75466204e+00]]]], device=cpu())\n",
            "B = NDArray([[[[ 5.93117094e+00 -4.61600447e+00 -7.43411541e+00 ...  9.49053860e+00\n",
            "     6.47611380e+00 -3.38525438e+00]\n",
            " ...93575430e+00 -6.98609781e+00  1.63659811e+00 ...  8.22474575e+00\n",
            "     2.56555057e+00  1.63004756e+00]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...80155873e+00  3.11298299e+00 -3.24756050e+00 ... -7.96233535e-01\n",
            "     4.72636795e+00 -5.75466204e+00]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ... -4.88638926e+00\n",
            "     4.75044203e+00 -7.56786048e-01]\n",
            " ...80155873e+00  3.11298299e+00 -3.24756050e+00 ... -7.96233535e-01\n",
            "     4.72636795e+00 -5.75466204e+00]]]], device=cpu())\n",
            "B          = NDArray([[[[ 5.93117094e+00 -4.61600447e+00 -7.43411541e+00 ...  9.49053860e+00\n",
            "     6.47611380e+00 -3.38525438e+00]\n",
            " ...93575430e+00 -6.98609781e+00  1.63659811e+00 ...  8.22474575e+00\n",
            "     2.56555057e+00  1.63004756e+00]]]], device=cpu())\n",
            "K          = 5\n",
            "W_col      = NDArray([[ 5.931171   -4.6160045  -7.4341154  ...  9.490539    6.476114\n",
            "  -3.3852544 ]\n",
            " [-0.17156623  0.21220385  0.29...0.531189\n",
            "   4.472448  ]\n",
            " [-3.9357543  -6.986098    1.6365981  ...  8.224746    2.5655506\n",
            "   1.6300476 ]], device=cpu())\n",
            "cols       = NDArray([[  8.820262     2.000786     4.89369    ...  -3.2994587   -5.6990123\n",
            "    3.9247875 ]\n",
            " [ -0.51609427   2.05299...17\n",
            "    3.9570265 ]\n",
            " [  3.2858942    3.4523911    4.7947583  ...  -0.79623353   4.726368\n",
            "   -5.754662  ]], device=cpu())\n",
            "out_h      = 13\n",
            "out_w      = 13\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x79493aaaaab0>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape13-W_shape13-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 17, 17, 1), W_shape = (5, 5, 1, 16), stride = 1, padding = 0\n",
            "backward = True, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[  1.5437562   -6.8538       4.3282647    5.4068804   -3.15688\n",
            "     -1.206689    -4.3909516    3.4969...448   -2.242325     0.6578698\n",
            "     -7.0278      -1.7489109   10.11736      2.5269346    1.7962458\n",
            "     -7.9124722 ]]]])\n",
            "W_shape    = (5, 5, 1, 16)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00]\n",
            "   [ 2.00078607e+00]\n",
            "   [ 4.89369011e+00]\n",
            "   [ 1.12044659e+01]\n",
            "   [ 9.33778954e+00]...22066e-01]\n",
            "   [ 1.05310105e-01]\n",
            "   [ 4.97272283e-01]\n",
            "   [ 1.13696384e+00]\n",
            "   [-5.08369303e+00]\n",
            "   [-5.73876619e-01]]]])\n",
            "Z_shape    = (3, 17, 17, 1)\n",
            "_W         = array([[[[  1.5437562 ,  -6.8538    ,   4.3282647 ,   5.4068804 ,\n",
            "           -3.15688   ,  -1.206689  ,  -4.3909516 , ...  -7.0278    ,  -1.7489109 ,\n",
            "           10.11736   ,   2.5269346 ,   1.7962458 ,  -7.9124722 ]]]],\n",
            "      dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00],\n",
            "         [ 2.00078607e+00],\n",
            "         [ 4.89369011e+00],\n",
            "         [ 1.12044659e+01],\n",
            "      ... 4.97272283e-01],\n",
            "         [ 1.13696384e+00],\n",
            "         [-5.08369303e+00],\n",
            "         [-5.73876619e-01]]]], dtype=float32)\n",
            "backward   = True\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00]\n",
            "   [ 2.00078607e+00]\n",
            "   [ 4.89369011e+00]\n",
            "   [ 1.12044659e+01]\n",
            "   [ 9.33778954e+00]...22066e-01]\n",
            "   [ 1.05310105e-01]\n",
            "   [ 4.97272283e-01]\n",
            "   [ 1.13696384e+00]\n",
            "   [-5.08369303e+00]\n",
            "   [-5.73876619e-01]]]])\n",
            "        b          = needle.Tensor([[[[  1.5437562   -6.8538       4.3282647    5.4068804   -3.15688\n",
            "     -1.206689    -4.3909516    3.4969...448   -2.242325     0.6578698\n",
            "     -7.0278      -1.7489109   10.11736      2.5269346    1.7962458\n",
            "     -7.9124722 ]]]])\n",
            "        padding    = 0\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00]\n",
            "   [ 2.00078607e+00]\n",
            "   [ 4.89369011e+00]\n",
            "   [ 1.12044659e+01]\n",
            "   [ 9.33778954e+00...48   -2.242325     0.6578698\n",
            "     -7.0278      -1.7489109   10.11736      2.5269346    1.7962458\n",
            "     -7.9124722 ]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x79493a966a50>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00]\n",
            "   [ 2.00078607e+00]\n",
            "   [ 4.89369011e+00]\n",
            "   [ 1.12044659e+01]\n",
            "   [ 9.33778954e+00...48   -2.242325     0.6578698\n",
            "     -7.0278      -1.7489109   10.11736      2.5269346    1.7962458\n",
            "     -7.9124722 ]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x79493a966a50>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493a9645f0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493a9645f0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x79493a966a50>\n",
            "A = NDArray([[[[ 8.82026196e+00]\n",
            "   [ 2.00078607e+00]\n",
            "   [ 4.89369011e+00]\n",
            "   [ 1.12044659e+01]\n",
            "   [ 9.33778954e+00]\n",
            "   [-...[ 1.05310105e-01]\n",
            "   [ 4.97272283e-01]\n",
            "   [ 1.13696384e+00]\n",
            "   [-5.08369303e+00]\n",
            "   [-5.73876619e-01]]]], device=cpu())\n",
            "B = NDArray([[[[  1.5437562   -6.8538       4.3282647    5.4068804   -3.15688\n",
            "     -1.206689    -4.3909516    3.4969025   ...5     0.6578698\n",
            "     -7.0278      -1.7489109   10.11736      2.5269346    1.7962458\n",
            "     -7.9124722 ]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00]\n",
            "   [ 2.00078607e+00]\n",
            "   [ 4.89369011e+00]\n",
            "   [ 1.12044659e+01]\n",
            "   [ 9.33778954e+00]\n",
            "   [-...[ 1.05310105e-01]\n",
            "   [ 4.97272283e-01]\n",
            "   [ 1.13696384e+00]\n",
            "   [-5.08369303e+00]\n",
            "   [-5.73876619e-01]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 8.82026196e+00]\n",
            "   [ 2.00078607e+00]\n",
            "   [ 4.89369011e+00]\n",
            "   [ 1.12044659e+01]\n",
            "   [ 9.33778954e+00]\n",
            "   [-...[ 1.05310105e-01]\n",
            "   [ 4.97272283e-01]\n",
            "   [ 1.13696384e+00]\n",
            "   [-5.08369303e+00]\n",
            "   [-5.73876619e-01]]]], device=cpu())\n",
            "B          = NDArray([[[[  1.5437562   -6.8538       4.3282647    5.4068804   -3.15688\n",
            "     -1.206689    -4.3909516    3.4969025   ...5     0.6578698\n",
            "     -7.0278      -1.7489109   10.11736      2.5269346    1.7962458\n",
            "     -7.9124722 ]]]], device=cpu())\n",
            "K          = 5\n",
            "W_col      = NDArray([[  1.5437562   -6.8538       4.3282647    5.4068804   -3.15688\n",
            "   -1.206689    -4.3909516    3.4969025   -5.3....242325     0.6578698\n",
            "   -7.0278      -1.7489109   10.11736      2.5269346    1.7962458\n",
            "   -7.9124722 ]], device=cpu())\n",
            "cols       = NDArray([[ 8.820262    2.000786    4.89369    ...  3.6454527   0.64491457\n",
            "   5.6970034 ]\n",
            " [ 2.000786    4.89369    11....1.1369638\n",
            "  -5.083693  ]\n",
            " [-4.294862   -4.494711    0.37293205 ...  1.1369638  -5.083693\n",
            "  -0.5738766 ]], device=cpu())\n",
            "out_h      = 13\n",
            "out_w      = 13\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x79493a966a50>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape14-W_shape14-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 17, 17, 16), W_shape = (5, 5, 16, 1), stride = 1, padding = 0\n",
            "backward = True, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[ 1.55579513e-02]\n",
            "   [-3.04658723e+00]\n",
            "   [ 4.09725952e+00]\n",
            "   [ 1.29906273e+00]\n",
            "   [-7.50546598e+00]...75421e+00]\n",
            "   [ 3.02805209e+00]\n",
            "   [-4.20992136e+00]\n",
            "   [ 4.11707735e+00]\n",
            "   [ 4.99041653e+00]\n",
            "   [ 5.11040497e+00]]]])\n",
            "W_shape    = (5, 5, 16, 1)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168e...3e+00]\n",
            "   [-1.25365603e+00 -1.71452928e+00  1.35930243e+01 ...  3.13170171e+00\n",
            "    -1.35708165e+00  1.29997072e+01]]]])\n",
            "Z_shape    = (3, 17, 17, 16)\n",
            "_W         = array([[[[ 1.55579513e-02],\n",
            "         [-3.04658723e+00],\n",
            "         [ 4.09725952e+00],\n",
            "         [ 1.29906273e+00],\n",
            "      ...-4.20992136e+00],\n",
            "         [ 4.11707735e+00],\n",
            "         [ 4.99041653e+00],\n",
            "         [ 5.11040497e+00]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "           6.08375072e-01,  2.21931624e+00,  1.66837...452928e+00,  1.35930243e+01, ...,\n",
            "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168e...3e+00]\n",
            "   [-1.25365603e+00 -1.71452928e+00  1.35930243e+01 ...  3.13170171e+00\n",
            "    -1.35708165e+00  1.29997072e+01]]]])\n",
            "        b          = needle.Tensor([[[[ 1.55579513e-02]\n",
            "   [-3.04658723e+00]\n",
            "   [ 4.09725952e+00]\n",
            "   [ 1.29906273e+00]\n",
            "   [-7.50546598e+00]...75421e+00]\n",
            "   [ 3.02805209e+00]\n",
            "   [-4.20992136e+00]\n",
            "   [ 4.11707735e+00]\n",
            "   [ 4.99041653e+00]\n",
            "   [ 5.11040497e+00]]]])\n",
            "        padding    = 0\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168...5421e+00]\n",
            "   [ 3.02805209e+00]\n",
            "   [-4.20992136e+00]\n",
            "   [ 4.11707735e+00]\n",
            "   [ 4.99041653e+00]\n",
            "   [ 5.11040497e+00]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x79493aa94080>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168...5421e+00]\n",
            "   [ 3.02805209e+00]\n",
            "   [-4.20992136e+00]\n",
            "   [ 4.11707735e+00]\n",
            "   [ 4.99041653e+00]\n",
            "   [ 5.11040497e+00]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x79493aa94080>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493aa95b80>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493aa95b80>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x79493aa94080>\n",
            "A = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168e+00]\n",
            " ...25365603e+00 -1.71452928e+00  1.35930243e+01 ...  3.13170171e+00\n",
            "    -1.35708165e+00  1.29997072e+01]]]], device=cpu())\n",
            "B = NDArray([[[[ 1.55579513e-02]\n",
            "   [-3.04658723e+00]\n",
            "   [ 4.09725952e+00]\n",
            "   [ 1.29906273e+00]\n",
            "   [-7.50546598e+00]\n",
            "   [-...[ 3.02805209e+00]\n",
            "   [-4.20992136e+00]\n",
            "   [ 4.11707735e+00]\n",
            "   [ 4.99041653e+00]\n",
            "   [ 5.11040497e+00]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168e+00]\n",
            " ...25365603e+00 -1.71452928e+00  1.35930243e+01 ...  3.13170171e+00\n",
            "    -1.35708165e+00  1.29997072e+01]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168e+00]\n",
            " ...25365603e+00 -1.71452928e+00  1.35930243e+01 ...  3.13170171e+00\n",
            "    -1.35708165e+00  1.29997072e+01]]]], device=cpu())\n",
            "B          = NDArray([[[[ 1.55579513e-02]\n",
            "   [-3.04658723e+00]\n",
            "   [ 4.09725952e+00]\n",
            "   [ 1.29906273e+00]\n",
            "   [-7.50546598e+00]\n",
            "   [-...[ 3.02805209e+00]\n",
            "   [-4.20992136e+00]\n",
            "   [ 4.11707735e+00]\n",
            "   [ 4.99041653e+00]\n",
            "   [ 5.11040497e+00]]]], device=cpu())\n",
            "K          = 5\n",
            "W_col      = NDArray([[ 1.55579513e-02]\n",
            " [-3.04658723e+00]\n",
            " [ 4.09725952e+00]\n",
            " [ 1.29906273e+00]\n",
            " [-7.50546598e+00]\n",
            " [-1.73352385e+...421e+00]\n",
            " [ 3.02805209e+00]\n",
            " [-4.20992136e+00]\n",
            " [ 4.11707735e+00]\n",
            " [ 4.99041653e+00]\n",
            " [ 5.11040497e+00]], device=cpu())\n",
            "cols       = NDArray([[  8.820262    2.000786    4.89369   ...   1.635331    8.157988\n",
            "    1.8887959]\n",
            " [  7.4703956  -1.0257913   1....2434509\n",
            "    3.5898256]\n",
            " [  5.264912    6.3784637  -2.9336812 ...   3.1317017  -1.3570817\n",
            "   12.999707 ]], device=cpu())\n",
            "out_h      = 13\n",
            "out_w      = 13\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x79493aa94080>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape15-W_shape15-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 17, 17, 16), W_shape = (1, 1, 16, 1), stride = 1, padding = 0\n",
            "backward = True, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[ 0.01555795]\n",
            "   [-3.0465872 ]\n",
            "   [ 4.0972595 ]\n",
            "   [ 1.2990627 ]\n",
            "   [-7.505466  ]\n",
            "   [-1.7335238 ]\n",
            "  ...[ 5.6893935 ]\n",
            "   [ 2.267663  ]\n",
            "   [-1.0709513 ]\n",
            "   [-5.0566583 ]\n",
            "   [-0.23777105]\n",
            "   [-9.931785  ]\n",
            "   [-0.44905776]]]])\n",
            "W_shape    = (1, 1, 16, 1)\n",
            "Z          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168e...3e+00]\n",
            "   [-1.25365603e+00 -1.71452928e+00  1.35930243e+01 ...  3.13170171e+00\n",
            "    -1.35708165e+00  1.29997072e+01]]]])\n",
            "Z_shape    = (3, 17, 17, 16)\n",
            "_W         = array([[[[ 0.01555795],\n",
            "         [-3.0465872 ],\n",
            "         [ 4.0972595 ],\n",
            "         [ 1.2990627 ],\n",
            "         [-7.505466  ]...13 ],\n",
            "         [-5.0566583 ],\n",
            "         [-0.23777105],\n",
            "         [-9.931785  ],\n",
            "         [-0.44905776]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "           6.08375072e-01,  2.21931624e+00,  1.66837...452928e+00,  1.35930243e+01, ...,\n",
            "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168e...3e+00]\n",
            "   [-1.25365603e+00 -1.71452928e+00  1.35930243e+01 ...  3.13170171e+00\n",
            "    -1.35708165e+00  1.29997072e+01]]]])\n",
            "        b          = needle.Tensor([[[[ 0.01555795]\n",
            "   [-3.0465872 ]\n",
            "   [ 4.0972595 ]\n",
            "   [ 1.2990627 ]\n",
            "   [-7.505466  ]\n",
            "   [-1.7335238 ]\n",
            "  ...[ 5.6893935 ]\n",
            "   [ 2.267663  ]\n",
            "   [-1.0709513 ]\n",
            "   [-5.0566583 ]\n",
            "   [-0.23777105]\n",
            "   [-9.931785  ]\n",
            "   [-0.44905776]]]])\n",
            "        padding    = 0\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168... 5.6893935 ]\n",
            "   [ 2.267663  ]\n",
            "   [-1.0709513 ]\n",
            "   [-5.0566583 ]\n",
            "   [-0.23777105]\n",
            "   [-9.931785  ]\n",
            "   [-0.44905776]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x79493a8d2570>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168... 5.6893935 ]\n",
            "   [ 2.267663  ]\n",
            "   [-1.0709513 ]\n",
            "   [-5.0566583 ]\n",
            "   [-0.23777105]\n",
            "   [-9.931785  ]\n",
            "   [-0.44905776]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x79493a8d2570>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493a8d2780>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493a8d2780>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x79493a8d2570>\n",
            "A = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168e+00]\n",
            " ...25365603e+00 -1.71452928e+00  1.35930243e+01 ...  3.13170171e+00\n",
            "    -1.35708165e+00  1.29997072e+01]]]], device=cpu())\n",
            "B = NDArray([[[[ 0.01555795]\n",
            "   [-3.0465872 ]\n",
            "   [ 4.0972595 ]\n",
            "   [ 1.2990627 ]\n",
            "   [-7.505466  ]\n",
            "   [-1.7335238 ]\n",
            "   [-2.5...   [ 2.267663  ]\n",
            "   [-1.0709513 ]\n",
            "   [-5.0566583 ]\n",
            "   [-0.23777105]\n",
            "   [-9.931785  ]\n",
            "   [-0.44905776]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168e+00]\n",
            " ...25365603e+00 -1.71452928e+00  1.35930243e+01 ...  3.13170171e+00\n",
            "    -1.35708165e+00  1.29997072e+01]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[ 8.82026196e+00  2.00078607e+00  4.89369011e+00 ...  6.08375072e-01\n",
            "     2.21931624e+00  1.66837168e+00]\n",
            " ...25365603e+00 -1.71452928e+00  1.35930243e+01 ...  3.13170171e+00\n",
            "    -1.35708165e+00  1.29997072e+01]]]], device=cpu())\n",
            "B          = NDArray([[[[ 0.01555795]\n",
            "   [-3.0465872 ]\n",
            "   [ 4.0972595 ]\n",
            "   [ 1.2990627 ]\n",
            "   [-7.505466  ]\n",
            "   [-1.7335238 ]\n",
            "   [-2.5...   [ 2.267663  ]\n",
            "   [-1.0709513 ]\n",
            "   [-5.0566583 ]\n",
            "   [-0.23777105]\n",
            "   [-9.931785  ]\n",
            "   [-0.44905776]]]], device=cpu())\n",
            "K          = 1\n",
            "W_col      = NDArray([[ 0.01555795]\n",
            " [-3.0465872 ]\n",
            " [ 4.0972595 ]\n",
            " [ 1.2990627 ]\n",
            " [-7.505466  ]\n",
            " [-1.7335238 ]\n",
            " [-2.5728364 ]\n",
            " [ 4....[ 5.6893935 ]\n",
            " [ 2.267663  ]\n",
            " [-1.0709513 ]\n",
            " [-5.0566583 ]\n",
            " [-0.23777105]\n",
            " [-9.931785  ]\n",
            " [-0.44905776]], device=cpu())\n",
            "cols       = NDArray([[ 8.820262   2.000786   4.89369   ...  0.6083751  2.2193162  1.6683717]\n",
            " [ 7.4703956 -1.0257913  1.5653385 .....3207941  2.2434509  3.5898256]\n",
            " [-1.253656  -1.7145293 13.593024  ...  3.1317017 -1.3570817 12.999707 ]], device=cpu())\n",
            "out_h      = 17\n",
            "out_w      = 17\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x79493a8d2570>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape16-W_shape16-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (1, 14, 14, 2), W_shape = (3, 3, 2, 2), stride = 1, padding = 0\n",
            "backward = True, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        W = ndl.Tensor(_W, device=device)\u001b[90m\u001b[39;49;00m\n",
            ">       y = ndl.conv(Z, W, padding=padding, stride=stride)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W          = needle.Tensor([[[[ -1.7671587   -8.082371  ]\n",
            "   [ -1.4591868   -3.807461  ]]\n",
            "\n",
            "  [[  4.2896194    5.705509  ]\n",
            "   [  7.3...7526     2.911123  ]\n",
            "   [-10.473016     0.61860955]]\n",
            "\n",
            "  [[ -0.65053475   0.46976614]\n",
            "   [  4.7152305  -13.698386  ]]]])\n",
            "W_shape    = (3, 3, 2, 2)\n",
            "Z          = needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   [  4.750...19315276  -8.283575  ]\n",
            "   [ -4.9275537   -7.359175  ]\n",
            "   [  8.240675     0.8211388 ]\n",
            "   [  2.8364513   -1.1133755 ]]]])\n",
            "Z_shape    = (1, 14, 14, 2)\n",
            "_W         = array([[[[ -1.7671587 ,  -8.082371  ],\n",
            "         [ -1.4591868 ,  -3.807461  ]],\n",
            "\n",
            "        [[  4.2896194 ,   5.705509  ],...016  ,   0.61860955]],\n",
            "\n",
            "        [[ -0.65053475,   0.46976614],\n",
            "         [  4.7152305 , -13.698386  ]]]], dtype=float32)\n",
            "_Z         = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...275537 ,  -7.359175  ],\n",
            "         [  8.240675  ,   0.8211388 ],\n",
            "         [  2.8364513 ,  -1.1133755 ]]]], dtype=float32)\n",
            "backward   = True\n",
            "device     = cpu()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:429: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   [  4.750...19315276  -8.283575  ]\n",
            "   [ -4.9275537   -7.359175  ]\n",
            "   [  8.240675     0.8211388 ]\n",
            "   [  2.8364513   -1.1133755 ]]]])\n",
            "        b          = needle.Tensor([[[[ -1.7671587   -8.082371  ]\n",
            "   [ -1.4591868   -3.807461  ]]\n",
            "\n",
            "  [[  4.2896194    5.705509  ]\n",
            "   [  7.3...7526     2.911123  ]\n",
            "   [-10.473016     0.61860955]]\n",
            "\n",
            "  [[ -0.65053475   0.46976614]\n",
            "   [  4.7152305  -13.698386  ]]]])\n",
            "        padding    = 0\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   [  4.75...526     2.911123  ]\n",
            "   [-10.473016     0.61860955]]\n",
            "\n",
            "  [[ -0.65053475   0.46976614]\n",
            "   [  4.7152305  -13.698386  ]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x79493a8d07a0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   [  4.75...526     2.911123  ]\n",
            "   [-10.473016     0.61860955]]\n",
            "\n",
            "  [[ -0.65053475   0.46976614]\n",
            "   [  4.7152305  -13.698386  ]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x79493a8d07a0>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493a8d0230>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79493a8d0230>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x79493a8d07a0>\n",
            "A = NDArray([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   [  4.750442   ...83575  ]\n",
            "   [ -4.9275537   -7.359175  ]\n",
            "   [  8.240675     0.8211388 ]\n",
            "   [  2.8364513   -1.1133755 ]]]], device=cpu())\n",
            "B = NDArray([[[[ -1.7671587   -8.082371  ]\n",
            "   [ -1.4591868   -3.807461  ]]\n",
            "\n",
            "  [[  4.2896194    5.705509  ]\n",
            "   [  7.3328934...123  ]\n",
            "   [-10.473016     0.61860955]]\n",
            "\n",
            "  [[ -0.65053475   0.46976614]\n",
            "   [  4.7152305  -13.698386  ]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   [  4.750442   ...83575  ]\n",
            "   [ -4.9275537   -7.359175  ]\n",
            "   [  8.240675     0.8211388 ]\n",
            "   [  2.8364513   -1.1133755 ]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[  8.820262     2.000786  ]\n",
            "   [  4.89369     11.204466  ]\n",
            "   [  9.33779     -4.8863893 ]\n",
            "   [  4.750442   ...83575  ]\n",
            "   [ -4.9275537   -7.359175  ]\n",
            "   [  8.240675     0.8211388 ]\n",
            "   [  2.8364513   -1.1133755 ]]]], device=cpu())\n",
            "B          = NDArray([[[[ -1.7671587   -8.082371  ]\n",
            "   [ -1.4591868   -3.807461  ]]\n",
            "\n",
            "  [[  4.2896194    5.705509  ]\n",
            "   [  7.3328934...123  ]\n",
            "   [-10.473016     0.61860955]]\n",
            "\n",
            "  [[ -0.65053475   0.46976614]\n",
            "   [  4.7152305  -13.698386  ]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[ -1.7671587   -8.082371  ]\n",
            " [ -1.4591868   -3.807461  ]\n",
            " [  4.2896194    5.705509  ]\n",
            " [  7.3328934    4.2627...     2.911123  ]\n",
            " [-10.473016     0.61860955]\n",
            " [ -0.65053475   0.46976614]\n",
            " [  4.7152305  -13.698386  ]], device=cpu())\n",
            "cols       = NDArray([[ 8.820262    2.000786    4.89369    ... -1.8137058  -3.3623023\n",
            "  -1.7977659 ]\n",
            " [ 4.89369    11.204466    9.3...8.240675\n",
            "   0.8211388 ]\n",
            " [ 3.7359416  -5.9447246   3.8662648  ...  0.8211388   2.8364513\n",
            "  -1.1133755 ]], device=cpu())\n",
            "out_h      = 12\n",
            "out_w      = 12\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x79493a8d07a0>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape0-W_shape0-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 1, padding = 0\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
            "            2.1704152 ,  -0.38803983],\n",
            "        ... [ -4.09374   ,   3.7291534 , -10.551835  , ...,   0.31741843,\n",
            "            0.03223436,   2.0512383 ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x79493aa95e20>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x79493aa97b30>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 14, 14, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x79493aa96630>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 14, 14, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape1-W_shape1-1-1] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 1, padding = 1\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
            "            2.1704152 ,  -0.38803983],\n",
            "        ... [ -4.09374   ,   3.7291534 , -10.551835  , ...,   0.31741843,\n",
            "            0.03223436,   2.0512383 ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "padding    = 1\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x79493aadab70>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x79493aadb2f0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 14, 14, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x79493aada630>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 14, 14, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape2-W_shape2-1-2] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 16), stride = 1, padding = 2\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Z_shape    = (3, 16, 16, 8)\n",
            "_W         = array([[[[  0.40910086,  -0.64982927,  11.320294  , ...,  -0.12077556,\n",
            "            1.428692  ,  -5.5845156 ],\n",
            "        ... [  1.1511405 ,   0.7441038 ,  16.463472  , ...,  -6.8931007 ,\n",
            "           -0.5833115 ,  -2.504636  ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "padding    = 2\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x79493aa68380>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x79493aa6be30>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 16, 16, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x79493aa6b1a0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 16, 16, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape3-W_shape3-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 14), stride = 1, padding = 0\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (3, 3, 8, 14)\n",
            "Z_shape    = (3, 16, 16, 8)\n",
            "_W         = array([[[[ 4.09100860e-01, -6.49829268e-01,  1.13202944e+01, ...,\n",
            "          -5.56089449e+00, -4.84385538e+00, -1.20775...448557e+00, -7.73867989e+00, ...,\n",
            "          -1.13336074e+00, -1.21658230e+00, -4.79330921e+00]]]],\n",
            "      dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x79493a8d3680>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x79493a8d15e0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 16, 16, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x79493a8d08f0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 16, 16, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape4-W_shape4-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 2), W_shape = (3, 3, 2, 14), stride = 1, padding = 0\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (3, 3, 2, 14)\n",
            "Z_shape    = (3, 16, 16, 2)\n",
            "_W         = array([[[[ -8.0968    ,  -2.5552022 ,   8.703147  ,  -1.4674252 ,\n",
            "            4.5861077 ,  -0.28521433,   4.383634  , ...        -8.13161   ,  -0.67411226,  -2.9204676 ,   1.675528  ,\n",
            "          -12.187821  ,   5.5746226 ]]]], dtype=float32)\n",
            "_Z         = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x79493aa96a50>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x79493aa95a00>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 16, 16, 2), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x79493aa96450>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 16, 16, 2)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape5-W_shape5-2-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 2, padding = 0\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
            "            2.1704152 ,  -0.38803983],\n",
            "        ... [ -4.09374   ,   3.7291534 , -10.551835  , ...,   0.31741843,\n",
            "            0.03223436,   2.0512383 ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x79493aa955e0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x79493aa95b50>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 14, 14, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x79493aa95310>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 14, 14, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape6-W_shape6-2-1] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (3, 3, 8, 16), stride = 2, padding = 1\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "_W         = array([[[[  4.282669  ,   8.133604  ,  -4.6223483 , ...,   2.0798197 ,\n",
            "            2.1704152 ,  -0.38803983],\n",
            "        ... [ -4.09374   ,   3.7291534 , -10.551835  , ...,   0.31741843,\n",
            "            0.03223436,   2.0512383 ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "padding    = 1\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x79493aadaae0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x79493aadb440>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 14, 14, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x79493aad93d0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 14, 14, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape7-W_shape7-2-2] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 16), stride = 2, padding = 2\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (3, 3, 8, 16)\n",
            "Z_shape    = (3, 16, 16, 8)\n",
            "_W         = array([[[[  0.40910086,  -0.64982927,  11.320294  , ...,  -0.12077556,\n",
            "            1.428692  ,  -5.5845156 ],\n",
            "        ... [  1.1511405 ,   0.7441038 ,  16.463472  , ...,  -6.8931007 ,\n",
            "           -0.5833115 ,  -2.504636  ]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "padding    = 2\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x79493aa97410>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x79493aa96870>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 16, 16, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x79493aa95a00>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 16, 16, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape8-W_shape8-2-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 8), W_shape = (3, 3, 8, 14), stride = 2, padding = 0\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (3, 3, 8, 14)\n",
            "Z_shape    = (3, 16, 16, 8)\n",
            "_W         = array([[[[ 4.09100860e-01, -6.49829268e-01,  1.13202944e+01, ...,\n",
            "          -5.56089449e+00, -4.84385538e+00, -1.20775...448557e+00, -7.73867989e+00, ...,\n",
            "          -1.13336074e+00, -1.21658230e+00, -4.79330921e+00]]]],\n",
            "      dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x79493aad9670>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...434513e+00, -4.41384506e+00, ...,\n",
            "          -6.15245628e+00,  3.33514667e+00, -1.35630560e+00]]]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x79493aad9eb0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 16, 16, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x79493aad9820>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 16, 16, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape9-W_shape9-2-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 2), W_shape = (3, 3, 2, 14), stride = 2, padding = 0\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (3, 3, 2, 14)\n",
            "Z_shape    = (3, 16, 16, 2)\n",
            "_W         = array([[[[ -8.0968    ,  -2.5552022 ,   8.703147  ,  -1.4674252 ,\n",
            "            4.5861077 ,  -0.28521433,   4.383634  , ...        -8.13161   ,  -0.67411226,  -2.9204676 ,   1.675528  ,\n",
            "          -12.187821  ,   5.5746226 ]]]], dtype=float32)\n",
            "_Z         = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x79493aa8e810>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...22368  ,   4.2222714 ],\n",
            "         [ -6.064339  ,   1.4188478 ],\n",
            "         [ -1.4109794 ,  -5.791016  ]]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x79493aa8c7a0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 16, 16, 2), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x79493aa8d9d0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 16, 16, 2)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape10-W_shape10-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 16, 16, 24), W_shape = (3, 3, 24, 14), stride = 1, padding = 0\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (3, 3, 24, 14)\n",
            "Z_shape    = (3, 16, 16, 24)\n",
            "_W         = array([[[[ -1.3245817 ,   1.0111231 ,  -1.9236585 , ...,  -2.5907016 ,\n",
            "           -0.36175704,   4.6234684 ],\n",
            "        ... [  3.2300415 ,  -2.4161792 ,  -3.420825  , ...,  -9.444658  ,\n",
            "            8.537833  ,   2.3818388 ]]]], dtype=float32)\n",
            "_Z         = array([[[[  8.820262  ,   2.000786  ,   4.89369   , ...,   3.2680929 ,\n",
            "            4.322181  ,  -3.7108252 ],\n",
            "        ... [  2.5084004 ,   3.1399443 ,  -0.12958507, ...,   0.13740699,\n",
            "           -1.400853  ,   0.07475674]]]], dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[  8.820262  ,   2.000786  ,   4.89369   , ...,   3.2680929 ,\n",
            "            4.322181  ,  -3.7108252 ],\n",
            "        ... [  2.5084004 ,   3.1399443 ,  -0.12958507, ...,   0.13740699,\n",
            "           -1.400853  ,   0.07475674]]]], dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x79493aa8dbe0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[  8.820262  ,   2.000786  ,   4.89369   , ...,   3.2680929 ,\n",
            "            4.322181  ,  -3.7108252 ],\n",
            "        ... [  2.5084004 ,   3.1399443 ,  -0.12958507, ...,   0.13740699,\n",
            "           -1.400853  ,   0.07475674]]]], dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[  8.820262  ,   2.000786  ,   4.89369   , ...,   3.2680929 ,\n",
            "            4.322181  ,  -3.7108252 ],\n",
            "        ... [  2.5084004 ,   3.1399443 ,  -0.12958507, ...,   0.13740699,\n",
            "           -1.400853  ,   0.07475674]]]], dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[  8.820262  ,   2.000786  ,   4.89369   , ...,   3.2680929 ,\n",
            "            4.322181  ,  -3.7108252 ],\n",
            "        ... [  2.5084004 ,   3.1399443 ,  -0.12958507, ...,   0.13740699,\n",
            "           -1.400853  ,   0.07475674]]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x79493aa8f620>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 16, 16, 24), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x79493aa8f5f0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 16, 16, 24)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape11-W_shape11-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 14, 14, 8), W_shape = (5, 5, 8, 16), stride = 1, padding = 0\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (5, 5, 8, 16)\n",
            "Z_shape    = (3, 14, 14, 8)\n",
            "_W         = array([[[[ 4.28266907e+00,  8.13360405e+00, -4.62234831e+00, ...,\n",
            "           2.07981968e+00,  2.17041516e+00, -3.88039...947495e+00, -4.97804356e+00, ...,\n",
            "          -5.69430470e-01,  4.27775383e-01, -3.84437203e+00]]]],\n",
            "      dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x79493a9648f0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...166728e+00,  4.62055349e+00, ...,\n",
            "          -6.23090088e-01, -8.48226726e-01, -2.29984760e+00]]]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x79493a966cf0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 14, 14, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x79493a966cc0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 14, 14, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape12-W_shape12-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 17, 17, 8), W_shape = (5, 5, 8, 16), stride = 1, padding = 0\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (5, 5, 8, 16)\n",
            "Z_shape    = (3, 17, 17, 8)\n",
            "_W         = array([[[[ 5.93117094e+00, -4.61600447e+00, -7.43411541e+00, ...,\n",
            "           9.49053860e+00,  6.47611380e+00, -3.38525...609781e+00,  1.63659811e+00, ...,\n",
            "           8.22474575e+00,  2.56555057e+00,  1.63004756e+00]]]],\n",
            "      dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...298299e+00, -3.24756050e+00, ...,\n",
            "          -7.96233535e-01,  4.72636795e+00, -5.75466204e+00]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...298299e+00, -3.24756050e+00, ...,\n",
            "          -7.96233535e-01,  4.72636795e+00, -5.75466204e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x79493aa8e150>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...298299e+00, -3.24756050e+00, ...,\n",
            "          -7.96233535e-01,  4.72636795e+00, -5.75466204e+00]]]],\n",
            "      dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...298299e+00, -3.24756050e+00, ...,\n",
            "          -7.96233535e-01,  4.72636795e+00, -5.75466204e+00]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "          -4.88638926e+00,  4.75044203e+00, -7.56786...298299e+00, -3.24756050e+00, ...,\n",
            "          -7.96233535e-01,  4.72636795e+00, -5.75466204e+00]]]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x79493aa8f770>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 17, 17, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x79493aa8e5a0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 17, 17, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape13-W_shape13-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 17, 17, 1), W_shape = (5, 5, 1, 16), stride = 1, padding = 0\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (5, 5, 1, 16)\n",
            "Z_shape    = (3, 17, 17, 1)\n",
            "_W         = array([[[[  1.5437562 ,  -6.8538    ,   4.3282647 ,   5.4068804 ,\n",
            "           -3.15688   ,  -1.206689  ,  -4.3909516 , ...  -7.0278    ,  -1.7489109 ,\n",
            "           10.11736   ,   2.5269346 ,   1.7962458 ,  -7.9124722 ]]]],\n",
            "      dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00],\n",
            "         [ 2.00078607e+00],\n",
            "         [ 4.89369011e+00],\n",
            "         [ 1.12044659e+01],\n",
            "      ... 4.97272283e-01],\n",
            "         [ 1.13696384e+00],\n",
            "         [-5.08369303e+00],\n",
            "         [-5.73876619e-01]]]], dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00],\n",
            "         [ 2.00078607e+00],\n",
            "         [ 4.89369011e+00],\n",
            "         [ 1.12044659e+01],\n",
            "      ... 4.97272283e-01],\n",
            "         [ 1.13696384e+00],\n",
            "         [-5.08369303e+00],\n",
            "         [-5.73876619e-01]]]], dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x79493aafafc0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00],\n",
            "         [ 2.00078607e+00],\n",
            "         [ 4.89369011e+00],\n",
            "         [ 1.12044659e+01],\n",
            "      ... 4.97272283e-01],\n",
            "         [ 1.13696384e+00],\n",
            "         [-5.08369303e+00],\n",
            "         [-5.73876619e-01]]]], dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00],\n",
            "         [ 2.00078607e+00],\n",
            "         [ 4.89369011e+00],\n",
            "         [ 1.12044659e+01],\n",
            "      ... 4.97272283e-01],\n",
            "         [ 1.13696384e+00],\n",
            "         [-5.08369303e+00],\n",
            "         [-5.73876619e-01]]]], dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00],\n",
            "         [ 2.00078607e+00],\n",
            "         [ 4.89369011e+00],\n",
            "         [ 1.12044659e+01],\n",
            "      ... 4.97272283e-01],\n",
            "         [ 1.13696384e+00],\n",
            "         [-5.08369303e+00],\n",
            "         [-5.73876619e-01]]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x79493aafb500>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 17, 17, 1), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x79493aafb8c0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 17, 17, 1)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape14-W_shape14-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 17, 17, 16), W_shape = (5, 5, 16, 1), stride = 1, padding = 0\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (5, 5, 16, 1)\n",
            "Z_shape    = (3, 17, 17, 16)\n",
            "_W         = array([[[[ 1.55579513e-02],\n",
            "         [-3.04658723e+00],\n",
            "         [ 4.09725952e+00],\n",
            "         [ 1.29906273e+00],\n",
            "      ...-4.20992136e+00],\n",
            "         [ 4.11707735e+00],\n",
            "         [ 4.99041653e+00],\n",
            "         [ 5.11040497e+00]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "           6.08375072e-01,  2.21931624e+00,  1.66837...452928e+00,  1.35930243e+01, ...,\n",
            "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "           6.08375072e-01,  2.21931624e+00,  1.66837...452928e+00,  1.35930243e+01, ...,\n",
            "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x79493aa8f740>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "           6.08375072e-01,  2.21931624e+00,  1.66837...452928e+00,  1.35930243e+01, ...,\n",
            "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
            "      dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "           6.08375072e-01,  2.21931624e+00,  1.66837...452928e+00,  1.35930243e+01, ...,\n",
            "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "           6.08375072e-01,  2.21931624e+00,  1.66837...452928e+00,  1.35930243e+01, ...,\n",
            "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x79493aa8dd60>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 17, 17, 16), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x79493aa8f1a0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 17, 17, 16)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape15-W_shape15-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (3, 17, 17, 16), W_shape = (1, 1, 16, 1), stride = 1, padding = 0\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (1, 1, 16, 1)\n",
            "Z_shape    = (3, 17, 17, 16)\n",
            "_W         = array([[[[ 0.01555795],\n",
            "         [-3.0465872 ],\n",
            "         [ 4.0972595 ],\n",
            "         [ 1.2990627 ],\n",
            "         [-7.505466  ]...13 ],\n",
            "         [-5.0566583 ],\n",
            "         [-0.23777105],\n",
            "         [-9.931785  ],\n",
            "         [-0.44905776]]]], dtype=float32)\n",
            "_Z         = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "           6.08375072e-01,  2.21931624e+00,  1.66837...452928e+00,  1.35930243e+01, ...,\n",
            "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
            "      dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "           6.08375072e-01,  2.21931624e+00,  1.66837...452928e+00,  1.35930243e+01, ...,\n",
            "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x794a1985c680>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "           6.08375072e-01,  2.21931624e+00,  1.66837...452928e+00,  1.35930243e+01, ...,\n",
            "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
            "      dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "           6.08375072e-01,  2.21931624e+00,  1.66837...452928e+00,  1.35930243e+01, ...,\n",
            "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
            "      dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[ 8.82026196e+00,  2.00078607e+00,  4.89369011e+00, ...,\n",
            "           6.08375072e-01,  2.21931624e+00,  1.66837...452928e+00,  1.35930243e+01, ...,\n",
            "           3.13170171e+00, -1.35708165e+00,  1.29997072e+01]]]],\n",
            "      dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x794a1985cb30>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 17, 17, 16), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x794a1985c320>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 17, 17, 16)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape16-W_shape16-1-0] _\u001b[0m\n",
            "\n",
            "Z_shape = (1, 14, 14, 2), W_shape = (3, 3, 2, 2), stride = 1, padding = 0\n",
            "backward = True, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mZ_shape, W_shape, stride, padding\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, op_conv_shapes)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mTrue\u001b[39;49;00m, \u001b[94mFalse\u001b[39;49;00m], ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mbackward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mforward\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_op_conv\u001b[39;49;00m(Z_shape, W_shape, stride, padding, backward, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = np.random.randn(*Z_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _Z = _Z.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        _W = np.random.randn(*W_shape)*\u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        _W = _W.astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            ">       Z = ndl.Tensor(_Z, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "W_shape    = (3, 3, 2, 2)\n",
            "Z_shape    = (1, 14, 14, 2)\n",
            "_W         = array([[[[ -1.7671587 ,  -8.082371  ],\n",
            "         [ -1.4591868 ,  -3.807461  ]],\n",
            "\n",
            "        [[  4.2896194 ,   5.705509  ],...016  ,   0.61860955]],\n",
            "\n",
            "        [[ -0.65053475,   0.46976614],\n",
            "         [  4.7152305 , -13.698386  ]]]], dtype=float32)\n",
            "_Z         = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...275537 ,  -7.359175  ],\n",
            "         [  8.240675  ,   0.8211388 ],\n",
            "         [  2.8364513 ,  -1.1133755 ]]]], dtype=float32)\n",
            "backward   = True\n",
            "device     = cuda()\n",
            "padding    = 0\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:427: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...275537 ,  -7.359175  ],\n",
            "         [  8.240675  ,   0.8211388 ],\n",
            "         [  2.8364513 ,  -1.1133755 ]]]], dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x79493a9d1280>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...275537 ,  -7.359175  ],\n",
            "         [  8.240675  ,   0.8211388 ],\n",
            "         [  2.8364513 ,  -1.1133755 ]]]], dtype=float32)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...275537 ,  -7.359175  ],\n",
            "         [  8.240675  ,   0.8211388 ],\n",
            "         [  2.8364513 ,  -1.1133755 ]]]], dtype=float32)\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[  8.820262  ,   2.000786  ],\n",
            "         [  4.89369   ,  11.204466  ],\n",
            "         [  9.33779   ,  -4.8863893 ],\n",
            " ...275537 ,  -7.359175  ],\n",
            "         [  8.240675  ,   0.8211388 ],\n",
            "         [  2.8364513 ,  -1.1133755 ]]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x79493a9d39e0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (1, 14, 14, 2), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x79493a9d1d00>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (1, 14, 14, 2)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape0-W_shape0-1-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape1-W_shape1-1-1]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape2-W_shape2-1-2]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape3-W_shape3-1-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape4-W_shape4-1-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape5-W_shape5-2-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape6-W_shape6-2-1]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape7-W_shape7-2-2]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape8-W_shape8-2-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape9-W_shape9-2-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape10-W_shape10-1-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape11-W_shape11-1-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape12-W_shape12-1-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape13-W_shape13-1-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape14-W_shape14-1-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape15-W_shape15-1-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape16-W_shape16-1-0]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape0-W_shape0-1-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape1-W_shape1-1-1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape2-W_shape2-1-2]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape3-W_shape3-1-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape4-W_shape4-1-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape5-W_shape5-2-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape6-W_shape6-2-1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape7-W_shape7-2-2]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape8-W_shape8-2-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape9-W_shape9-2-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape10-W_shape10-1-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape11-W_shape11-1-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape12-W_shape12-1-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape13-W_shape13-1-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape14-W_shape14-1-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape15-W_shape15-1-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_op_conv[backward-needle.backend_ndarray.ndarray_backend_cuda-Z_shape16-W_shape16-1-0]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31m===================== \u001b[31m\u001b[1m34 failed\u001b[0m, \u001b[33m1769 deselected\u001b[0m\u001b[31m in 10.15s\u001b[0m\u001b[31m =====================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"op_conv and backward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV40MCaK66oW"
      },
      "source": [
        "-----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6RpCM6v66oW"
      },
      "source": [
        "### nn.Conv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "7TLv4pnB66oW"
      },
      "source": [
        "#### Fixing init._calculate_fans for convolution\n",
        "Previously, we have implemented Kaiming uniform/normal initializations, where we essentially assigned `fan_in = input_size` and `fan_out = output_size`.\n",
        "For convolution, this becomes somewhat more detailed, in that you should multiply both of these by the \"receptive field size\", which is in this case just the product of the kernel sizes -- which in our case are always going to be the same, i.e., $k\\times k$ kernels.\n",
        "\n",
        "**You will need to edit your `kaiming_uniform` in `python/needle/init/init_initializers.py`, etc. init functions to support multidimensional arrays.** In particular, it should support a new `shape` argument which is then passed to, e.g., the underlying `rand` function. Specifically, if the argument `shape` is not `None`, then ignore `fan_in` and `fan_out`, and use the value of `shape` for initializations instead.\n",
        "\n",
        "You can test this below; though it is not _directly_ graded, it must match ours to pass the nn.Conv mugrade tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwT8j-ga66oW",
        "outputId": "2e79cf2e-ad04-4c8a-8103-69dd114d789b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: langsmith-0.4.42, typeguard-4.4.4, anyio-4.11.0\n",
            "collected 1803 items / 1801 deselected / 2 selected                            \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py::test_init_kaiming_uniform[needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_init_kaiming_uniform[needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m____ test_init_kaiming_uniform[needle.backend_ndarray.ndarray_backend_cuda] ____\u001b[0m\n",
            "\n",
            "device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_init_kaiming_uniform\u001b[39;49;00m(device):\u001b[90m\u001b[39;49;00m\n",
            "        _A = np.random.randn(\u001b[94m3\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m, \u001b[94m16\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            ">       A = ndl.Tensor(_A, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "_A         = array([[[[-7.62114512e-01, -8.87780137e-01,  9.36398544e-01, ...,\n",
            "          -8.01496885e-01, -6.47181432e-01,  4.72247...2.62466179e-02, -1.14335160e-01,  7.43553516e-01, ...,\n",
            "           1.36606007e+00,  1.55511403e+00,  6.13326226e-01]]]])\n",
            "device     = cuda()\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:167: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:220: in __init__\n",
            "    \u001b[0mcached_data = Tensor._array_from_numpy(array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        array      = array([[[[-7.62114512e-01, -8.87780137e-01,  9.36398544e-01, ...,\n",
            "          -8.01496885e-01, -6.47181432e-01,  4.72247...2.62466179e-02, -1.14335160e-01,  7.43553516e-01, ...,\n",
            "           1.36606007e+00,  1.55511403e+00,  6.13326226e-01]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        kwargs     = {}\n",
            "        requires_grad = True\n",
            "        self       = <[AttributeError(\"'Tensor' object has no attribute 'cached_data'\") raised in repr()] Tensor object at 0x797742d44140>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:233: in _array_from_numpy\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m array_api.array(numpy_array, device=device, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = None\n",
            "        numpy_array = array([[[[-7.62114512e-01, -8.87780137e-01,  9.36398544e-01, ...,\n",
            "          -8.01496885e-01, -6.47181432e-01,  4.72247...2.62466179e-02, -1.14335160e-01,  7.43553516e-01, ...,\n",
            "           1.36606007e+00,  1.55511403e+00,  6.13326226e-01]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:701: in array\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(a, device=device)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = array([[[[-7.62114512e-01, -8.87780137e-01,  9.36398544e-01, ...,\n",
            "          -8.01496885e-01, -6.47181432e-01,  4.72247...2.62466179e-02, -1.14335160e-01,  7.43553516e-01, ...,\n",
            "           1.36606007e+00,  1.55511403e+00,  6.13326226e-01]]]])\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[-7.62114512e-01, -8.87780137e-01,  9.36398544e-01, ...,\n",
            "          -8.01496885e-01, -6.47181432e-01,  4.72247...2.62466179e-02, -1.14335160e-01,  7.43553516e-01, ...,\n",
            "           1.36606007e+00,  1.55511403e+00,  6.13326226e-01]]]])\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x797742ee2900>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 3, 16, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x797742ee1a60>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 3, 16, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_init_kaiming_uniform[needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31m================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m1 passed\u001b[0m, \u001b[33m1801 deselected\u001b[0m\u001b[31m in 4.54s\u001b[0m\u001b[31m =================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"kaiming_uniform\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89lWtHc966oW"
      },
      "source": [
        "#### Implementing nn.Conv\n",
        "\n",
        "Essentially, nn.Conv is just a wrapper of the convolution operator we previously implemented\n",
        "which adds a bias term, initializes the weight and bias, and ensures that the padding is set so that the input and output dimensions are the same (in the `stride=1` case, anyways).\n",
        "\n",
        "Importantly, nn.Conv should support NCHW format instead of NHWC format. In particular, we think this makes more sense given our current BatchNorm implementation. You can implement this by applying `transpose` twice to both the input and output.  \n",
        "\n",
        "- Ensure nn.Conv works for `(N, C, H, W)` tensors even though we implemented the conv op for `(N, H, W, C)` tensors\n",
        "- Initialize the `(k, k, i, o)` weight tensor using Kaiming uniform initialization with default settings\n",
        "- Initialize the `(o,)` bias tensor using uniform initialization on the interval $\\displaystyle\\pm\\frac{1}{\\sqrt{\\verb|in_channels| \\times \\verb|kernel_size|^2}}$\n",
        "- Calculate the appropriate padding to ensure input and output dimensions are the same\n",
        "- Calculate the convolution, then add the properly-broadcasted bias term if present\n",
        "\n",
        "You can now test your nn.Conv against PyTorch's nn.Conv2d with the two PyTest calls below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swQSWPCZ66oW",
        "outputId": "e06e252e-511a-49a1-f8dd-281b3be1412a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: langsmith-0.4.42, typeguard-4.4.4, anyio-4.11.0\n",
            "collected 1803 items / 1793 deselected / 10 selected                           \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-4-8-16-3-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 10%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-8-16-3-2] \u001b[31mFAILED\u001b[0m\u001b[31m [ 20%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-8-8-3-2] \u001b[31mFAILED\u001b[0m\u001b[31m [ 30%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-16-8-3-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 40%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-16-8-3-2] \u001b[31mFAILED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-4-8-16-3-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 60%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-8-16-3-2] \u001b[31mFAILED\u001b[0m\u001b[31m [ 70%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-8-8-3-2] \u001b[31mFAILED\u001b[0m\u001b[31m [ 80%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-16-8-3-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 90%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-16-8-3-2] \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-4-8-16-3-1] __\u001b[0m\n",
            "\n",
            "s = 4, cin = 8, cout = 16, k = 3, stride = 1, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_forward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        x = ndl.init.rand(\u001b[94m10\u001b[39;49;00m, cin, s, s, device=device)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        g = torch.nn.Conv2d(cin, cout, k, stride=stride, padding=k//\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        g.weight.data = torch.tensor(f.weight.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        g.bias.data = torch.tensor(f.bias.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        z = torch.tensor(x.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m np.linalg.norm(f(x).cached_data.numpy() - g(z).data.numpy()) < \u001b[94m1e-3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                              ^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "cin        = 8\n",
            "cout       = 16\n",
            "device     = cpu()\n",
            "f          = <needle.nn.nn_conv.Conv object at 0x7813436d3440>\n",
            "g          = Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "k          = 3\n",
            "s          = 4\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "x          = needle.Tensor([[[[2.30571285e-01 2.68709034e-01 8.00255597e-01 9.55568373e-01]\n",
            "   [3.16550195e-01 8.26805294e-01 1.039...e-01 7.63746858e-01 6.13455363e-02 4.62761223e-01]\n",
            "   [5.51044010e-03 8.10290754e-01 9.50486064e-01 3.51073705e-02]]]])\n",
            "z          = tensor([[[[2.3057e-01, 2.6871e-01, 8.0026e-01, 9.5557e-01],\n",
            "          [3.1655e-01, 8.2681e-01, 1.0399e-01, 6.3398e-01]...       [1.8104e-01, 7.6375e-01, 6.1346e-02, 4.6276e-01],\n",
            "          [5.5104e-03, 8.1029e-01, 9.5049e-01, 3.5107e-02]]]])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:357: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_basic.py\u001b[0m:75: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[2.30571285e-01 2.68709034e-01 8.00255597e-01 9.55568373e-01]\n",
            "   [3.16550195e-01 8.26805294e-01 1.03...01 7.63746858e-01 6.13455363e-02 4.62761223e-01]\n",
            "   [5.51044010e-03 8.10290754e-01 9.50486064e-01 3.51073705e-02]]]]),)\n",
            "        kwargs     = {}\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x7813436d3440>\n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_conv.py\u001b[0m:57: in forward\n",
            "    \u001b[0mout = ops.conv(out, \u001b[96mself\u001b[39;49;00m.weight, stride=\u001b[96mself\u001b[39;49;00m.stride, padding=\u001b[96mself\u001b[39;49;00m.padding)\u001b[90m\u001b[39;49;00m\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        out        = needle.Tensor([[[[2.30571285e-01 7.98689246e-01 1.98990941e-01 ... 1.16558611e-01\n",
            "    9.71763074e-01 9.55046654e-01]\n",
            " ...0486064e-01]\n",
            "   [2.43940815e-01 5.71497440e-01 2.26491272e-01 ... 5.26584268e-01\n",
            "    4.45096269e-02 3.51073705e-02]]]])\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x7813436d3440>\n",
            "        x          = needle.Tensor([[[[2.30571285e-01 2.68709034e-01 8.00255597e-01 9.55568373e-01]\n",
            "   [3.16550195e-01 8.26805294e-01 1.039...e-01 7.63746858e-01 6.13455363e-02 4.62761223e-01]\n",
            "   [5.51044010e-03 8.10290754e-01 9.50486064e-01 3.51073705e-02]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[2.30571285e-01 7.98689246e-01 1.98990941e-01 ... 1.16558611e-01\n",
            "    9.71763074e-01 9.55046654e-01]\n",
            " ...0486064e-01]\n",
            "   [2.43940815e-01 5.71497440e-01 2.26491272e-01 ... 5.26584268e-01\n",
            "    4.45096269e-02 3.51073705e-02]]]])\n",
            "        b          = needle.Tensor([[[[ 0.02818251  0.12423962  0.05933046 ...  0.24571836 -0.24766244\n",
            "    -0.238371  ]\n",
            "   [-0.27700204  0....18  0.07989958\n",
            "    -0.12652083]\n",
            "   [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\n",
            "     0.07735741]]]])\n",
            "        padding    = 1\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[2.30571285e-01 7.98689246e-01 1.98990941e-01 ... 1.16558611e-01\n",
            "    9.71763074e-01 9.55046654e-01]\n",
            "...8  0.07989958\n",
            "    -0.12652083]\n",
            "   [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\n",
            "     0.07735741]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x78125e9bc3b0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[2.30571285e-01 7.98689246e-01 1.98990941e-01 ... 1.16558611e-01\n",
            "    9.71763074e-01 9.55046654e-01]\n",
            "...8  0.07989958\n",
            "    -0.12652083]\n",
            "   [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\n",
            "     0.07735741]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x78125e9bc3b0>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x78125e7028d0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x78125e7028d0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x78125e9bc3b0>\n",
            "A = NDArray([[[[2.30571285e-01 7.98689246e-01 1.98990941e-01 ... 1.16558611e-01\n",
            "    9.71763074e-01 9.55046654e-01]\n",
            "   [2.6...  [2.43940815e-01 5.71497440e-01 2.26491272e-01 ... 5.26584268e-01\n",
            "    4.45096269e-02 3.51073705e-02]]]], device=cpu())\n",
            "B = NDArray([[[[ 0.02818251  0.12423962  0.05933046 ...  0.24571836 -0.24766244\n",
            "    -0.238371  ]\n",
            "   [-0.27700204  0.192038...\n",
            "    -0.12652083]\n",
            "   [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\n",
            "     0.07735741]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[2.30571285e-01 7.98689246e-01 1.98990941e-01 ... 1.16558611e-01\n",
            "    9.71763074e-01 9.55046654e-01]\n",
            "   [2.6...  [2.43940815e-01 5.71497440e-01 2.26491272e-01 ... 5.26584268e-01\n",
            "    4.45096269e-02 3.51073705e-02]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.0...  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]]]], device=cpu())\n",
            "B          = NDArray([[[[ 0.02818251  0.12423962  0.05933046 ...  0.24571836 -0.24766244\n",
            "    -0.238371  ]\n",
            "   [-0.27700204  0.192038...\n",
            "    -0.12652083]\n",
            "   [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\n",
            "     0.07735741]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[ 0.02818251  0.12423962  0.05933046 ...  0.24571836 -0.24766244\n",
            "  -0.238371  ]\n",
            " [-0.27700204  0.19203815  0....07989958\n",
            "  -0.12652083]\n",
            " [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\n",
            "   0.07735741]], device=cpu())\n",
            "cols       = NDArray([[0.         0.         0.         ... 0.4016882  0.9554659  0.6386092 ]\n",
            " [0.         0.         0.         .....        0.         0.        ]\n",
            " [0.9809794  0.50053746 0.14198647 ... 0.         0.         0.        ]], device=cpu())\n",
            "out_h      = 4\n",
            "out_w      = 4\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x78125e9bc3b0>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-8-16-3-2] _\u001b[0m\n",
            "\n",
            "s = 32, cin = 8, cout = 16, k = 3, stride = 2, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_forward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        x = ndl.init.rand(\u001b[94m10\u001b[39;49;00m, cin, s, s, device=device)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        g = torch.nn.Conv2d(cin, cout, k, stride=stride, padding=k//\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        g.weight.data = torch.tensor(f.weight.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        g.bias.data = torch.tensor(f.bias.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        z = torch.tensor(x.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m np.linalg.norm(f(x).cached_data.numpy() - g(z).data.numpy()) < \u001b[94m1e-3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                              ^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "cin        = 8\n",
            "cout       = 16\n",
            "device     = cpu()\n",
            "f          = <needle.nn.nn_conv.Conv object at 0x78125e94e9f0>\n",
            "g          = Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "k          = 3\n",
            "s          = 32\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "x          = needle.Tensor([[[[2.30571285e-01 2.68709034e-01 8.00255597e-01 ... 9.25395012e-01\n",
            "    6.64665580e-01 4.23054427e-01]\n",
            " ...0342062e-03]\n",
            "   [2.65467048e-01 1.94168106e-01 7.92771041e-01 ... 7.72226214e-01\n",
            "    6.59931153e-02 4.83135551e-01]]]])\n",
            "z          = tensor([[[[2.3057e-01, 2.6871e-01, 8.0026e-01,  ..., 9.2540e-01,\n",
            "           6.6467e-01, 4.2305e-01],\n",
            "          [1.9899...1, 8.3034e-03],\n",
            "          [2.6547e-01, 1.9417e-01, 7.9277e-01,  ..., 7.7223e-01,\n",
            "           6.5993e-02, 4.8314e-01]]]])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:357: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_basic.py\u001b[0m:75: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[2.30571285e-01 2.68709034e-01 8.00255597e-01 ... 9.25395012e-01\n",
            "    6.64665580e-01 4.23054427e-01]\n",
            "...42062e-03]\n",
            "   [2.65467048e-01 1.94168106e-01 7.92771041e-01 ... 7.72226214e-01\n",
            "    6.59931153e-02 4.83135551e-01]]]]),)\n",
            "        kwargs     = {}\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x78125e94e9f0>\n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_conv.py\u001b[0m:57: in forward\n",
            "    \u001b[0mout = ops.conv(out, \u001b[96mself\u001b[39;49;00m.weight, stride=\u001b[96mself\u001b[39;49;00m.stride, padding=\u001b[96mself\u001b[39;49;00m.padding)\u001b[90m\u001b[39;49;00m\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        out        = needle.Tensor([[[[2.30571285e-01 7.23623097e-01 8.65805268e-01 ... 5.07418290e-02\n",
            "    9.86115813e-01 5.62441587e-01]\n",
            " ...9931153e-02]\n",
            "   [2.45067000e-01 8.56018782e-01 2.21710548e-01 ... 4.76585664e-02\n",
            "    1.26168638e-01 4.83135551e-01]]]])\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x78125e94e9f0>\n",
            "        x          = needle.Tensor([[[[2.30571285e-01 2.68709034e-01 8.00255597e-01 ... 9.25395012e-01\n",
            "    6.64665580e-01 4.23054427e-01]\n",
            " ...0342062e-03]\n",
            "   [2.65467048e-01 1.94168106e-01 7.92771041e-01 ... 7.72226214e-01\n",
            "    6.59931153e-02 4.83135551e-01]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[2.30571285e-01 7.23623097e-01 8.65805268e-01 ... 5.07418290e-02\n",
            "    9.86115813e-01 5.62441587e-01]\n",
            " ...9931153e-02]\n",
            "   [2.45067000e-01 8.56018782e-01 2.21710548e-01 ... 4.76585664e-02\n",
            "    1.26168638e-01 4.83135551e-01]]]])\n",
            "        b          = needle.Tensor([[[[ 0.02818251  0.12423962  0.05933046 ...  0.24571836 -0.24766244\n",
            "    -0.238371  ]\n",
            "   [-0.27700204  0....18  0.07989958\n",
            "    -0.12652083]\n",
            "   [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\n",
            "     0.07735741]]]])\n",
            "        padding    = 1\n",
            "        stride     = 2\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[2.30571285e-01 7.23623097e-01 8.65805268e-01 ... 5.07418290e-02\n",
            "    9.86115813e-01 5.62441587e-01]\n",
            "...8  0.07989958\n",
            "    -0.12652083]\n",
            "   [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\n",
            "     0.07735741]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x78125ddffa70>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[2.30571285e-01 7.23623097e-01 8.65805268e-01 ... 5.07418290e-02\n",
            "    9.86115813e-01 5.62441587e-01]\n",
            "...8  0.07989958\n",
            "    -0.12652083]\n",
            "   [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\n",
            "     0.07735741]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x78125ddffa70>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x78125ddffb90>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x78125ddffb90>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x78125ddffa70>\n",
            "A = NDArray([[[[2.30571285e-01 7.23623097e-01 8.65805268e-01 ... 5.07418290e-02\n",
            "    9.86115813e-01 5.62441587e-01]\n",
            "   [2.6...  [2.45067000e-01 8.56018782e-01 2.21710548e-01 ... 4.76585664e-02\n",
            "    1.26168638e-01 4.83135551e-01]]]], device=cpu())\n",
            "B = NDArray([[[[ 0.02818251  0.12423962  0.05933046 ...  0.24571836 -0.24766244\n",
            "    -0.238371  ]\n",
            "   [-0.27700204  0.192038...\n",
            "    -0.12652083]\n",
            "   [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\n",
            "     0.07735741]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[2.30571285e-01 7.23623097e-01 8.65805268e-01 ... 5.07418290e-02\n",
            "    9.86115813e-01 5.62441587e-01]\n",
            "   [2.6...  [2.45067000e-01 8.56018782e-01 2.21710548e-01 ... 4.76585664e-02\n",
            "    1.26168638e-01 4.83135551e-01]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ..... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]]], device=cpu())\n",
            "B          = NDArray([[[[ 0.02818251  0.12423962  0.05933046 ...  0.24571836 -0.24766244\n",
            "    -0.238371  ]\n",
            "   [-0.27700204  0.192038...\n",
            "    -0.12652083]\n",
            "   [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\n",
            "     0.07735741]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[ 0.02818251  0.12423962  0.05933046 ...  0.24571836 -0.24766244\n",
            "  -0.238371  ]\n",
            " [-0.27700204  0.19203815  0....07989958\n",
            "  -0.12652083]\n",
            " [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\n",
            "   0.07735741]], device=cpu())\n",
            "cols       = NDArray([[0.         0.         0.         ... 0.76747835 0.34424347 0.31014904]\n",
            " [0.         0.         0.         .....803975  0.03431202 0.7722262 ]\n",
            " [0.7979285  0.34147772 0.7443342  ... 0.04765857 0.12616864 0.48313555]], device=cpu())\n",
            "out_h      = 16\n",
            "out_w      = 16\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x78125ddffa70>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-8-8-3-2] __\u001b[0m\n",
            "\n",
            "s = 32, cin = 8, cout = 8, k = 3, stride = 2, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_forward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        x = ndl.init.rand(\u001b[94m10\u001b[39;49;00m, cin, s, s, device=device)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        g = torch.nn.Conv2d(cin, cout, k, stride=stride, padding=k//\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        g.weight.data = torch.tensor(f.weight.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        g.bias.data = torch.tensor(f.bias.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        z = torch.tensor(x.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m np.linalg.norm(f(x).cached_data.numpy() - g(z).data.numpy()) < \u001b[94m1e-3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                              ^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "cin        = 8\n",
            "cout       = 8\n",
            "device     = cpu()\n",
            "f          = <needle.nn.nn_conv.Conv object at 0x78125dcf2b40>\n",
            "g          = Conv2d(8, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "k          = 3\n",
            "s          = 32\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "x          = needle.Tensor([[[[1.60467640e-01 8.86304677e-01 4.46394414e-01 ... 4.77646500e-01\n",
            "    2.83999979e-01 2.38413274e-01]\n",
            " ...9195308e-01]\n",
            "   [5.43365121e-01 6.34333074e-01 9.18954492e-01 ... 6.02832973e-01\n",
            "    7.47691453e-01 3.75390649e-01]]]])\n",
            "z          = tensor([[[[1.6047e-01, 8.8630e-01, 4.4639e-01,  ..., 4.7765e-01,\n",
            "           2.8400e-01, 2.3841e-01],\n",
            "          [5.1451...1, 1.3920e-01],\n",
            "          [5.4337e-01, 6.3433e-01, 9.1895e-01,  ..., 6.0283e-01,\n",
            "           7.4769e-01, 3.7539e-01]]]])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:357: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_basic.py\u001b[0m:75: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[1.60467640e-01 8.86304677e-01 4.46394414e-01 ... 4.77646500e-01\n",
            "    2.83999979e-01 2.38413274e-01]\n",
            "...95308e-01]\n",
            "   [5.43365121e-01 6.34333074e-01 9.18954492e-01 ... 6.02832973e-01\n",
            "    7.47691453e-01 3.75390649e-01]]]]),)\n",
            "        kwargs     = {}\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x78125dcf2b40>\n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_conv.py\u001b[0m:57: in forward\n",
            "    \u001b[0mout = ops.conv(out, \u001b[96mself\u001b[39;49;00m.weight, stride=\u001b[96mself\u001b[39;49;00m.stride, padding=\u001b[96mself\u001b[39;49;00m.padding)\u001b[90m\u001b[39;49;00m\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        out        = needle.Tensor([[[[1.60467640e-01 9.19170976e-01 6.17237926e-01 ... 7.75355279e-01\n",
            "    4.59888279e-01 4.75542918e-02]\n",
            " ...7691453e-01]\n",
            "   [8.49906206e-01 7.04644203e-01 6.61012948e-01 ... 3.19166720e-01\n",
            "    7.03095138e-01 3.75390649e-01]]]])\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x78125dcf2b40>\n",
            "        x          = needle.Tensor([[[[1.60467640e-01 8.86304677e-01 4.46394414e-01 ... 4.77646500e-01\n",
            "    2.83999979e-01 2.38413274e-01]\n",
            " ...9195308e-01]\n",
            "   [5.43365121e-01 6.34333074e-01 9.18954492e-01 ... 6.02832973e-01\n",
            "    7.47691453e-01 3.75390649e-01]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[1.60467640e-01 9.19170976e-01 6.17237926e-01 ... 7.75355279e-01\n",
            "    4.59888279e-01 4.75542918e-02]\n",
            " ...7691453e-01]\n",
            "   [8.49906206e-01 7.04644203e-01 6.61012948e-01 ... 3.19166720e-01\n",
            "    7.03095138e-01 3.75390649e-01]]]])\n",
            "        b          = needle.Tensor([[[[ 0.02818251  0.12423962  0.05933046  0.02591333 -0.04407792\n",
            "     0.084232   -0.03603405  0.22619021]....24439585]\n",
            "   [ 0.19046631  0.2703653   0.24236172 -0.267871   -0.18777046\n",
            "    -0.06400812  0.26104474 -0.11545335]]]])\n",
            "        padding    = 1\n",
            "        stride     = 2\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[1.60467640e-01 9.19170976e-01 6.17237926e-01 ... 7.75355279e-01\n",
            "    4.59888279e-01 4.75542918e-02]\n",
            "...24439585]\n",
            "   [ 0.19046631  0.2703653   0.24236172 -0.267871   -0.18777046\n",
            "    -0.06400812  0.26104474 -0.11545335]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x78125dcf0380>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[1.60467640e-01 9.19170976e-01 6.17237926e-01 ... 7.75355279e-01\n",
            "    4.59888279e-01 4.75542918e-02]\n",
            "...24439585]\n",
            "   [ 0.19046631  0.2703653   0.24236172 -0.267871   -0.18777046\n",
            "    -0.06400812  0.26104474 -0.11545335]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x78125dcf0380>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x78125dcf33b0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x78125dcf33b0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x78125dcf0380>\n",
            "A = NDArray([[[[1.60467640e-01 9.19170976e-01 6.17237926e-01 ... 7.75355279e-01\n",
            "    4.59888279e-01 4.75542918e-02]\n",
            "   [8.8...  [8.49906206e-01 7.04644203e-01 6.61012948e-01 ... 3.19166720e-01\n",
            "    7.03095138e-01 3.75390649e-01]]]], device=cpu())\n",
            "B = NDArray([[[[ 0.02818251  0.12423962  0.05933046  0.02591333 -0.04407792\n",
            "     0.084232   -0.03603405  0.22619021]\n",
            "   [ ...[ 0.19046631  0.2703653   0.24236172 -0.267871   -0.18777046\n",
            "    -0.06400812  0.26104474 -0.11545335]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[1.60467640e-01 9.19170976e-01 6.17237926e-01 ... 7.75355279e-01\n",
            "    4.59888279e-01 4.75542918e-02]\n",
            "   [8.8...  [8.49906206e-01 7.04644203e-01 6.61012948e-01 ... 3.19166720e-01\n",
            "    7.03095138e-01 3.75390649e-01]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.0...  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]]]], device=cpu())\n",
            "B          = NDArray([[[[ 0.02818251  0.12423962  0.05933046  0.02591333 -0.04407792\n",
            "     0.084232   -0.03603405  0.22619021]\n",
            "   [ ...[ 0.19046631  0.2703653   0.24236172 -0.267871   -0.18777046\n",
            "    -0.06400812  0.26104474 -0.11545335]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[ 0.02818251  0.12423962  0.05933046  0.02591333 -0.04407792  0.084232\n",
            "  -0.03603405  0.22619021]\n",
            " [ 0.267695...5]\n",
            " [ 0.19046631  0.2703653   0.24236172 -0.267871   -0.18777046 -0.06400812\n",
            "   0.26104474 -0.11545335]], device=cpu())\n",
            "cols       = NDArray([[0.         0.         0.         ... 0.22031407 0.16934165 0.3967405 ]\n",
            " [0.         0.         0.         .....4969366 0.9855497  0.602833  ]\n",
            " [0.7244085  0.6250048  0.52861714 ... 0.31916672 0.70309514 0.37539065]], device=cpu())\n",
            "out_h      = 16\n",
            "out_w      = 16\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x78125dcf0380>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-16-8-3-1] _\u001b[0m\n",
            "\n",
            "s = 32, cin = 16, cout = 8, k = 3, stride = 1, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_forward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        x = ndl.init.rand(\u001b[94m10\u001b[39;49;00m, cin, s, s, device=device)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        g = torch.nn.Conv2d(cin, cout, k, stride=stride, padding=k//\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        g.weight.data = torch.tensor(f.weight.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        g.bias.data = torch.tensor(f.bias.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        z = torch.tensor(x.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m np.linalg.norm(f(x).cached_data.numpy() - g(z).data.numpy()) < \u001b[94m1e-3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                              ^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "cin        = 16\n",
            "cout       = 8\n",
            "device     = cpu()\n",
            "f          = <needle.nn.nn_conv.Conv object at 0x78125dc69a90>\n",
            "g          = Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "k          = 3\n",
            "s          = 32\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "x          = needle.Tensor([[[[2.30571285e-01 2.68709034e-01 8.00255597e-01 ... 9.25395012e-01\n",
            "    6.64665580e-01 4.23054427e-01]\n",
            " ...1358378e-01]\n",
            "   [6.18849814e-01 4.57632452e-01 7.51767039e-01 ... 3.38609844e-01\n",
            "    2.57683158e-01 6.61808699e-02]]]])\n",
            "z          = tensor([[[[2.3057e-01, 2.6871e-01, 8.0026e-01,  ..., 9.2540e-01,\n",
            "           6.6467e-01, 4.2305e-01],\n",
            "          [1.9899...1, 7.0136e-01],\n",
            "          [6.1885e-01, 4.5763e-01, 7.5177e-01,  ..., 3.3861e-01,\n",
            "           2.5768e-01, 6.6181e-02]]]])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:357: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_basic.py\u001b[0m:75: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[2.30571285e-01 2.68709034e-01 8.00255597e-01 ... 9.25395012e-01\n",
            "    6.64665580e-01 4.23054427e-01]\n",
            "...58378e-01]\n",
            "   [6.18849814e-01 4.57632452e-01 7.51767039e-01 ... 3.38609844e-01\n",
            "    2.57683158e-01 6.61808699e-02]]]]),)\n",
            "        kwargs     = {}\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x78125dc69a90>\n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_conv.py\u001b[0m:57: in forward\n",
            "    \u001b[0mout = ops.conv(out, \u001b[96mself\u001b[39;49;00m.weight, stride=\u001b[96mself\u001b[39;49;00m.stride, padding=\u001b[96mself\u001b[39;49;00m.padding)\u001b[90m\u001b[39;49;00m\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        out        = needle.Tensor([[[[2.30571285e-01 7.23623097e-01 8.65805268e-01 ... 1.55031145e-01\n",
            "    7.97336817e-01 9.86015499e-01]\n",
            " ...7683158e-01]\n",
            "   [4.85624522e-01 2.03076765e-01 6.45504475e-01 ... 8.21592152e-01\n",
            "    9.46305871e-01 6.61808699e-02]]]])\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x78125dc69a90>\n",
            "        x          = needle.Tensor([[[[2.30571285e-01 2.68709034e-01 8.00255597e-01 ... 9.25395012e-01\n",
            "    6.64665580e-01 4.23054427e-01]\n",
            " ...1358378e-01]\n",
            "   [6.18849814e-01 4.57632452e-01 7.51767039e-01 ... 3.38609844e-01\n",
            "    2.57683158e-01 6.61808699e-02]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[2.30571285e-01 7.23623097e-01 8.65805268e-01 ... 1.55031145e-01\n",
            "    7.97336817e-01 9.86015499e-01]\n",
            " ...7683158e-01]\n",
            "   [4.85624522e-01 2.03076765e-01 6.45504475e-01 ... 8.21592152e-01\n",
            "    9.46305871e-01 6.61808699e-02]]]])\n",
            "        b          = needle.Tensor([[[[ 0.01992804  0.08785069  0.04195297 ...  0.05956101 -0.02547991\n",
            "     0.15994066]\n",
            "   [ 0.18928954 -0....2 -0.11381223\n",
            "     0.07500601]\n",
            "   [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\n",
            "     0.05469996]]]])\n",
            "        padding    = 1\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[2.30571285e-01 7.23623097e-01 8.65805268e-01 ... 1.55031145e-01\n",
            "    7.97336817e-01 9.86015499e-01]\n",
            "... -0.11381223\n",
            "     0.07500601]\n",
            "   [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\n",
            "     0.05469996]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x78125dc690a0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[2.30571285e-01 7.23623097e-01 8.65805268e-01 ... 1.55031145e-01\n",
            "    7.97336817e-01 9.86015499e-01]\n",
            "... -0.11381223\n",
            "     0.07500601]\n",
            "   [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\n",
            "     0.05469996]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x78125dc690a0>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x78125dc6a960>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x78125dc6a960>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x78125dc690a0>\n",
            "A = NDArray([[[[2.30571285e-01 7.23623097e-01 8.65805268e-01 ... 1.55031145e-01\n",
            "    7.97336817e-01 9.86015499e-01]\n",
            "   [2.6...  [4.85624522e-01 2.03076765e-01 6.45504475e-01 ... 8.21592152e-01\n",
            "    9.46305871e-01 6.61808699e-02]]]], device=cpu())\n",
            "B = NDArray([[[[ 0.01992804  0.08785069  0.04195297 ...  0.05956101 -0.02547991\n",
            "     0.15994066]\n",
            "   [ 0.18928954 -0.047584...     0.07500601]\n",
            "   [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\n",
            "     0.05469996]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[2.30571285e-01 7.23623097e-01 8.65805268e-01 ... 1.55031145e-01\n",
            "    7.97336817e-01 9.86015499e-01]\n",
            "   [2.6...  [4.85624522e-01 2.03076765e-01 6.45504475e-01 ... 8.21592152e-01\n",
            "    9.46305871e-01 6.61808699e-02]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ..... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]]], device=cpu())\n",
            "B          = NDArray([[[[ 0.01992804  0.08785069  0.04195297 ...  0.05956101 -0.02547991\n",
            "     0.15994066]\n",
            "   [ 0.18928954 -0.047584...     0.07500601]\n",
            "   [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\n",
            "     0.05469996]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[ 0.01992804  0.08785069  0.04195297 ...  0.05956101 -0.02547991\n",
            "   0.15994066]\n",
            " [ 0.18928954 -0.0475848   0....1381223\n",
            "   0.07500601]\n",
            " [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\n",
            "   0.05469996]], device=cpu())\n",
            "cols       = NDArray([[0.         0.         0.         ... 0.310158   0.7398494  0.9160058 ]\n",
            " [0.         0.         0.         .....        0.         0.        ]\n",
            " [0.47734421 0.08033708 0.8365457  ... 0.         0.         0.        ]], device=cpu())\n",
            "out_h      = 32\n",
            "out_w      = 32\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x78125dc690a0>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-16-8-3-2] _\u001b[0m\n",
            "\n",
            "s = 32, cin = 16, cout = 8, k = 3, stride = 2, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_forward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        x = ndl.init.rand(\u001b[94m10\u001b[39;49;00m, cin, s, s, device=device)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        g = torch.nn.Conv2d(cin, cout, k, stride=stride, padding=k//\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        g.weight.data = torch.tensor(f.weight.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        g.bias.data = torch.tensor(f.bias.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        z = torch.tensor(x.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m np.linalg.norm(f(x).cached_data.numpy() - g(z).data.numpy()) < \u001b[94m1e-3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                              ^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "cin        = 16\n",
            "cout       = 8\n",
            "device     = cpu()\n",
            "f          = <needle.nn.nn_conv.Conv object at 0x78125dcbc4d0>\n",
            "g          = Conv2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "k          = 3\n",
            "s          = 32\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "x          = needle.Tensor([[[[2.30571285e-01 2.68709034e-01 8.00255597e-01 ... 9.25395012e-01\n",
            "    6.64665580e-01 4.23054427e-01]\n",
            " ...1358378e-01]\n",
            "   [6.18849814e-01 4.57632452e-01 7.51767039e-01 ... 3.38609844e-01\n",
            "    2.57683158e-01 6.61808699e-02]]]])\n",
            "z          = tensor([[[[2.3057e-01, 2.6871e-01, 8.0026e-01,  ..., 9.2540e-01,\n",
            "           6.6467e-01, 4.2305e-01],\n",
            "          [1.9899...1, 7.0136e-01],\n",
            "          [6.1885e-01, 4.5763e-01, 7.5177e-01,  ..., 3.3861e-01,\n",
            "           2.5768e-01, 6.6181e-02]]]])\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:357: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_basic.py\u001b[0m:75: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[2.30571285e-01 2.68709034e-01 8.00255597e-01 ... 9.25395012e-01\n",
            "    6.64665580e-01 4.23054427e-01]\n",
            "...58378e-01]\n",
            "   [6.18849814e-01 4.57632452e-01 7.51767039e-01 ... 3.38609844e-01\n",
            "    2.57683158e-01 6.61808699e-02]]]]),)\n",
            "        kwargs     = {}\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x78125dcbc4d0>\n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_conv.py\u001b[0m:57: in forward\n",
            "    \u001b[0mout = ops.conv(out, \u001b[96mself\u001b[39;49;00m.weight, stride=\u001b[96mself\u001b[39;49;00m.stride, padding=\u001b[96mself\u001b[39;49;00m.padding)\u001b[90m\u001b[39;49;00m\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        out        = needle.Tensor([[[[2.30571285e-01 7.23623097e-01 8.65805268e-01 ... 1.55031145e-01\n",
            "    7.97336817e-01 9.86015499e-01]\n",
            " ...7683158e-01]\n",
            "   [4.85624522e-01 2.03076765e-01 6.45504475e-01 ... 8.21592152e-01\n",
            "    9.46305871e-01 6.61808699e-02]]]])\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x78125dcbc4d0>\n",
            "        x          = needle.Tensor([[[[2.30571285e-01 2.68709034e-01 8.00255597e-01 ... 9.25395012e-01\n",
            "    6.64665580e-01 4.23054427e-01]\n",
            " ...1358378e-01]\n",
            "   [6.18849814e-01 4.57632452e-01 7.51767039e-01 ... 3.38609844e-01\n",
            "    2.57683158e-01 6.61808699e-02]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[2.30571285e-01 7.23623097e-01 8.65805268e-01 ... 1.55031145e-01\n",
            "    7.97336817e-01 9.86015499e-01]\n",
            " ...7683158e-01]\n",
            "   [4.85624522e-01 2.03076765e-01 6.45504475e-01 ... 8.21592152e-01\n",
            "    9.46305871e-01 6.61808699e-02]]]])\n",
            "        b          = needle.Tensor([[[[ 0.01992804  0.08785069  0.04195297 ...  0.05956101 -0.02547991\n",
            "     0.15994066]\n",
            "   [ 0.18928954 -0....2 -0.11381223\n",
            "     0.07500601]\n",
            "   [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\n",
            "     0.05469996]]]])\n",
            "        padding    = 1\n",
            "        stride     = 2\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[2.30571285e-01 7.23623097e-01 8.65805268e-01 ... 1.55031145e-01\n",
            "    7.97336817e-01 9.86015499e-01]\n",
            "... -0.11381223\n",
            "     0.07500601]\n",
            "   [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\n",
            "     0.05469996]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x78125dcbd730>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[2.30571285e-01 7.23623097e-01 8.65805268e-01 ... 1.55031145e-01\n",
            "    7.97336817e-01 9.86015499e-01]\n",
            "... -0.11381223\n",
            "     0.07500601]\n",
            "   [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\n",
            "     0.05469996]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x78125dcbd730>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x78125dcbd940>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x78125dcbd940>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x78125dcbd730>\n",
            "A = NDArray([[[[2.30571285e-01 7.23623097e-01 8.65805268e-01 ... 1.55031145e-01\n",
            "    7.97336817e-01 9.86015499e-01]\n",
            "   [2.6...  [4.85624522e-01 2.03076765e-01 6.45504475e-01 ... 8.21592152e-01\n",
            "    9.46305871e-01 6.61808699e-02]]]], device=cpu())\n",
            "B = NDArray([[[[ 0.01992804  0.08785069  0.04195297 ...  0.05956101 -0.02547991\n",
            "     0.15994066]\n",
            "   [ 0.18928954 -0.047584...     0.07500601]\n",
            "   [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\n",
            "     0.05469996]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[2.30571285e-01 7.23623097e-01 8.65805268e-01 ... 1.55031145e-01\n",
            "    7.97336817e-01 9.86015499e-01]\n",
            "   [2.6...  [4.85624522e-01 2.03076765e-01 6.45504475e-01 ... 8.21592152e-01\n",
            "    9.46305871e-01 6.61808699e-02]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ..... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]]], device=cpu())\n",
            "B          = NDArray([[[[ 0.01992804  0.08785069  0.04195297 ...  0.05956101 -0.02547991\n",
            "     0.15994066]\n",
            "   [ 0.18928954 -0.047584...     0.07500601]\n",
            "   [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\n",
            "     0.05469996]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[ 0.01992804  0.08785069  0.04195297 ...  0.05956101 -0.02547991\n",
            "   0.15994066]\n",
            " [ 0.18928954 -0.0475848   0....1381223\n",
            "   0.07500601]\n",
            " [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\n",
            "   0.05469996]], device=cpu())\n",
            "cols       = NDArray([[0.         0.         0.         ... 0.310158   0.7398494  0.9160058 ]\n",
            " [0.         0.         0.         .....0215268 0.8537141  0.33860984]\n",
            " [0.7899795  0.306552   0.8941302  ... 0.82159215 0.9463059  0.06618087]], device=cpu())\n",
            "out_h      = 16\n",
            "out_w      = 16\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x78125dcbd730>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-4-8-16-3-1] _\u001b[0m\n",
            "\n",
            "s = 4, cin = 8, cout = 16, k = 3, stride = 1, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_forward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "cin        = 8\n",
            "cout       = 16\n",
            "device     = cuda()\n",
            "k          = 3\n",
            "s          = 4\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:349: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_conv.py\u001b[0m:35: in __init__\n",
            "    \u001b[0minit.kaiming_uniform(\u001b[90m\u001b[39;49;00m\n",
            "        __class__  = <class 'needle.nn.nn_conv.Conv'>\n",
            "        bias       = True\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        fan_in     = 72\n",
            "        fan_out    = 144\n",
            "        in_channels = 8\n",
            "        kernel_size = 3\n",
            "        out_channels = 16\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x78125ddfff80>\n",
            "        stride     = 1\n",
            "        weight_shape = (3, 3, 8, 16)\n",
            "\u001b[1m\u001b[31mpython/needle/init/init_initializers.py\u001b[0m:30: in kaiming_uniform\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m rand(*shape, low=-bound, high=bound, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        bound      = 0.28867513459481287\n",
            "        fan_in     = 72\n",
            "        fan_out    = 144\n",
            "        kwargs     = {'device': cuda(), 'dtype': 'float32'}\n",
            "        nonlinearity = 'relu'\n",
            "        shape      = (3, 3, 8, 16)\n",
            "\u001b[1m\u001b[31mpython/needle/init/init_basic.py\u001b[0m:8: in rand\n",
            "    \u001b[0marray = device.rand(*shape) * (high - low) + low\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        high       = 0.28867513459481287\n",
            "        low        = -0.28867513459481287\n",
            "        requires_grad = False\n",
            "        shape      = (3, 3, 8, 16)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:44: in rand\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(np.random.rand(*shape).astype(dtype), device=\u001b[96mself\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        dtype      = 'float32'\n",
            "        self       = cuda()\n",
            "        shape      = (3, 3, 8, 16)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[5.4881352e-01, 7.1518934e-01, 6.0276335e-01, ...,\n",
            "          9.2559665e-01, 7.1036056e-02, 8.7129302e-02],\n",
            "  ...82192e-01, 7.2855872e-01, 3.2965115e-01, ...,\n",
            "          7.0641059e-01, 2.4577023e-02, 6.3398695e-01]]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x78125dc62390>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 3, 8, 16), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x78125dc623c0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 3, 8, 16)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-8-16-3-2] _\u001b[0m\n",
            "\n",
            "s = 32, cin = 8, cout = 16, k = 3, stride = 2, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_forward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "cin        = 8\n",
            "cout       = 16\n",
            "device     = cuda()\n",
            "k          = 3\n",
            "s          = 32\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:349: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_conv.py\u001b[0m:35: in __init__\n",
            "    \u001b[0minit.kaiming_uniform(\u001b[90m\u001b[39;49;00m\n",
            "        __class__  = <class 'needle.nn.nn_conv.Conv'>\n",
            "        bias       = True\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        fan_in     = 72\n",
            "        fan_out    = 144\n",
            "        in_channels = 8\n",
            "        kernel_size = 3\n",
            "        out_channels = 16\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x78125dc6bf80>\n",
            "        stride     = 2\n",
            "        weight_shape = (3, 3, 8, 16)\n",
            "\u001b[1m\u001b[31mpython/needle/init/init_initializers.py\u001b[0m:30: in kaiming_uniform\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m rand(*shape, low=-bound, high=bound, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        bound      = 0.28867513459481287\n",
            "        fan_in     = 72\n",
            "        fan_out    = 144\n",
            "        kwargs     = {'device': cuda(), 'dtype': 'float32'}\n",
            "        nonlinearity = 'relu'\n",
            "        shape      = (3, 3, 8, 16)\n",
            "\u001b[1m\u001b[31mpython/needle/init/init_basic.py\u001b[0m:8: in rand\n",
            "    \u001b[0marray = device.rand(*shape) * (high - low) + low\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        high       = 0.28867513459481287\n",
            "        low        = -0.28867513459481287\n",
            "        requires_grad = False\n",
            "        shape      = (3, 3, 8, 16)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:44: in rand\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(np.random.rand(*shape).astype(dtype), device=\u001b[96mself\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        dtype      = 'float32'\n",
            "        self       = cuda()\n",
            "        shape      = (3, 3, 8, 16)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[5.4881352e-01, 7.1518934e-01, 6.0276335e-01, ...,\n",
            "          9.2559665e-01, 7.1036056e-02, 8.7129302e-02],\n",
            "  ...82192e-01, 7.2855872e-01, 3.2965115e-01, ...,\n",
            "          7.0641059e-01, 2.4577023e-02, 6.3398695e-01]]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x78125dc6a210>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 3, 8, 16), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x78125dc69fa0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 3, 8, 16)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-8-8-3-2] _\u001b[0m\n",
            "\n",
            "s = 32, cin = 8, cout = 8, k = 3, stride = 2, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_forward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "cin        = 8\n",
            "cout       = 8\n",
            "device     = cuda()\n",
            "k          = 3\n",
            "s          = 32\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:349: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_conv.py\u001b[0m:35: in __init__\n",
            "    \u001b[0minit.kaiming_uniform(\u001b[90m\u001b[39;49;00m\n",
            "        __class__  = <class 'needle.nn.nn_conv.Conv'>\n",
            "        bias       = True\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        fan_in     = 72\n",
            "        fan_out    = 72\n",
            "        in_channels = 8\n",
            "        kernel_size = 3\n",
            "        out_channels = 8\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x78125dcc4110>\n",
            "        stride     = 2\n",
            "        weight_shape = (3, 3, 8, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/init/init_initializers.py\u001b[0m:30: in kaiming_uniform\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m rand(*shape, low=-bound, high=bound, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        bound      = 0.28867513459481287\n",
            "        fan_in     = 72\n",
            "        fan_out    = 72\n",
            "        kwargs     = {'device': cuda(), 'dtype': 'float32'}\n",
            "        nonlinearity = 'relu'\n",
            "        shape      = (3, 3, 8, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/init/init_basic.py\u001b[0m:8: in rand\n",
            "    \u001b[0marray = device.rand(*shape) * (high - low) + low\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        high       = 0.28867513459481287\n",
            "        low        = -0.28867513459481287\n",
            "        requires_grad = False\n",
            "        shape      = (3, 3, 8, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:44: in rand\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(np.random.rand(*shape).astype(dtype), device=\u001b[96mself\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        dtype      = 'float32'\n",
            "        self       = cuda()\n",
            "        shape      = (3, 3, 8, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[0.5488135 , 0.71518934, 0.60276335, 0.5448832 , 0.4236548 ,\n",
            "          0.6458941 , 0.4375872 , 0.891773  ],\n",
            " ...89734, 0.9682864 , 0.9197828 , 0.03603382, 0.17477201,\n",
            "          0.38913468, 0.9521427 , 0.30002892]]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x78125dcc7e00>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 3, 8, 8), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x78125dcc4140>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 3, 8, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-16-8-3-1] _\u001b[0m\n",
            "\n",
            "s = 32, cin = 16, cout = 8, k = 3, stride = 1, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_forward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "cin        = 16\n",
            "cout       = 8\n",
            "device     = cuda()\n",
            "k          = 3\n",
            "s          = 32\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:349: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_conv.py\u001b[0m:35: in __init__\n",
            "    \u001b[0minit.kaiming_uniform(\u001b[90m\u001b[39;49;00m\n",
            "        __class__  = <class 'needle.nn.nn_conv.Conv'>\n",
            "        bias       = True\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        fan_in     = 144\n",
            "        fan_out    = 72\n",
            "        in_channels = 16\n",
            "        kernel_size = 3\n",
            "        out_channels = 8\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x78125dcc4230>\n",
            "        stride     = 1\n",
            "        weight_shape = (3, 3, 16, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/init/init_initializers.py\u001b[0m:30: in kaiming_uniform\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m rand(*shape, low=-bound, high=bound, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        bound      = 0.2041241452319315\n",
            "        fan_in     = 144\n",
            "        fan_out    = 72\n",
            "        kwargs     = {'device': cuda(), 'dtype': 'float32'}\n",
            "        nonlinearity = 'relu'\n",
            "        shape      = (3, 3, 16, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/init/init_basic.py\u001b[0m:8: in rand\n",
            "    \u001b[0marray = device.rand(*shape) * (high - low) + low\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        high       = 0.2041241452319315\n",
            "        low        = -0.2041241452319315\n",
            "        requires_grad = False\n",
            "        shape      = (3, 3, 16, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:44: in rand\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(np.random.rand(*shape).astype(dtype), device=\u001b[96mself\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        dtype      = 'float32'\n",
            "        self       = cuda()\n",
            "        shape      = (3, 3, 16, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[0.5488135 , 0.71518934, 0.60276335, ..., 0.6458941 ,\n",
            "          0.4375872 , 0.891773  ],\n",
            "         [0.96366274...3],\n",
            "         [0.10244628, 0.39702582, 0.27664974, ..., 0.7064106 ,\n",
            "          0.02457702, 0.63398695]]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x78125dcc45f0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 3, 16, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x78125dcc73e0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 3, 16, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-16-8-3-2] _\u001b[0m\n",
            "\n",
            "s = 32, cin = 16, cout = 8, k = 3, stride = 2, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_forward_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_forward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "cin        = 16\n",
            "cout       = 8\n",
            "device     = cuda()\n",
            "k          = 3\n",
            "s          = 32\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:349: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_conv.py\u001b[0m:35: in __init__\n",
            "    \u001b[0minit.kaiming_uniform(\u001b[90m\u001b[39;49;00m\n",
            "        __class__  = <class 'needle.nn.nn_conv.Conv'>\n",
            "        bias       = True\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        fan_in     = 144\n",
            "        fan_out    = 72\n",
            "        in_channels = 16\n",
            "        kernel_size = 3\n",
            "        out_channels = 8\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x78125dcc74a0>\n",
            "        stride     = 2\n",
            "        weight_shape = (3, 3, 16, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/init/init_initializers.py\u001b[0m:30: in kaiming_uniform\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m rand(*shape, low=-bound, high=bound, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        bound      = 0.2041241452319315\n",
            "        fan_in     = 144\n",
            "        fan_out    = 72\n",
            "        kwargs     = {'device': cuda(), 'dtype': 'float32'}\n",
            "        nonlinearity = 'relu'\n",
            "        shape      = (3, 3, 16, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/init/init_basic.py\u001b[0m:8: in rand\n",
            "    \u001b[0marray = device.rand(*shape) * (high - low) + low\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        high       = 0.2041241452319315\n",
            "        low        = -0.2041241452319315\n",
            "        requires_grad = False\n",
            "        shape      = (3, 3, 16, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:44: in rand\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(np.random.rand(*shape).astype(dtype), device=\u001b[96mself\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        dtype      = 'float32'\n",
            "        self       = cuda()\n",
            "        shape      = (3, 3, 16, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[0.5488135 , 0.71518934, 0.60276335, ..., 0.6458941 ,\n",
            "          0.4375872 , 0.891773  ],\n",
            "         [0.96366274...3],\n",
            "         [0.10244628, 0.39702582, 0.27664974, ..., 0.7064106 ,\n",
            "          0.02457702, 0.63398695]]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x78125dcc7d70>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 3, 16, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x78125dcc6510>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 3, 16, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-4-8-16-3-1]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-8-16-3-2]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-8-8-3-2]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-16-8-3-1]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-16-8-3-2]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-4-8-16-3-1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-8-16-3-2]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-8-8-3-2]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-16-8-3-1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cuda-32-16-8-3-2]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31m===================== \u001b[31m\u001b[1m10 failed\u001b[0m, \u001b[33m1793 deselected\u001b[0m\u001b[31m in 5.19s\u001b[0m\u001b[31m ======================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"nn_conv_forward\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNz0uOT166oW",
        "outputId": "de8db853-628b-4405-ba95-29db797d5bb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: langsmith-0.4.42, typeguard-4.4.4, anyio-4.11.0\n",
            "collected 1803 items / 1789 deselected / 14 selected                           \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-4-1-1-3-1] \u001b[31mFAILED\u001b[0m\u001b[31m [  7%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-16-3-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 14%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-16-3-2] \u001b[31mFAILED\u001b[0m\u001b[31m [ 21%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-8-3-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 28%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-8-3-2] \u001b[31mFAILED\u001b[0m\u001b[31m [ 35%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-16-8-3-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 42%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-16-8-3-2] \u001b[31mFAILED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-4-1-1-3-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 57%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-16-3-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 64%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-16-3-2] \u001b[31mFAILED\u001b[0m\u001b[31m [ 71%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-8-3-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 78%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-8-3-2] \u001b[31mFAILED\u001b[0m\u001b[31m [ 85%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-16-8-3-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 92%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-16-8-3-2] \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-4-1-1-3-1] __\u001b[0m\n",
            "\n",
            "s = 4, cin = 1, cout = 1, k = 3, stride = 1, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_back_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_backward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        x = ndl.init.rand(\u001b[94m1\u001b[39;49;00m, cin, s, s, device=device, requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        g = torch.nn.Conv2d(cin, cout, k, stride=stride, padding=k//\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        g.weight.data = torch.tensor(f.weight.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        g.bias.data = torch.tensor(f.bias.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        z = torch.tensor(x.cached_data.numpy(), requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        z.requires_grad = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       res1 = f(x)\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "cin        = 1\n",
            "cout       = 1\n",
            "device     = cpu()\n",
            "f          = <needle.nn.nn_conv.Conv object at 0x79219aef0680>\n",
            "g          = Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "k          = 3\n",
            "s          = 4\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "x          = needle.Tensor([[[[0.3834415  0.79172504 0.5288949  0.56804454]\n",
            "   [0.92559665 0.07103606 0.0871293  0.0202184 ]\n",
            "   [0.83261985 0.77815676 0.87001216 0.9786183 ]\n",
            "   [0.7991586  0.46147937 0.7805292  0.11827443]]]])\n",
            "z          = tensor([[[[0.3834, 0.7917, 0.5289, 0.5680],\n",
            "          [0.9256, 0.0710, 0.0871, 0.0202],\n",
            "          [0.8326, 0.7782, 0.8700, 0.9786],\n",
            "          [0.7992, 0.4615, 0.7805, 0.1183]]]], requires_grad=True)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:383: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_basic.py\u001b[0m:75: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[0.3834415  0.79172504 0.5288949  0.56804454]\n",
            "   [0.92559665 0.07103606 0.0871293  0.0202184 ]\n",
            "   [0.83261985 0.77815676 0.87001216 0.9786183 ]\n",
            "   [0.7991586  0.46147937 0.7805292  0.11827443]]]]),)\n",
            "        kwargs     = {}\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x79219aef0680>\n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_conv.py\u001b[0m:57: in forward\n",
            "    \u001b[0mout = ops.conv(out, \u001b[96mself\u001b[39;49;00m.weight, stride=\u001b[96mself\u001b[39;49;00m.stride, padding=\u001b[96mself\u001b[39;49;00m.padding)\u001b[90m\u001b[39;49;00m\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        out        = needle.Tensor([[[[0.3834415 ]\n",
            "   [0.79172504]\n",
            "   [0.5288949 ]\n",
            "   [0.56804454]]\n",
            "\n",
            "  [[0.92559665]\n",
            "   [0.07103606]\n",
            "   [0....]\n",
            "   [0.77815676]\n",
            "   [0.87001216]\n",
            "   [0.9786183 ]]\n",
            "\n",
            "  [[0.7991586 ]\n",
            "   [0.46147937]\n",
            "   [0.7805292 ]\n",
            "   [0.11827443]]]])\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x79219aef0680>\n",
            "        x          = needle.Tensor([[[[0.3834415  0.79172504 0.5288949  0.56804454]\n",
            "   [0.92559665 0.07103606 0.0871293  0.0202184 ]\n",
            "   [0.83261985 0.77815676 0.87001216 0.9786183 ]\n",
            "   [0.7991586  0.46147937 0.7805292  0.11827443]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[0.3834415 ]\n",
            "   [0.79172504]\n",
            "   [0.5288949 ]\n",
            "   [0.56804454]]\n",
            "\n",
            "  [[0.92559665]\n",
            "   [0.07103606]\n",
            "   [0....]\n",
            "   [0.77815676]\n",
            "   [0.87001216]\n",
            "   [0.9786183 ]]\n",
            "\n",
            "  [[0.7991586 ]\n",
            "   [0.46147937]\n",
            "   [0.7805292 ]\n",
            "   [0.11827443]]]])\n",
            "        b          = needle.Tensor([[[[ 0.07971215]]\n",
            "\n",
            "  [[ 0.35140276]]\n",
            "\n",
            "  [[ 0.16781187]]]\n",
            "\n",
            "\n",
            " [[[ 0.07329392]]\n",
            "\n",
            "  [[-0.12467122]]\n",
            "\n",
            "  [[ 0.23824406]]]\n",
            "\n",
            "\n",
            " [[[-0.10191965]]\n",
            "\n",
            "  [[ 0.63976264]]\n",
            "\n",
            "  [[ 0.75715816]]]])\n",
            "        padding    = 1\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[0.3834415 ]\n",
            "   [0.79172504]\n",
            "   [0.5288949 ]\n",
            "   [0.56804454]]\n",
            "\n",
            "  [[0.92559665]\n",
            "   [0.07103606]\n",
            "   [0...\n",
            " [[[ 0.07329392]]\n",
            "\n",
            "  [[-0.12467122]]\n",
            "\n",
            "  [[ 0.23824406]]]\n",
            "\n",
            "\n",
            " [[[-0.10191965]]\n",
            "\n",
            "  [[ 0.63976264]]\n",
            "\n",
            "  [[ 0.75715816]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x79219af1a0c0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[0.3834415 ]\n",
            "   [0.79172504]\n",
            "   [0.5288949 ]\n",
            "   [0.56804454]]\n",
            "\n",
            "  [[0.92559665]\n",
            "   [0.07103606]\n",
            "   [0...\n",
            " [[[ 0.07329392]]\n",
            "\n",
            "  [[-0.12467122]]\n",
            "\n",
            "  [[ 0.23824406]]]\n",
            "\n",
            "\n",
            " [[[-0.10191965]]\n",
            "\n",
            "  [[ 0.63976264]]\n",
            "\n",
            "  [[ 0.75715816]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x79219af1a0c0>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79219ad9a510>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79219ad9a510>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x79219af1a0c0>\n",
            "A = NDArray([[[[0.3834415 ]\n",
            "   [0.79172504]\n",
            "   [0.5288949 ]\n",
            "   [0.56804454]]\n",
            "\n",
            "  [[0.92559665]\n",
            "   [0.07103606]\n",
            "   [0.087129...76]\n",
            "   [0.87001216]\n",
            "   [0.9786183 ]]\n",
            "\n",
            "  [[0.7991586 ]\n",
            "   [0.46147937]\n",
            "   [0.7805292 ]\n",
            "   [0.11827443]]]], device=cpu())\n",
            "B = NDArray([[[[ 0.07971215]]\n",
            "\n",
            "  [[ 0.35140276]]\n",
            "\n",
            "  [[ 0.16781187]]]\n",
            "\n",
            "\n",
            " [[[ 0.07329392]]\n",
            "\n",
            "  [[-0.12467122]]\n",
            "\n",
            "  [[ 0.23824406]]]\n",
            "\n",
            "\n",
            " [[[-0.10191965]]\n",
            "\n",
            "  [[ 0.63976264]]\n",
            "\n",
            "  [[ 0.75715816]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[0.3834415 ]\n",
            "   [0.79172504]\n",
            "   [0.5288949 ]\n",
            "   [0.56804454]]\n",
            "\n",
            "  [[0.92559665]\n",
            "   [0.07103606]\n",
            "   [0.087129...76]\n",
            "   [0.87001216]\n",
            "   [0.9786183 ]]\n",
            "\n",
            "  [[0.7991586 ]\n",
            "   [0.46147937]\n",
            "   [0.7805292 ]\n",
            "   [0.11827443]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  [[0.      ...  ]]\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]]], device=cpu())\n",
            "B          = NDArray([[[[ 0.07971215]]\n",
            "\n",
            "  [[ 0.35140276]]\n",
            "\n",
            "  [[ 0.16781187]]]\n",
            "\n",
            "\n",
            " [[[ 0.07329392]]\n",
            "\n",
            "  [[-0.12467122]]\n",
            "\n",
            "  [[ 0.23824406]]]\n",
            "\n",
            "\n",
            " [[[-0.10191965]]\n",
            "\n",
            "  [[ 0.63976264]]\n",
            "\n",
            "  [[ 0.75715816]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[ 0.07971215]\n",
            " [ 0.35140276]\n",
            " [ 0.16781187]\n",
            " [ 0.07329392]\n",
            " [-0.12467122]\n",
            " [ 0.23824406]\n",
            " [-0.10191965]\n",
            " [ 0.63976264]\n",
            " [ 0.75715816]], device=cpu())\n",
            "cols       = NDArray([[0.         0.         0.         0.         0.3834415  0.79172504\n",
            "  0.         0.92559665 0.07103606]\n",
            " [0.  ...      ]\n",
            " [0.87001216 0.9786183  0.         0.7805292  0.11827443 0.\n",
            "  0.         0.         0.        ]], device=cpu())\n",
            "out_h      = 4\n",
            "out_w      = 4\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x79219af1a0c0>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-16-3-1] _\u001b[0m\n",
            "\n",
            "s = 14, cin = 8, cout = 16, k = 3, stride = 1, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_back_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_backward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        x = ndl.init.rand(\u001b[94m1\u001b[39;49;00m, cin, s, s, device=device, requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        g = torch.nn.Conv2d(cin, cout, k, stride=stride, padding=k//\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        g.weight.data = torch.tensor(f.weight.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        g.bias.data = torch.tensor(f.bias.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        z = torch.tensor(x.cached_data.numpy(), requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        z.requires_grad = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       res1 = f(x)\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "cin        = 8\n",
            "cout       = 16\n",
            "device     = cpu()\n",
            "f          = <needle.nn.nn_conv.Conv object at 0x79219af8fe30>\n",
            "g          = Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "k          = 3\n",
            "s          = 14\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "x          = needle.Tensor([[[[0.23057128 0.26870903 0.8002556  ... 0.89270717 0.10357846\n",
            "    0.01809636]\n",
            "   [0.59058535 0.43553153....58820176 0.98280334\n",
            "    0.4994615 ]\n",
            "   [0.13629234 0.68629104 0.6020755  ... 0.61242527 0.23260188\n",
            "    0.4892255 ]]]])\n",
            "z          = tensor([[[[0.2306, 0.2687, 0.8003,  ..., 0.8927, 0.1036, 0.0181],\n",
            "          [0.5906, 0.4355, 0.7987,  ..., 0.2638, 0.9....5882, 0.9828, 0.4995],\n",
            "          [0.1363, 0.6863, 0.6021,  ..., 0.6124, 0.2326, 0.4892]]]],\n",
            "       requires_grad=True)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:383: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_basic.py\u001b[0m:75: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[0.23057128 0.26870903 0.8002556  ... 0.89270717 0.10357846\n",
            "    0.01809636]\n",
            "   [0.59058535 0.4355315...8820176 0.98280334\n",
            "    0.4994615 ]\n",
            "   [0.13629234 0.68629104 0.6020755  ... 0.61242527 0.23260188\n",
            "    0.4892255 ]]]]),)\n",
            "        kwargs     = {}\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x79219af8fe30>\n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_conv.py\u001b[0m:57: in forward\n",
            "    \u001b[0mout = ops.conv(out, \u001b[96mself\u001b[39;49;00m.weight, stride=\u001b[96mself\u001b[39;49;00m.stride, padding=\u001b[96mself\u001b[39;49;00m.padding)\u001b[90m\u001b[39;49;00m\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        out        = needle.Tensor([[[[0.23057128 0.4137802  0.48104244 ... 0.7080749  0.8794175\n",
            "    0.46163937]\n",
            "   [0.26870903 0.6863802  ....28646463 0.90192366\n",
            "    0.23260188]\n",
            "   [0.37406263 0.1939908  0.08044852 ... 0.50159144 0.85839814\n",
            "    0.4892255 ]]]])\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x79219af8fe30>\n",
            "        x          = needle.Tensor([[[[0.23057128 0.26870903 0.8002556  ... 0.89270717 0.10357846\n",
            "    0.01809636]\n",
            "   [0.59058535 0.43553153....58820176 0.98280334\n",
            "    0.4994615 ]\n",
            "   [0.13629234 0.68629104 0.6020755  ... 0.61242527 0.23260188\n",
            "    0.4892255 ]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[0.23057128 0.4137802  0.48104244 ... 0.7080749  0.8794175\n",
            "    0.46163937]\n",
            "   [0.26870903 0.6863802  ....28646463 0.90192366\n",
            "    0.23260188]\n",
            "   [0.37406263 0.1939908  0.08044852 ... 0.50159144 0.85839814\n",
            "    0.4892255 ]]]])\n",
            "        b          = needle.Tensor([[[[ 0.02818251  0.12423962  0.05933046 ...  0.24571836 -0.24766244\n",
            "    -0.238371  ]\n",
            "   [-0.27700204  0....18  0.07989958\n",
            "    -0.12652083]\n",
            "   [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\n",
            "     0.07735741]]]])\n",
            "        padding    = 1\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[0.23057128 0.4137802  0.48104244 ... 0.7080749  0.8794175\n",
            "    0.46163937]\n",
            "   [0.26870903 0.6863802 ...8  0.07989958\n",
            "    -0.12652083]\n",
            "   [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\n",
            "     0.07735741]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x79219a26b500>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[0.23057128 0.4137802  0.48104244 ... 0.7080749  0.8794175\n",
            "    0.46163937]\n",
            "   [0.26870903 0.6863802 ...8  0.07989958\n",
            "    -0.12652083]\n",
            "   [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\n",
            "     0.07735741]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x79219a26b500>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79219a2694c0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79219a2694c0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x79219a26b500>\n",
            "A = NDArray([[[[0.23057128 0.4137802  0.48104244 ... 0.7080749  0.8794175\n",
            "    0.46163937]\n",
            "   [0.26870903 0.6863802  0.2982...192366\n",
            "    0.23260188]\n",
            "   [0.37406263 0.1939908  0.08044852 ... 0.50159144 0.85839814\n",
            "    0.4892255 ]]]], device=cpu())\n",
            "B = NDArray([[[[ 0.02818251  0.12423962  0.05933046 ...  0.24571836 -0.24766244\n",
            "    -0.238371  ]\n",
            "   [-0.27700204  0.192038...\n",
            "    -0.12652083]\n",
            "   [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\n",
            "     0.07735741]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[0.23057128 0.4137802  0.48104244 ... 0.7080749  0.8794175\n",
            "    0.46163937]\n",
            "   [0.26870903 0.6863802  0.2982...192366\n",
            "    0.23260188]\n",
            "   [0.37406263 0.1939908  0.08044852 ... 0.50159144 0.85839814\n",
            "    0.4892255 ]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ..... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]]], device=cpu())\n",
            "B          = NDArray([[[[ 0.02818251  0.12423962  0.05933046 ...  0.24571836 -0.24766244\n",
            "    -0.238371  ]\n",
            "   [-0.27700204  0.192038...\n",
            "    -0.12652083]\n",
            "   [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\n",
            "     0.07735741]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[ 0.02818251  0.12423962  0.05933046 ...  0.24571836 -0.24766244\n",
            "  -0.238371  ]\n",
            " [-0.27700204  0.19203815  0....07989958\n",
            "  -0.12652083]\n",
            " [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\n",
            "   0.07735741]], device=cpu())\n",
            "cols       = NDArray([[0.         0.         0.         ... 0.22477733 0.62278897 0.1203874 ]\n",
            " [0.         0.         0.         .....        0.         0.        ]\n",
            " [0.9824449  0.42837852 0.7428983  ... 0.         0.         0.        ]], device=cpu())\n",
            "out_h      = 14\n",
            "out_w      = 14\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x79219a26b500>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-16-3-2] _\u001b[0m\n",
            "\n",
            "s = 14, cin = 8, cout = 16, k = 3, stride = 2, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_back_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_backward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        x = ndl.init.rand(\u001b[94m1\u001b[39;49;00m, cin, s, s, device=device, requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        g = torch.nn.Conv2d(cin, cout, k, stride=stride, padding=k//\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        g.weight.data = torch.tensor(f.weight.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        g.bias.data = torch.tensor(f.bias.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        z = torch.tensor(x.cached_data.numpy(), requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        z.requires_grad = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       res1 = f(x)\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "cin        = 8\n",
            "cout       = 16\n",
            "device     = cpu()\n",
            "f          = <needle.nn.nn_conv.Conv object at 0x7922818c4e90>\n",
            "g          = Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "k          = 3\n",
            "s          = 14\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "x          = needle.Tensor([[[[0.23057128 0.26870903 0.8002556  ... 0.89270717 0.10357846\n",
            "    0.01809636]\n",
            "   [0.59058535 0.43553153....58820176 0.98280334\n",
            "    0.4994615 ]\n",
            "   [0.13629234 0.68629104 0.6020755  ... 0.61242527 0.23260188\n",
            "    0.4892255 ]]]])\n",
            "z          = tensor([[[[0.2306, 0.2687, 0.8003,  ..., 0.8927, 0.1036, 0.0181],\n",
            "          [0.5906, 0.4355, 0.7987,  ..., 0.2638, 0.9....5882, 0.9828, 0.4995],\n",
            "          [0.1363, 0.6863, 0.6021,  ..., 0.6124, 0.2326, 0.4892]]]],\n",
            "       requires_grad=True)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:383: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_basic.py\u001b[0m:75: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[0.23057128 0.26870903 0.8002556  ... 0.89270717 0.10357846\n",
            "    0.01809636]\n",
            "   [0.59058535 0.4355315...8820176 0.98280334\n",
            "    0.4994615 ]\n",
            "   [0.13629234 0.68629104 0.6020755  ... 0.61242527 0.23260188\n",
            "    0.4892255 ]]]]),)\n",
            "        kwargs     = {}\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x7922818c4e90>\n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_conv.py\u001b[0m:57: in forward\n",
            "    \u001b[0mout = ops.conv(out, \u001b[96mself\u001b[39;49;00m.weight, stride=\u001b[96mself\u001b[39;49;00m.stride, padding=\u001b[96mself\u001b[39;49;00m.padding)\u001b[90m\u001b[39;49;00m\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        out        = needle.Tensor([[[[0.23057128 0.4137802  0.48104244 ... 0.7080749  0.8794175\n",
            "    0.46163937]\n",
            "   [0.26870903 0.6863802  ....28646463 0.90192366\n",
            "    0.23260188]\n",
            "   [0.37406263 0.1939908  0.08044852 ... 0.50159144 0.85839814\n",
            "    0.4892255 ]]]])\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x7922818c4e90>\n",
            "        x          = needle.Tensor([[[[0.23057128 0.26870903 0.8002556  ... 0.89270717 0.10357846\n",
            "    0.01809636]\n",
            "   [0.59058535 0.43553153....58820176 0.98280334\n",
            "    0.4994615 ]\n",
            "   [0.13629234 0.68629104 0.6020755  ... 0.61242527 0.23260188\n",
            "    0.4892255 ]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[0.23057128 0.4137802  0.48104244 ... 0.7080749  0.8794175\n",
            "    0.46163937]\n",
            "   [0.26870903 0.6863802  ....28646463 0.90192366\n",
            "    0.23260188]\n",
            "   [0.37406263 0.1939908  0.08044852 ... 0.50159144 0.85839814\n",
            "    0.4892255 ]]]])\n",
            "        b          = needle.Tensor([[[[ 0.02818251  0.12423962  0.05933046 ...  0.24571836 -0.24766244\n",
            "    -0.238371  ]\n",
            "   [-0.27700204  0....18  0.07989958\n",
            "    -0.12652083]\n",
            "   [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\n",
            "     0.07735741]]]])\n",
            "        padding    = 1\n",
            "        stride     = 2\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[0.23057128 0.4137802  0.48104244 ... 0.7080749  0.8794175\n",
            "    0.46163937]\n",
            "   [0.26870903 0.6863802 ...8  0.07989958\n",
            "    -0.12652083]\n",
            "   [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\n",
            "     0.07735741]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x7922818a8bf0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[0.23057128 0.4137802  0.48104244 ... 0.7080749  0.8794175\n",
            "    0.46163937]\n",
            "   [0.26870903 0.6863802 ...8  0.07989958\n",
            "    -0.12652083]\n",
            "   [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\n",
            "     0.07735741]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x7922818a8bf0>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7922818aaab0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x7922818aaab0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x7922818a8bf0>\n",
            "A = NDArray([[[[0.23057128 0.4137802  0.48104244 ... 0.7080749  0.8794175\n",
            "    0.46163937]\n",
            "   [0.26870903 0.6863802  0.2982...192366\n",
            "    0.23260188]\n",
            "   [0.37406263 0.1939908  0.08044852 ... 0.50159144 0.85839814\n",
            "    0.4892255 ]]]], device=cpu())\n",
            "B = NDArray([[[[ 0.02818251  0.12423962  0.05933046 ...  0.24571836 -0.24766244\n",
            "    -0.238371  ]\n",
            "   [-0.27700204  0.192038...\n",
            "    -0.12652083]\n",
            "   [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\n",
            "     0.07735741]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[0.23057128 0.4137802  0.48104244 ... 0.7080749  0.8794175\n",
            "    0.46163937]\n",
            "   [0.26870903 0.6863802  0.2982...192366\n",
            "    0.23260188]\n",
            "   [0.37406263 0.1939908  0.08044852 ... 0.50159144 0.85839814\n",
            "    0.4892255 ]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ..... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]]], device=cpu())\n",
            "B          = NDArray([[[[ 0.02818251  0.12423962  0.05933046 ...  0.24571836 -0.24766244\n",
            "    -0.238371  ]\n",
            "   [-0.27700204  0.192038...\n",
            "    -0.12652083]\n",
            "   [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\n",
            "     0.07735741]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[ 0.02818251  0.12423962  0.05933046 ...  0.24571836 -0.24766244\n",
            "  -0.238371  ]\n",
            " [-0.27700204  0.19203815  0....07989958\n",
            "  -0.12652083]\n",
            " [ 0.2585501   0.13195843 -0.09835096 ...  0.1191712  -0.2744856\n",
            "   0.07735741]], device=cpu())\n",
            "cols       = NDArray([[0.         0.         0.         ... 0.22477733 0.62278897 0.1203874 ]\n",
            " [0.         0.         0.         .....2455295 0.19085    0.61242527]\n",
            " [0.9665751  0.6012772  0.945431   ... 0.50159144 0.85839814 0.4892255 ]], device=cpu())\n",
            "out_h      = 7\n",
            "out_w      = 7\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x7922818a8bf0>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-8-3-1] _\u001b[0m\n",
            "\n",
            "s = 14, cin = 8, cout = 8, k = 3, stride = 1, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_back_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_backward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        x = ndl.init.rand(\u001b[94m1\u001b[39;49;00m, cin, s, s, device=device, requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        g = torch.nn.Conv2d(cin, cout, k, stride=stride, padding=k//\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        g.weight.data = torch.tensor(f.weight.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        g.bias.data = torch.tensor(f.bias.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        z = torch.tensor(x.cached_data.numpy(), requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        z.requires_grad = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       res1 = f(x)\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "cin        = 8\n",
            "cout       = 8\n",
            "device     = cpu()\n",
            "f          = <needle.nn.nn_conv.Conv object at 0x79219a269850>\n",
            "g          = Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "k          = 3\n",
            "s          = 14\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "x          = needle.Tensor([[[[0.16046764 0.8863047  0.4463944  ... 0.0599443  0.06107854\n",
            "    0.90773296]\n",
            "   [0.7398839  0.89806235....9895251  0.64441556\n",
            "    0.36599803]\n",
            "   [0.10201953 0.7878494  0.7080749  ... 0.5395366  0.04585036\n",
            "    0.46389467]]]])\n",
            "z          = tensor([[[[0.1605, 0.8863, 0.4464,  ..., 0.0599, 0.0611, 0.9077],\n",
            "          [0.7399, 0.8981, 0.6726,  ..., 0.3280, 0.6....9895, 0.6444, 0.3660],\n",
            "          [0.1020, 0.7878, 0.7081,  ..., 0.5395, 0.0459, 0.4639]]]],\n",
            "       requires_grad=True)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:383: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_basic.py\u001b[0m:75: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[0.16046764 0.8863047  0.4463944  ... 0.0599443  0.06107854\n",
            "    0.90773296]\n",
            "   [0.7398839  0.8980623...895251  0.64441556\n",
            "    0.36599803]\n",
            "   [0.10201953 0.7878494  0.7080749  ... 0.5395366  0.04585036\n",
            "    0.46389467]]]]),)\n",
            "        kwargs     = {}\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x79219a269850>\n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_conv.py\u001b[0m:57: in forward\n",
            "    \u001b[0mout = ops.conv(out, \u001b[96mself\u001b[39;49;00m.weight, stride=\u001b[96mself\u001b[39;49;00m.stride, padding=\u001b[96mself\u001b[39;49;00m.padding)\u001b[90m\u001b[39;49;00m\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        out        = needle.Tensor([[[[0.16046764 0.21645726 0.06918266 ... 0.05975792 0.70340705\n",
            "    0.5320924 ]\n",
            "   [0.8863047  0.16604783....616183   0.00620341\n",
            "    0.04585036]\n",
            "   [0.24488948 0.72982764 0.89270717 ... 0.38427317 0.00928445\n",
            "    0.46389467]]]])\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x79219a269850>\n",
            "        x          = needle.Tensor([[[[0.16046764 0.8863047  0.4463944  ... 0.0599443  0.06107854\n",
            "    0.90773296]\n",
            "   [0.7398839  0.89806235....9895251  0.64441556\n",
            "    0.36599803]\n",
            "   [0.10201953 0.7878494  0.7080749  ... 0.5395366  0.04585036\n",
            "    0.46389467]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[0.16046764 0.21645726 0.06918266 ... 0.05975792 0.70340705\n",
            "    0.5320924 ]\n",
            "   [0.8863047  0.16604783....616183   0.00620341\n",
            "    0.04585036]\n",
            "   [0.24488948 0.72982764 0.89270717 ... 0.38427317 0.00928445\n",
            "    0.46389467]]]])\n",
            "        b          = needle.Tensor([[[[ 0.02818251  0.12423962  0.05933046  0.02591333 -0.04407792\n",
            "     0.084232   -0.03603405  0.22619021]....24439585]\n",
            "   [ 0.19046631  0.2703653   0.24236172 -0.267871   -0.18777046\n",
            "    -0.06400812  0.26104474 -0.11545335]]]])\n",
            "        padding    = 1\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[0.16046764 0.21645726 0.06918266 ... 0.05975792 0.70340705\n",
            "    0.5320924 ]\n",
            "   [0.8863047  0.1660478...24439585]\n",
            "   [ 0.19046631  0.2703653   0.24236172 -0.267871   -0.18777046\n",
            "    -0.06400812  0.26104474 -0.11545335]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x79219a26ab40>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[0.16046764 0.21645726 0.06918266 ... 0.05975792 0.70340705\n",
            "    0.5320924 ]\n",
            "   [0.8863047  0.1660478...24439585]\n",
            "   [ 0.19046631  0.2703653   0.24236172 -0.267871   -0.18777046\n",
            "    -0.06400812  0.26104474 -0.11545335]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x79219a26ab40>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79219a26a0f0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79219a26a0f0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x79219a26ab40>\n",
            "A = NDArray([[[[0.16046764 0.21645726 0.06918266 ... 0.05975792 0.70340705\n",
            "    0.5320924 ]\n",
            "   [0.8863047  0.16604783 0.879...620341\n",
            "    0.04585036]\n",
            "   [0.24488948 0.72982764 0.89270717 ... 0.38427317 0.00928445\n",
            "    0.46389467]]]], device=cpu())\n",
            "B = NDArray([[[[ 0.02818251  0.12423962  0.05933046  0.02591333 -0.04407792\n",
            "     0.084232   -0.03603405  0.22619021]\n",
            "   [ ...[ 0.19046631  0.2703653   0.24236172 -0.267871   -0.18777046\n",
            "    -0.06400812  0.26104474 -0.11545335]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[0.16046764 0.21645726 0.06918266 ... 0.05975792 0.70340705\n",
            "    0.5320924 ]\n",
            "   [0.8863047  0.16604783 0.879...620341\n",
            "    0.04585036]\n",
            "   [0.24488948 0.72982764 0.89270717 ... 0.38427317 0.00928445\n",
            "    0.46389467]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ..... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]]], device=cpu())\n",
            "B          = NDArray([[[[ 0.02818251  0.12423962  0.05933046  0.02591333 -0.04407792\n",
            "     0.084232   -0.03603405  0.22619021]\n",
            "   [ ...[ 0.19046631  0.2703653   0.24236172 -0.267871   -0.18777046\n",
            "    -0.06400812  0.26104474 -0.11545335]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[ 0.02818251  0.12423962  0.05933046  0.02591333 -0.04407792  0.084232\n",
            "  -0.03603405  0.22619021]\n",
            " [ 0.267695...5]\n",
            " [ 0.19046631  0.2703653   0.24236172 -0.267871   -0.18777046 -0.06400812\n",
            "   0.26104474 -0.11545335]], device=cpu())\n",
            "cols       = NDArray([[0.         0.         0.         ... 0.72239155 0.8418157  0.16632462]\n",
            " [0.         0.         0.         .....        0.         0.        ]\n",
            " [0.37191874 0.16235794 0.34989768 ... 0.         0.         0.        ]], device=cpu())\n",
            "out_h      = 14\n",
            "out_w      = 14\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x79219a26ab40>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-8-3-2] _\u001b[0m\n",
            "\n",
            "s = 14, cin = 8, cout = 8, k = 3, stride = 2, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_back_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_backward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        x = ndl.init.rand(\u001b[94m1\u001b[39;49;00m, cin, s, s, device=device, requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        g = torch.nn.Conv2d(cin, cout, k, stride=stride, padding=k//\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        g.weight.data = torch.tensor(f.weight.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        g.bias.data = torch.tensor(f.bias.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        z = torch.tensor(x.cached_data.numpy(), requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        z.requires_grad = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       res1 = f(x)\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "cin        = 8\n",
            "cout       = 8\n",
            "device     = cpu()\n",
            "f          = <needle.nn.nn_conv.Conv object at 0x79219a2b9cd0>\n",
            "g          = Conv2d(8, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "k          = 3\n",
            "s          = 14\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "x          = needle.Tensor([[[[0.16046764 0.8863047  0.4463944  ... 0.0599443  0.06107854\n",
            "    0.90773296]\n",
            "   [0.7398839  0.89806235....9895251  0.64441556\n",
            "    0.36599803]\n",
            "   [0.10201953 0.7878494  0.7080749  ... 0.5395366  0.04585036\n",
            "    0.46389467]]]])\n",
            "z          = tensor([[[[0.1605, 0.8863, 0.4464,  ..., 0.0599, 0.0611, 0.9077],\n",
            "          [0.7399, 0.8981, 0.6726,  ..., 0.3280, 0.6....9895, 0.6444, 0.3660],\n",
            "          [0.1020, 0.7878, 0.7081,  ..., 0.5395, 0.0459, 0.4639]]]],\n",
            "       requires_grad=True)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:383: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_basic.py\u001b[0m:75: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[0.16046764 0.8863047  0.4463944  ... 0.0599443  0.06107854\n",
            "    0.90773296]\n",
            "   [0.7398839  0.8980623...895251  0.64441556\n",
            "    0.36599803]\n",
            "   [0.10201953 0.7878494  0.7080749  ... 0.5395366  0.04585036\n",
            "    0.46389467]]]]),)\n",
            "        kwargs     = {}\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x79219a2b9cd0>\n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_conv.py\u001b[0m:57: in forward\n",
            "    \u001b[0mout = ops.conv(out, \u001b[96mself\u001b[39;49;00m.weight, stride=\u001b[96mself\u001b[39;49;00m.stride, padding=\u001b[96mself\u001b[39;49;00m.padding)\u001b[90m\u001b[39;49;00m\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        out        = needle.Tensor([[[[0.16046764 0.21645726 0.06918266 ... 0.05975792 0.70340705\n",
            "    0.5320924 ]\n",
            "   [0.8863047  0.16604783....616183   0.00620341\n",
            "    0.04585036]\n",
            "   [0.24488948 0.72982764 0.89270717 ... 0.38427317 0.00928445\n",
            "    0.46389467]]]])\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x79219a2b9cd0>\n",
            "        x          = needle.Tensor([[[[0.16046764 0.8863047  0.4463944  ... 0.0599443  0.06107854\n",
            "    0.90773296]\n",
            "   [0.7398839  0.89806235....9895251  0.64441556\n",
            "    0.36599803]\n",
            "   [0.10201953 0.7878494  0.7080749  ... 0.5395366  0.04585036\n",
            "    0.46389467]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[0.16046764 0.21645726 0.06918266 ... 0.05975792 0.70340705\n",
            "    0.5320924 ]\n",
            "   [0.8863047  0.16604783....616183   0.00620341\n",
            "    0.04585036]\n",
            "   [0.24488948 0.72982764 0.89270717 ... 0.38427317 0.00928445\n",
            "    0.46389467]]]])\n",
            "        b          = needle.Tensor([[[[ 0.02818251  0.12423962  0.05933046  0.02591333 -0.04407792\n",
            "     0.084232   -0.03603405  0.22619021]....24439585]\n",
            "   [ 0.19046631  0.2703653   0.24236172 -0.267871   -0.18777046\n",
            "    -0.06400812  0.26104474 -0.11545335]]]])\n",
            "        padding    = 1\n",
            "        stride     = 2\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[0.16046764 0.21645726 0.06918266 ... 0.05975792 0.70340705\n",
            "    0.5320924 ]\n",
            "   [0.8863047  0.1660478...24439585]\n",
            "   [ 0.19046631  0.2703653   0.24236172 -0.267871   -0.18777046\n",
            "    -0.06400812  0.26104474 -0.11545335]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x79219a2bb0b0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[0.16046764 0.21645726 0.06918266 ... 0.05975792 0.70340705\n",
            "    0.5320924 ]\n",
            "   [0.8863047  0.1660478...24439585]\n",
            "   [ 0.19046631  0.2703653   0.24236172 -0.267871   -0.18777046\n",
            "    -0.06400812  0.26104474 -0.11545335]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x79219a2bb0b0>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79219a2bb380>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79219a2bb380>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x79219a2bb0b0>\n",
            "A = NDArray([[[[0.16046764 0.21645726 0.06918266 ... 0.05975792 0.70340705\n",
            "    0.5320924 ]\n",
            "   [0.8863047  0.16604783 0.879...620341\n",
            "    0.04585036]\n",
            "   [0.24488948 0.72982764 0.89270717 ... 0.38427317 0.00928445\n",
            "    0.46389467]]]], device=cpu())\n",
            "B = NDArray([[[[ 0.02818251  0.12423962  0.05933046  0.02591333 -0.04407792\n",
            "     0.084232   -0.03603405  0.22619021]\n",
            "   [ ...[ 0.19046631  0.2703653   0.24236172 -0.267871   -0.18777046\n",
            "    -0.06400812  0.26104474 -0.11545335]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[0.16046764 0.21645726 0.06918266 ... 0.05975792 0.70340705\n",
            "    0.5320924 ]\n",
            "   [0.8863047  0.16604783 0.879...620341\n",
            "    0.04585036]\n",
            "   [0.24488948 0.72982764 0.89270717 ... 0.38427317 0.00928445\n",
            "    0.46389467]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ..... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]]], device=cpu())\n",
            "B          = NDArray([[[[ 0.02818251  0.12423962  0.05933046  0.02591333 -0.04407792\n",
            "     0.084232   -0.03603405  0.22619021]\n",
            "   [ ...[ 0.19046631  0.2703653   0.24236172 -0.267871   -0.18777046\n",
            "    -0.06400812  0.26104474 -0.11545335]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[ 0.02818251  0.12423962  0.05933046  0.02591333 -0.04407792  0.084232\n",
            "  -0.03603405  0.22619021]\n",
            " [ 0.267695...5]\n",
            " [ 0.19046631  0.2703653   0.24236172 -0.267871   -0.18777046 -0.06400812\n",
            "   0.26104474 -0.11545335]], device=cpu())\n",
            "cols       = NDArray([[0.         0.         0.         ... 0.72239155 0.8418157  0.16632462]\n",
            " [0.         0.         0.         .....7047735 0.1851164  0.5395366 ]\n",
            " [0.97073144 0.15093489 0.33044058 ... 0.38427317 0.00928445 0.46389467]], device=cpu())\n",
            "out_h      = 7\n",
            "out_w      = 7\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x79219a2bb0b0>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-16-8-3-1] _\u001b[0m\n",
            "\n",
            "s = 14, cin = 16, cout = 8, k = 3, stride = 1, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_back_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_backward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        x = ndl.init.rand(\u001b[94m1\u001b[39;49;00m, cin, s, s, device=device, requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        g = torch.nn.Conv2d(cin, cout, k, stride=stride, padding=k//\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        g.weight.data = torch.tensor(f.weight.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        g.bias.data = torch.tensor(f.bias.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        z = torch.tensor(x.cached_data.numpy(), requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        z.requires_grad = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       res1 = f(x)\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "cin        = 16\n",
            "cout       = 8\n",
            "device     = cpu()\n",
            "f          = <needle.nn.nn_conv.Conv object at 0x79219a2fc4a0>\n",
            "g          = Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "k          = 3\n",
            "s          = 14\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "x          = needle.Tensor([[[[2.30571285e-01 2.68709034e-01 8.00255597e-01 ... 8.92707169e-01\n",
            "    1.03578463e-01 1.80963576e-02]\n",
            " ...9546629e-02]\n",
            "   [5.53714156e-01 8.54465425e-01 1.40972406e-01 ... 1.98812798e-01\n",
            "    7.92465881e-02 4.67657059e-01]]]])\n",
            "z          = tensor([[[[2.3057e-01, 2.6871e-01, 8.0026e-01,  ..., 8.9271e-01,\n",
            "           1.0358e-01, 1.8096e-02],\n",
            "          [5.9059...      [5.5371e-01, 8.5447e-01, 1.4097e-01,  ..., 1.9881e-01,\n",
            "           7.9247e-02, 4.6766e-01]]]], requires_grad=True)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:383: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_basic.py\u001b[0m:75: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[2.30571285e-01 2.68709034e-01 8.00255597e-01 ... 8.92707169e-01\n",
            "    1.03578463e-01 1.80963576e-02]\n",
            "...46629e-02]\n",
            "   [5.53714156e-01 8.54465425e-01 1.40972406e-01 ... 1.98812798e-01\n",
            "    7.92465881e-02 4.67657059e-01]]]]),)\n",
            "        kwargs     = {}\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x79219a2fc4a0>\n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_conv.py\u001b[0m:57: in forward\n",
            "    \u001b[0mout = ops.conv(out, \u001b[96mself\u001b[39;49;00m.weight, stride=\u001b[96mself\u001b[39;49;00m.stride, padding=\u001b[96mself\u001b[39;49;00m.padding)\u001b[90m\u001b[39;49;00m\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        out        = needle.Tensor([[[[2.30571285e-01 4.13780212e-01 4.81042445e-01 ... 5.77296734e-01\n",
            "    2.61953145e-01 8.37002099e-02]\n",
            " ...2465881e-02]\n",
            "   [3.74062628e-01 1.93990797e-01 8.04485157e-02 ... 1.88007966e-01\n",
            "    4.31537718e-01 4.67657059e-01]]]])\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x79219a2fc4a0>\n",
            "        x          = needle.Tensor([[[[2.30571285e-01 2.68709034e-01 8.00255597e-01 ... 8.92707169e-01\n",
            "    1.03578463e-01 1.80963576e-02]\n",
            " ...9546629e-02]\n",
            "   [5.53714156e-01 8.54465425e-01 1.40972406e-01 ... 1.98812798e-01\n",
            "    7.92465881e-02 4.67657059e-01]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[2.30571285e-01 4.13780212e-01 4.81042445e-01 ... 5.77296734e-01\n",
            "    2.61953145e-01 8.37002099e-02]\n",
            " ...2465881e-02]\n",
            "   [3.74062628e-01 1.93990797e-01 8.04485157e-02 ... 1.88007966e-01\n",
            "    4.31537718e-01 4.67657059e-01]]]])\n",
            "        b          = needle.Tensor([[[[ 0.01992804  0.08785069  0.04195297 ...  0.05956101 -0.02547991\n",
            "     0.15994066]\n",
            "   [ 0.18928954 -0....2 -0.11381223\n",
            "     0.07500601]\n",
            "   [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\n",
            "     0.05469996]]]])\n",
            "        padding    = 1\n",
            "        stride     = 1\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[2.30571285e-01 4.13780212e-01 4.81042445e-01 ... 5.77296734e-01\n",
            "    2.61953145e-01 8.37002099e-02]\n",
            "... -0.11381223\n",
            "     0.07500601]\n",
            "   [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\n",
            "     0.05469996]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x79219a2fd640>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[2.30571285e-01 4.13780212e-01 4.81042445e-01 ... 5.77296734e-01\n",
            "    2.61953145e-01 8.37002099e-02]\n",
            "... -0.11381223\n",
            "     0.07500601]\n",
            "   [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\n",
            "     0.05469996]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x79219a2fd640>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79219a2fd790>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79219a2fd790>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x79219a2fd640>\n",
            "A = NDArray([[[[2.30571285e-01 4.13780212e-01 4.81042445e-01 ... 5.77296734e-01\n",
            "    2.61953145e-01 8.37002099e-02]\n",
            "   [2.6...  [3.74062628e-01 1.93990797e-01 8.04485157e-02 ... 1.88007966e-01\n",
            "    4.31537718e-01 4.67657059e-01]]]], device=cpu())\n",
            "B = NDArray([[[[ 0.01992804  0.08785069  0.04195297 ...  0.05956101 -0.02547991\n",
            "     0.15994066]\n",
            "   [ 0.18928954 -0.047584...     0.07500601]\n",
            "   [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\n",
            "     0.05469996]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[2.30571285e-01 4.13780212e-01 4.81042445e-01 ... 5.77296734e-01\n",
            "    2.61953145e-01 8.37002099e-02]\n",
            "   [2.6...  [3.74062628e-01 1.93990797e-01 8.04485157e-02 ... 1.88007966e-01\n",
            "    4.31537718e-01 4.67657059e-01]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ..... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]]], device=cpu())\n",
            "B          = NDArray([[[[ 0.01992804  0.08785069  0.04195297 ...  0.05956101 -0.02547991\n",
            "     0.15994066]\n",
            "   [ 0.18928954 -0.047584...     0.07500601]\n",
            "   [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\n",
            "     0.05469996]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[ 0.01992804  0.08785069  0.04195297 ...  0.05956101 -0.02547991\n",
            "   0.15994066]\n",
            " [ 0.18928954 -0.0475848   0....1381223\n",
            "   0.07500601]\n",
            " [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\n",
            "   0.05469996]], device=cpu())\n",
            "cols       = NDArray([[0.         0.         0.         ... 0.20921049 0.66919315 0.8368076 ]\n",
            " [0.         0.         0.         .....        0.         0.        ]\n",
            " [0.9824449  0.42837852 0.7428983  ... 0.         0.         0.        ]], device=cpu())\n",
            "out_h      = 14\n",
            "out_w      = 14\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x79219a2fd640>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-16-8-3-2] _\u001b[0m\n",
            "\n",
            "s = 14, cin = 16, cout = 8, k = 3, stride = 2, device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_back_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_backward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "        x = ndl.init.rand(\u001b[94m1\u001b[39;49;00m, cin, s, s, device=device, requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        g = torch.nn.Conv2d(cin, cout, k, stride=stride, padding=k//\u001b[94m2\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        g.weight.data = torch.tensor(f.weight.cached_data.numpy().transpose(\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        g.bias.data = torch.tensor(f.bias.cached_data.numpy())\u001b[90m\u001b[39;49;00m\n",
            "        z = torch.tensor(x.cached_data.numpy(), requires_grad=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        z.requires_grad = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       res1 = f(x)\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "cin        = 16\n",
            "cout       = 8\n",
            "device     = cpu()\n",
            "f          = <needle.nn.nn_conv.Conv object at 0x79219a26b770>\n",
            "g          = Conv2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "k          = 3\n",
            "s          = 14\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "x          = needle.Tensor([[[[2.30571285e-01 2.68709034e-01 8.00255597e-01 ... 8.92707169e-01\n",
            "    1.03578463e-01 1.80963576e-02]\n",
            " ...9546629e-02]\n",
            "   [5.53714156e-01 8.54465425e-01 1.40972406e-01 ... 1.98812798e-01\n",
            "    7.92465881e-02 4.67657059e-01]]]])\n",
            "z          = tensor([[[[2.3057e-01, 2.6871e-01, 8.0026e-01,  ..., 8.9271e-01,\n",
            "           1.0358e-01, 1.8096e-02],\n",
            "          [5.9059...      [5.5371e-01, 8.5447e-01, 1.4097e-01,  ..., 1.9881e-01,\n",
            "           7.9247e-02, 4.6766e-01]]]], requires_grad=True)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:383: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_basic.py\u001b[0m:75: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[2.30571285e-01 2.68709034e-01 8.00255597e-01 ... 8.92707169e-01\n",
            "    1.03578463e-01 1.80963576e-02]\n",
            "...46629e-02]\n",
            "   [5.53714156e-01 8.54465425e-01 1.40972406e-01 ... 1.98812798e-01\n",
            "    7.92465881e-02 4.67657059e-01]]]]),)\n",
            "        kwargs     = {}\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x79219a26b770>\n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_conv.py\u001b[0m:57: in forward\n",
            "    \u001b[0mout = ops.conv(out, \u001b[96mself\u001b[39;49;00m.weight, stride=\u001b[96mself\u001b[39;49;00m.stride, padding=\u001b[96mself\u001b[39;49;00m.padding)\u001b[90m\u001b[39;49;00m\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        out        = needle.Tensor([[[[2.30571285e-01 4.13780212e-01 4.81042445e-01 ... 5.77296734e-01\n",
            "    2.61953145e-01 8.37002099e-02]\n",
            " ...2465881e-02]\n",
            "   [3.74062628e-01 1.93990797e-01 8.04485157e-02 ... 1.88007966e-01\n",
            "    4.31537718e-01 4.67657059e-01]]]])\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x79219a26b770>\n",
            "        x          = needle.Tensor([[[[2.30571285e-01 2.68709034e-01 8.00255597e-01 ... 8.92707169e-01\n",
            "    1.03578463e-01 1.80963576e-02]\n",
            " ...9546629e-02]\n",
            "   [5.53714156e-01 8.54465425e-01 1.40972406e-01 ... 1.98812798e-01\n",
            "    7.92465881e-02 4.67657059e-01]]]])\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        a          = needle.Tensor([[[[2.30571285e-01 4.13780212e-01 4.81042445e-01 ... 5.77296734e-01\n",
            "    2.61953145e-01 8.37002099e-02]\n",
            " ...2465881e-02]\n",
            "   [3.74062628e-01 1.93990797e-01 8.04485157e-02 ... 1.88007966e-01\n",
            "    4.31537718e-01 4.67657059e-01]]]])\n",
            "        b          = needle.Tensor([[[[ 0.01992804  0.08785069  0.04195297 ...  0.05956101 -0.02547991\n",
            "     0.15994066]\n",
            "   [ 0.18928954 -0....2 -0.11381223\n",
            "     0.07500601]\n",
            "   [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\n",
            "     0.05469996]]]])\n",
            "        padding    = 1\n",
            "        stride     = 2\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        args       = (needle.Tensor([[[[2.30571285e-01 4.13780212e-01 4.81042445e-01 ... 5.77296734e-01\n",
            "    2.61953145e-01 8.37002099e-02]\n",
            "... -0.11381223\n",
            "     0.07500601]\n",
            "   [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\n",
            "     0.05469996]]]]))\n",
            "        self       = <needle.ops.ops_mathematic.Conv object at 0x79219a26b860>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "        inputs     = (needle.Tensor([[[[2.30571285e-01 4.13780212e-01 4.81042445e-01 ... 5.77296734e-01\n",
            "    2.61953145e-01 8.37002099e-02]\n",
            "... -0.11381223\n",
            "     0.07500601]\n",
            "   [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\n",
            "     0.05469996]]]]))\n",
            "        op         = <needle.ops.ops_mathematic.Conv object at 0x79219a26b860>\n",
            "        tensor     = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79219a26bcb0>\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute 'matmul'\") raised in repr()] Tensor object at 0x79219a26bcb0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x79219a26b860>\n",
            "A = NDArray([[[[2.30571285e-01 4.13780212e-01 4.81042445e-01 ... 5.77296734e-01\n",
            "    2.61953145e-01 8.37002099e-02]\n",
            "   [2.6...  [3.74062628e-01 1.93990797e-01 8.04485157e-02 ... 1.88007966e-01\n",
            "    4.31537718e-01 4.67657059e-01]]]], device=cpu())\n",
            "B = NDArray([[[[ 0.01992804  0.08785069  0.04195297 ...  0.05956101 -0.02547991\n",
            "     0.15994066]\n",
            "   [ 0.18928954 -0.047584...     0.07500601]\n",
            "   [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\n",
            "     0.05469996]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "A          = NDArray([[[[2.30571285e-01 4.13780212e-01 4.81042445e-01 ... 5.77296734e-01\n",
            "    2.61953145e-01 8.37002099e-02]\n",
            "   [2.6...  [3.74062628e-01 1.93990797e-01 8.04485157e-02 ... 1.88007966e-01\n",
            "    4.31537718e-01 4.67657059e-01]]]], device=cpu())\n",
            "A_padded   = NDArray([[[[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ..... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]]], device=cpu())\n",
            "B          = NDArray([[[[ 0.01992804  0.08785069  0.04195297 ...  0.05956101 -0.02547991\n",
            "     0.15994066]\n",
            "   [ 0.18928954 -0.047584...     0.07500601]\n",
            "   [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\n",
            "     0.05469996]]]], device=cpu())\n",
            "K          = 3\n",
            "W_col      = NDArray([[ 0.01992804  0.08785069  0.04195297 ...  0.05956101 -0.02547991\n",
            "   0.15994066]\n",
            " [ 0.18928954 -0.0475848   0....1381223\n",
            "   0.07500601]\n",
            " [-0.16230063 -0.04203904 -0.09118237 ...  0.08426678 -0.19409062\n",
            "   0.05469996]], device=cpu())\n",
            "cols       = NDArray([[0.         0.         0.         ... 0.20921049 0.66919315 0.8368076 ]\n",
            " [0.         0.         0.         .....96802   0.12021667 0.1988128 ]\n",
            " [0.9665751  0.6012772  0.945431   ... 0.18800797 0.43153772 0.46765706]], device=cpu())\n",
            "out_h      = 7\n",
            "out_w      = 7\n",
            "self       = <needle.ops.ops_mathematic.Conv object at 0x79219a26b860>\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-4-1-1-3-1] _\u001b[0m\n",
            "\n",
            "s = 4, cin = 1, cout = 1, k = 3, stride = 1, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_back_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_backward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "cin        = 1\n",
            "cout       = 1\n",
            "device     = cuda()\n",
            "k          = 3\n",
            "s          = 4\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:374: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_conv.py\u001b[0m:35: in __init__\n",
            "    \u001b[0minit.kaiming_uniform(\u001b[90m\u001b[39;49;00m\n",
            "        __class__  = <class 'needle.nn.nn_conv.Conv'>\n",
            "        bias       = True\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        fan_in     = 9\n",
            "        fan_out    = 9\n",
            "        in_channels = 1\n",
            "        kernel_size = 3\n",
            "        out_channels = 1\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x79219a2b8320>\n",
            "        stride     = 1\n",
            "        weight_shape = (3, 3, 1, 1)\n",
            "\u001b[1m\u001b[31mpython/needle/init/init_initializers.py\u001b[0m:30: in kaiming_uniform\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m rand(*shape, low=-bound, high=bound, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        bound      = 0.816496580927726\n",
            "        fan_in     = 9\n",
            "        fan_out    = 9\n",
            "        kwargs     = {'device': cuda(), 'dtype': 'float32'}\n",
            "        nonlinearity = 'relu'\n",
            "        shape      = (3, 3, 1, 1)\n",
            "\u001b[1m\u001b[31mpython/needle/init/init_basic.py\u001b[0m:8: in rand\n",
            "    \u001b[0marray = device.rand(*shape) * (high - low) + low\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        high       = 0.816496580927726\n",
            "        low        = -0.816496580927726\n",
            "        requires_grad = False\n",
            "        shape      = (3, 3, 1, 1)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:44: in rand\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(np.random.rand(*shape).astype(dtype), device=\u001b[96mself\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        dtype      = 'float32'\n",
            "        self       = cuda()\n",
            "        shape      = (3, 3, 1, 1)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[0.5488135 ]],\n",
            "\n",
            "        [[0.71518934]],\n",
            "\n",
            "        [[0.60276335]]],\n",
            "\n",
            "\n",
            "       [[[0.5448832 ]],\n",
            "\n",
            "        [[0.4236...\n",
            "\n",
            "        [[0.6458941 ]]],\n",
            "\n",
            "\n",
            "       [[[0.4375872 ]],\n",
            "\n",
            "        [[0.891773  ]],\n",
            "\n",
            "        [[0.96366274]]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x79219a2b9700>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 3, 1, 1), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x79219a2bb4d0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 3, 1, 1)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-16-3-1] _\u001b[0m\n",
            "\n",
            "s = 14, cin = 8, cout = 16, k = 3, stride = 1, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_back_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_backward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "cin        = 8\n",
            "cout       = 16\n",
            "device     = cuda()\n",
            "k          = 3\n",
            "s          = 14\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:374: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_conv.py\u001b[0m:35: in __init__\n",
            "    \u001b[0minit.kaiming_uniform(\u001b[90m\u001b[39;49;00m\n",
            "        __class__  = <class 'needle.nn.nn_conv.Conv'>\n",
            "        bias       = True\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        fan_in     = 72\n",
            "        fan_out    = 144\n",
            "        in_channels = 8\n",
            "        kernel_size = 3\n",
            "        out_channels = 16\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x79219a26a570>\n",
            "        stride     = 1\n",
            "        weight_shape = (3, 3, 8, 16)\n",
            "\u001b[1m\u001b[31mpython/needle/init/init_initializers.py\u001b[0m:30: in kaiming_uniform\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m rand(*shape, low=-bound, high=bound, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        bound      = 0.28867513459481287\n",
            "        fan_in     = 72\n",
            "        fan_out    = 144\n",
            "        kwargs     = {'device': cuda(), 'dtype': 'float32'}\n",
            "        nonlinearity = 'relu'\n",
            "        shape      = (3, 3, 8, 16)\n",
            "\u001b[1m\u001b[31mpython/needle/init/init_basic.py\u001b[0m:8: in rand\n",
            "    \u001b[0marray = device.rand(*shape) * (high - low) + low\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        high       = 0.28867513459481287\n",
            "        low        = -0.28867513459481287\n",
            "        requires_grad = False\n",
            "        shape      = (3, 3, 8, 16)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:44: in rand\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(np.random.rand(*shape).astype(dtype), device=\u001b[96mself\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        dtype      = 'float32'\n",
            "        self       = cuda()\n",
            "        shape      = (3, 3, 8, 16)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[5.4881352e-01, 7.1518934e-01, 6.0276335e-01, ...,\n",
            "          9.2559665e-01, 7.1036056e-02, 8.7129302e-02],\n",
            "  ...82192e-01, 7.2855872e-01, 3.2965115e-01, ...,\n",
            "          7.0641059e-01, 2.4577023e-02, 6.3398695e-01]]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x79219a26ade0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 3, 8, 16), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x79219a26baa0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 3, 8, 16)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-16-3-2] _\u001b[0m\n",
            "\n",
            "s = 14, cin = 8, cout = 16, k = 3, stride = 2, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_back_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_backward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "cin        = 8\n",
            "cout       = 16\n",
            "device     = cuda()\n",
            "k          = 3\n",
            "s          = 14\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:374: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_conv.py\u001b[0m:35: in __init__\n",
            "    \u001b[0minit.kaiming_uniform(\u001b[90m\u001b[39;49;00m\n",
            "        __class__  = <class 'needle.nn.nn_conv.Conv'>\n",
            "        bias       = True\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        fan_in     = 72\n",
            "        fan_out    = 144\n",
            "        in_channels = 8\n",
            "        kernel_size = 3\n",
            "        out_channels = 16\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x79219a2fc140>\n",
            "        stride     = 2\n",
            "        weight_shape = (3, 3, 8, 16)\n",
            "\u001b[1m\u001b[31mpython/needle/init/init_initializers.py\u001b[0m:30: in kaiming_uniform\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m rand(*shape, low=-bound, high=bound, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        bound      = 0.28867513459481287\n",
            "        fan_in     = 72\n",
            "        fan_out    = 144\n",
            "        kwargs     = {'device': cuda(), 'dtype': 'float32'}\n",
            "        nonlinearity = 'relu'\n",
            "        shape      = (3, 3, 8, 16)\n",
            "\u001b[1m\u001b[31mpython/needle/init/init_basic.py\u001b[0m:8: in rand\n",
            "    \u001b[0marray = device.rand(*shape) * (high - low) + low\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        high       = 0.28867513459481287\n",
            "        low        = -0.28867513459481287\n",
            "        requires_grad = False\n",
            "        shape      = (3, 3, 8, 16)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:44: in rand\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(np.random.rand(*shape).astype(dtype), device=\u001b[96mself\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        dtype      = 'float32'\n",
            "        self       = cuda()\n",
            "        shape      = (3, 3, 8, 16)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[5.4881352e-01, 7.1518934e-01, 6.0276335e-01, ...,\n",
            "          9.2559665e-01, 7.1036056e-02, 8.7129302e-02],\n",
            "  ...82192e-01, 7.2855872e-01, 3.2965115e-01, ...,\n",
            "          7.0641059e-01, 2.4577023e-02, 6.3398695e-01]]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x79219a2fd880>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 3, 8, 16), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x79219a2fc800>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 3, 8, 16)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-8-3-1] _\u001b[0m\n",
            "\n",
            "s = 14, cin = 8, cout = 8, k = 3, stride = 1, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_back_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_backward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "cin        = 8\n",
            "cout       = 8\n",
            "device     = cuda()\n",
            "k          = 3\n",
            "s          = 14\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:374: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_conv.py\u001b[0m:35: in __init__\n",
            "    \u001b[0minit.kaiming_uniform(\u001b[90m\u001b[39;49;00m\n",
            "        __class__  = <class 'needle.nn.nn_conv.Conv'>\n",
            "        bias       = True\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        fan_in     = 72\n",
            "        fan_out    = 72\n",
            "        in_channels = 8\n",
            "        kernel_size = 3\n",
            "        out_channels = 8\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x79219a2b84a0>\n",
            "        stride     = 1\n",
            "        weight_shape = (3, 3, 8, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/init/init_initializers.py\u001b[0m:30: in kaiming_uniform\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m rand(*shape, low=-bound, high=bound, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        bound      = 0.28867513459481287\n",
            "        fan_in     = 72\n",
            "        fan_out    = 72\n",
            "        kwargs     = {'device': cuda(), 'dtype': 'float32'}\n",
            "        nonlinearity = 'relu'\n",
            "        shape      = (3, 3, 8, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/init/init_basic.py\u001b[0m:8: in rand\n",
            "    \u001b[0marray = device.rand(*shape) * (high - low) + low\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        high       = 0.28867513459481287\n",
            "        low        = -0.28867513459481287\n",
            "        requires_grad = False\n",
            "        shape      = (3, 3, 8, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:44: in rand\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(np.random.rand(*shape).astype(dtype), device=\u001b[96mself\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        dtype      = 'float32'\n",
            "        self       = cuda()\n",
            "        shape      = (3, 3, 8, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[0.5488135 , 0.71518934, 0.60276335, 0.5448832 , 0.4236548 ,\n",
            "          0.6458941 , 0.4375872 , 0.891773  ],\n",
            " ...89734, 0.9682864 , 0.9197828 , 0.03603382, 0.17477201,\n",
            "          0.38913468, 0.9521427 , 0.30002892]]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x79219a2b99d0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 3, 8, 8), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x79219a2b9010>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 3, 8, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-8-3-2] _\u001b[0m\n",
            "\n",
            "s = 14, cin = 8, cout = 8, k = 3, stride = 2, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_back_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_backward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "cin        = 8\n",
            "cout       = 8\n",
            "device     = cuda()\n",
            "k          = 3\n",
            "s          = 14\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:374: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_conv.py\u001b[0m:35: in __init__\n",
            "    \u001b[0minit.kaiming_uniform(\u001b[90m\u001b[39;49;00m\n",
            "        __class__  = <class 'needle.nn.nn_conv.Conv'>\n",
            "        bias       = True\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        fan_in     = 72\n",
            "        fan_out    = 72\n",
            "        in_channels = 8\n",
            "        kernel_size = 3\n",
            "        out_channels = 8\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x79219a2ff290>\n",
            "        stride     = 2\n",
            "        weight_shape = (3, 3, 8, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/init/init_initializers.py\u001b[0m:30: in kaiming_uniform\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m rand(*shape, low=-bound, high=bound, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        bound      = 0.28867513459481287\n",
            "        fan_in     = 72\n",
            "        fan_out    = 72\n",
            "        kwargs     = {'device': cuda(), 'dtype': 'float32'}\n",
            "        nonlinearity = 'relu'\n",
            "        shape      = (3, 3, 8, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/init/init_basic.py\u001b[0m:8: in rand\n",
            "    \u001b[0marray = device.rand(*shape) * (high - low) + low\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        high       = 0.28867513459481287\n",
            "        low        = -0.28867513459481287\n",
            "        requires_grad = False\n",
            "        shape      = (3, 3, 8, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:44: in rand\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(np.random.rand(*shape).astype(dtype), device=\u001b[96mself\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        dtype      = 'float32'\n",
            "        self       = cuda()\n",
            "        shape      = (3, 3, 8, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[0.5488135 , 0.71518934, 0.60276335, 0.5448832 , 0.4236548 ,\n",
            "          0.6458941 , 0.4375872 , 0.891773  ],\n",
            " ...89734, 0.9682864 , 0.9197828 , 0.03603382, 0.17477201,\n",
            "          0.38913468, 0.9521427 , 0.30002892]]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x79219a2fe990>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 3, 8, 8), strides = None, device = cuda(), handle = None, offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x79219a2ff4a0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 3, 8, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-16-8-3-1] _\u001b[0m\n",
            "\n",
            "s = 14, cin = 16, cout = 8, k = 3, stride = 1, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_back_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_backward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "cin        = 16\n",
            "cout       = 8\n",
            "device     = cuda()\n",
            "k          = 3\n",
            "s          = 14\n",
            "stride     = 1\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:374: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_conv.py\u001b[0m:35: in __init__\n",
            "    \u001b[0minit.kaiming_uniform(\u001b[90m\u001b[39;49;00m\n",
            "        __class__  = <class 'needle.nn.nn_conv.Conv'>\n",
            "        bias       = True\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        fan_in     = 144\n",
            "        fan_out    = 72\n",
            "        in_channels = 16\n",
            "        kernel_size = 3\n",
            "        out_channels = 8\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x79219a2ba1b0>\n",
            "        stride     = 1\n",
            "        weight_shape = (3, 3, 16, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/init/init_initializers.py\u001b[0m:30: in kaiming_uniform\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m rand(*shape, low=-bound, high=bound, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        bound      = 0.2041241452319315\n",
            "        fan_in     = 144\n",
            "        fan_out    = 72\n",
            "        kwargs     = {'device': cuda(), 'dtype': 'float32'}\n",
            "        nonlinearity = 'relu'\n",
            "        shape      = (3, 3, 16, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/init/init_basic.py\u001b[0m:8: in rand\n",
            "    \u001b[0marray = device.rand(*shape) * (high - low) + low\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        high       = 0.2041241452319315\n",
            "        low        = -0.2041241452319315\n",
            "        requires_grad = False\n",
            "        shape      = (3, 3, 16, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:44: in rand\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(np.random.rand(*shape).astype(dtype), device=\u001b[96mself\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        dtype      = 'float32'\n",
            "        self       = cuda()\n",
            "        shape      = (3, 3, 16, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[0.5488135 , 0.71518934, 0.60276335, ..., 0.6458941 ,\n",
            "          0.4375872 , 0.891773  ],\n",
            "         [0.96366274...3],\n",
            "         [0.10244628, 0.39702582, 0.27664974, ..., 0.7064106 ,\n",
            "          0.02457702, 0.63398695]]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x79219a2bbd10>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 3, 16, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x79219a2bb080>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 3, 16, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[31m\u001b[1m_ test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-16-8-3-2] _\u001b[0m\n",
            "\n",
            "s = 14, cin = 16, cout = 8, k = 3, stride = 2, device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33ms,cin,cout,k,stride\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, conv_back_params)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_nn_conv_backward\u001b[39;49;00m(s, cin, cout, k, stride, device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mtorch\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       f = ndl.nn.Conv(cin, cout, k, stride=stride, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "cin        = 16\n",
            "cout       = 8\n",
            "device     = cuda()\n",
            "k          = 3\n",
            "s          = 14\n",
            "stride     = 2\n",
            "torch      = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:374: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpython/needle/nn/nn_conv.py\u001b[0m:35: in __init__\n",
            "    \u001b[0minit.kaiming_uniform(\u001b[90m\u001b[39;49;00m\n",
            "        __class__  = <class 'needle.nn.nn_conv.Conv'>\n",
            "        bias       = True\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        fan_in     = 144\n",
            "        fan_out    = 72\n",
            "        in_channels = 16\n",
            "        kernel_size = 3\n",
            "        out_channels = 8\n",
            "        self       = <needle.nn.nn_conv.Conv object at 0x79219a2ff680>\n",
            "        stride     = 2\n",
            "        weight_shape = (3, 3, 16, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/init/init_initializers.py\u001b[0m:30: in kaiming_uniform\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m rand(*shape, low=-bound, high=bound, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        bound      = 0.2041241452319315\n",
            "        fan_in     = 144\n",
            "        fan_out    = 72\n",
            "        kwargs     = {'device': cuda(), 'dtype': 'float32'}\n",
            "        nonlinearity = 'relu'\n",
            "        shape      = (3, 3, 16, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/init/init_basic.py\u001b[0m:8: in rand\n",
            "    \u001b[0marray = device.rand(*shape) * (high - low) + low\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        dtype      = 'float32'\n",
            "        high       = 0.2041241452319315\n",
            "        low        = -0.2041241452319315\n",
            "        requires_grad = False\n",
            "        shape      = (3, 3, 16, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:44: in rand\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDArray(np.random.rand(*shape).astype(dtype), device=\u001b[96mself\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        dtype      = 'float32'\n",
            "        self       = cuda()\n",
            "        shape      = (3, 3, 16, 8)\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:119: in __init__\n",
            "    \u001b[0marray = \u001b[96mself\u001b[39;49;00m.make(other.shape, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "        device     = cuda()\n",
            "        other      = array([[[[0.5488135 , 0.71518934, 0.60276335, ..., 0.6458941 ,\n",
            "          0.4375872 , 0.891773  ],\n",
            "         [0.96366274...3],\n",
            "         [0.10244628, 0.39702582, 0.27664974, ..., 0.7064106 ,\n",
            "          0.02457702, 0.63398695]]]], dtype=float32)\n",
            "        self       = <[AttributeError(\"'NDArray' object has no attribute '_device'\") raised in repr()] NDArray object at 0x79219a2ffcb0>\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "shape = (3, 3, 16, 8), strides = None, device = cuda(), handle = None\n",
            "offset = 0\n",
            "\n",
            "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        shape: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...],\u001b[90m\u001b[39;49;00m\n",
            "        strides: \u001b[96mtuple\u001b[39;49;00m[\u001b[96mint\u001b[39;49;00m, ...] | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        device: BackendDevice | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        handle: Any = \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        offset: \u001b[96mint\u001b[39;49;00m = \u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "    ) -> \u001b[33m\"\u001b[39;49;00m\u001b[33mNDArray\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Create a new NDArray with the given properties.  This will allocation the\u001b[39;49;00m\n",
            "    \u001b[33m    memory if handle=None, otherwise it will use the handle of an existing\u001b[39;49;00m\n",
            "    \u001b[33m    array.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        array = NDArray.\u001b[92m__new__\u001b[39;49;00m(NDArray)\u001b[90m\u001b[39;49;00m\n",
            "        array._shape = \u001b[96mtuple\u001b[39;49;00m(shape)\u001b[90m\u001b[39;49;00m\n",
            "        array._strides = NDArray.compact_strides(shape) \u001b[94mif\u001b[39;49;00m strides \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m strides\u001b[90m\u001b[39;49;00m\n",
            "        array._offset = offset\u001b[90m\u001b[39;49;00m\n",
            "        array._device = device \u001b[94mif\u001b[39;49;00m device \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m default_device()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m handle \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           array._handle = array.device.Array(prod(shape))\u001b[90m\u001b[39;49;00m\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: CUDA driver version is insufficient for CUDA runtime version\u001b[0m\n",
            "\n",
            "array      = <[AttributeError(\"'NDArray' object has no attribute '_handle'\") raised in repr()] NDArray object at 0x79219a2ffda0>\n",
            "device     = cuda()\n",
            "handle     = None\n",
            "offset     = 0\n",
            "shape      = (3, 3, 16, 8)\n",
            "strides    = None\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/backend_ndarray/ndarray.py\u001b[0m:161: RuntimeError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-4-1-1-3-1]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-16-3-1]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-16-3-2]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-8-3-1]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-8-3-2]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-16-8-3-1]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-16-8-3-2]\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-4-1-1-3-1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-16-3-1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-16-3-2]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-8-3-1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-8-8-3-2]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-16-8-3-1]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cuda-14-16-8-3-2]\u001b[0m - RuntimeError: CUDA driver version is insufficient for CUDA runtime version\n",
            "\u001b[31m===================== \u001b[31m\u001b[1m14 failed\u001b[0m, \u001b[33m1789 deselected\u001b[0m\u001b[31m in 6.25s\u001b[0m\u001b[31m ======================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"nn_conv_backward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0Ng0Y-r66oW"
      },
      "source": [
        "-----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGEijrER66oW"
      },
      "source": [
        "### Submit nn.Conv to mugrade [20 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9d0-Qrj66oW",
        "outputId": "4c84ee03-86b3-43ab-86bf-dae067b5f64b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submit\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: langsmith-0.4.42, typeguard-4.4.4, anyio-4.11.0\n",
            "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
            "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py \n",
            "Submitting conv_forward...\n",
            "\u001b[31mF\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m_____________________________ submit_conv_forward ______________________________\u001b[0m\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92msubmit_conv_forward\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mDoConvOp\u001b[39;49;00m(batches, cin, cout, n, k=\u001b[94m3\u001b[39;49;00m, stride=\u001b[94m1\u001b[39;49;00m, padding=\u001b[94m0\u001b[39;49;00m, device=ndl.cpu()):\u001b[90m\u001b[39;49;00m\n",
            "            X = Rand(batches, n, n, cin, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            W = Rand(k, k, cin, cout, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            y = ndl.conv(X, W, stride=stride, padding=padding)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m y\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mDoConvLayer\u001b[39;49;00m(batches, cin, cout, n, k=\u001b[94m3\u001b[39;49;00m, stride=\u001b[94m1\u001b[39;49;00m, bias=\u001b[94mTrue\u001b[39;49;00m, device=ndl.cpu()):\u001b[90m\u001b[39;49;00m\n",
            "            X = Rand(batches, cin, n, n, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            f = ndl.nn.Conv(cin, cout, k, stride=stride, bias=bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m f(X)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       MugradeSubmit(DoConvOp(\u001b[94m2\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, k=\u001b[94m1\u001b[39;49;00m, stride=\u001b[94m1\u001b[39;49;00m, padding=\u001b[94m0\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:530: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:522: in DoConvOp\n",
            "    \u001b[0my = ndl.conv(X, W, stride=stride, padding=padding)\u001b[90m\u001b[39;49;00m\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x7830bbffbd40>\n",
            "A = NDArray([[[[3.]\n",
            "   [4.]\n",
            "   [6.]\n",
            "   [3.]]\n",
            "\n",
            "  [[8.]\n",
            "   [3.]\n",
            "   [5.]\n",
            "   [6.]]\n",
            "\n",
            "  [[2.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [8.]]\n",
            "\n",
            "  [[6.]\n",
            "...\n",
            "\n",
            "  [[7.]\n",
            "   [1.]\n",
            "   [8.]\n",
            "   [5.]]\n",
            "\n",
            "  [[8.]\n",
            "   [9.]\n",
            "   [9.]\n",
            "   [7.]]\n",
            "\n",
            "  [[8.]\n",
            "   [1.]\n",
            "   [5.]\n",
            "   [4.]]]], device=cpu())\n",
            "B = NDArray([[[[4. 5.]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1msubmit_conv_forward\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[31m in 3.17s\u001b[0m\u001b[31m ========================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"conv_forward\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88gWXNl666oW",
        "outputId": "5c295565-a699-4a3e-fe6c-f00065420458"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submit\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: langsmith-0.4.42, typeguard-4.4.4, anyio-4.11.0\n",
            "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
            "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py \n",
            "Submitting conv_backward...\n",
            "\u001b[31mF\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m_____________________________ submit_conv_backward _____________________________\u001b[0m\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92msubmit_conv_backward\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mDoConvOpBackward\u001b[39;49;00m(batches, cin, cout, n, k=\u001b[94m3\u001b[39;49;00m, stride=\u001b[94m1\u001b[39;49;00m, padding=\u001b[94m0\u001b[39;49;00m, device=ndl.cpu(), wrtX=\u001b[94mTrue\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "            X = Rand(batches, n, n, cin, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            X.requires_grad = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            W = Rand(k, k, cin, cout, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            W.requires_grad = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            y = ndl.conv(X, W, stride=stride, padding=padding).sum()\u001b[90m\u001b[39;49;00m\n",
            "            y.backward()\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m wrtX:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m W.grad\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m X.grad\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mDoConvLayerBackward\u001b[39;49;00m(batches, cin, cout, n, k=\u001b[94m3\u001b[39;49;00m, stride=\u001b[94m1\u001b[39;49;00m, bias=\u001b[94mTrue\u001b[39;49;00m, device=ndl.cpu(), wrtX=\u001b[94mTrue\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "            X = Rand(batches, cin, n, n, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            X.requires_grad = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            f = ndl.nn.Conv(cin, cout, k, stride=stride, bias=bias, device=device)\u001b[90m\u001b[39;49;00m\n",
            "            y = f(X).sum()\u001b[90m\u001b[39;49;00m\n",
            "            y.backward()\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m wrtX:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m f.weight.grad\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m X.grad\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       MugradeSubmit(DoConvOpBackward(\u001b[94m2\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, k=\u001b[94m1\u001b[39;49;00m, stride=\u001b[94m1\u001b[39;49;00m, padding=\u001b[94m0\u001b[39;49;00m, wrtX=\u001b[94mTrue\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:579: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:561: in DoConvOpBackward\n",
            "    \u001b[0my = ndl.conv(X, W, stride=stride, padding=padding).sum()\u001b[90m\u001b[39;49;00m\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:627: in conv\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Conv(stride, padding)(a, b)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:80: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
            "    \u001b[0mtensor.realize_cached_data()\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:107: in realize_cached_data\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.cached_data = \u001b[96mself\u001b[39;49;00m.op.compute(\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <needle.ops.ops_mathematic.Conv object at 0x78f8c3154170>\n",
            "A = NDArray([[[[3.]\n",
            "   [4.]\n",
            "   [6.]\n",
            "   [3.]]\n",
            "\n",
            "  [[8.]\n",
            "   [3.]\n",
            "   [5.]\n",
            "   [6.]]\n",
            "\n",
            "  [[2.]\n",
            "   [1.]\n",
            "   [1.]\n",
            "   [8.]]\n",
            "\n",
            "  [[6.]\n",
            "...\n",
            "\n",
            "  [[7.]\n",
            "   [1.]\n",
            "   [8.]\n",
            "   [5.]]\n",
            "\n",
            "  [[8.]\n",
            "   [9.]\n",
            "   [9.]\n",
            "   [7.]]\n",
            "\n",
            "  [[8.]\n",
            "   [1.]\n",
            "   [5.]\n",
            "   [4.]]]], device=cpu())\n",
            "B = NDArray([[[[4. 5.]]]], device=cpu())\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcompute\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, A, B):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        K = B.shape[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            "        A_padded = \u001b[96mself\u001b[39;49;00m._pad_input(A)\u001b[90m\u001b[39;49;00m\n",
            "        cols, out_h, out_w = \u001b[96mself\u001b[39;49;00m._im2col(A_padded, K)\u001b[90m\u001b[39;49;00m\n",
            "        W_col = B.compact().reshape((K * K * B.shape[\u001b[94m2\u001b[39;49;00m], B.shape[\u001b[94m3\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
            ">       out = cols.matmul(W_col)\u001b[90m\u001b[39;49;00m\n",
            "              ^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AttributeError: 'NDArray' object has no attribute 'matmul'\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mpython/needle/ops/ops_mathematic.py\u001b[0m:535: AttributeError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1msubmit_conv_backward\u001b[0m - AttributeError: 'NDArray' object has no attribute 'matmul'\n",
            "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[31m in 3.99s\u001b[0m\u001b[31m ========================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"conv_backward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJcZte0f66oW"
      },
      "source": [
        "------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "n8cvGdGM66oW"
      },
      "source": [
        "### Implementing \"ResNet9\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWK5kZut66oW"
      },
      "source": [
        "You will now use your convolutional layer to implement a model similar to _ResNet9_, which is known to be a reasonable model for getting good accuracy on CIFAR-10 quickly (see [here](https://github.com/davidcpage/cifar10-fast)). Our main change is that we used striding instead of pooling and divided all of the channels by 4 for the sake of performance (as our framework is not as well-optimized as industry-grade frameworks).\n",
        "\n",
        "In the figure below, before the first linear layer, you should \"flatten\" the tensor. You can use the module `Flatten` in `nn_basic.py`, or you can simply use `.reshape` in the `forward()` method of your ResNet9.\n",
        "\n",
        "Make sure that you pass the device to all modules in your model; otherwise, you will get errors about mismatched devices when trying to run with CUDA.\n",
        "\n",
        "<center><img src=\"https://github.com/dlsyscourse/hw4/blob/main/ResNet9.png?raw=true\" alt=\"ResNet9\" style=\"width: 400px;\" /></center>\n",
        "\n",
        "We have tried to make it easier to pass the tests here than for previous assignments where you have implemented models. In particular, we are just going to make sure it has the right number of parameters and similar accuracy and loss after 1 or 2 batches of CIFAR-10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToWdFfjP66oW",
        "outputId": "f502ac5b-0a3f-4a76-98ed-9c3c6974e47d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: langsmith-0.4.42, typeguard-4.4.4, anyio-4.11.0\n",
            "collected 1803 items / 1801 deselected / 2 selected                            \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py::test_resnet9[needle.backend_ndarray.ndarray_backend_cpu] \u001b[31mFAILED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_resnet9[needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m___________ test_resnet9[needle.backend_ndarray.ndarray_backend_cpu] ___________\u001b[0m\n",
            "\n",
            "device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_resnet9\u001b[39;49;00m(device):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mnum_params\u001b[39;49;00m(model):\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m np.sum([np.prod(x.shape) \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m model.parameters()])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mapps\u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96mmodels\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[94mimport\u001b[39;49;00m ResNet9\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            ">       model = ResNet9(device=device)\u001b[90m\u001b[39;49;00m\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "ResNet9    = <class 'apps.models.ResNet9'>\n",
            "device     = cpu()\n",
            "num_params = <function test_resnet9.<locals>.num_params at 0x799cd1fc11c0>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:180: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <apps.models.ResNet9 object at 0x799cd2678740>, device = cpu()\n",
            "dtype = 'float32'\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[96msuper\u001b[39;49;00m().\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION ###\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m() \u001b[90m###\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
            "\n",
            "__class__  = <class 'apps.models.ResNet9'>\n",
            "device     = cpu()\n",
            "dtype      = 'float32'\n",
            "self       = <apps.models.ResNet9 object at 0x799cd2678740>\n",
            "\n",
            "\u001b[1m\u001b[31mapps/models.py\u001b[0m:14: NotImplementedError\n",
            "\u001b[31m\u001b[1m__________ test_resnet9[needle.backend_ndarray.ndarray_backend_cuda] ___________\u001b[0m\n",
            "\n",
            "device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_resnet9\u001b[39;49;00m(device):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mnum_params\u001b[39;49;00m(model):\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m np.sum([np.prod(x.shape) \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m model.parameters()])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mapps\u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96mmodels\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[94mimport\u001b[39;49;00m ResNet9\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            ">       model = ResNet9(device=device)\u001b[90m\u001b[39;49;00m\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "ResNet9    = <class 'apps.models.ResNet9'>\n",
            "device     = cuda()\n",
            "num_params = <function test_resnet9.<locals>.num_params at 0x799cd1fc1f80>\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:180: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <apps.models.ResNet9 object at 0x799cd1a034a0>, device = cuda()\n",
            "dtype = 'float32'\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[96msuper\u001b[39;49;00m().\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION ###\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m() \u001b[90m###\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
            "\n",
            "__class__  = <class 'apps.models.ResNet9'>\n",
            "device     = cuda()\n",
            "dtype      = 'float32'\n",
            "self       = <apps.models.ResNet9 object at 0x799cd1a034a0>\n",
            "\n",
            "\u001b[1m\u001b[31mapps/models.py\u001b[0m:14: NotImplementedError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_resnet9[needle.backend_ndarray.ndarray_backend_cpu]\u001b[0m - NotImplementedError\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_resnet9[needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - NotImplementedError\n",
            "\u001b[31m====================== \u001b[31m\u001b[1m2 failed\u001b[0m, \u001b[33m1801 deselected\u001b[0m\u001b[31m in 3.27s\u001b[0m\u001b[31m ======================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"resnet9\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS9aoPo166oX"
      },
      "source": [
        "Now we can train a ResNet on CIFAR10: (remember to copy the solutions in `python/needle/optim.py` from previous homeworks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MgL71Rc66oX",
        "outputId": "dd2b9816-4044-4d6f-a41f-4e300890a61d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: langsmith-0.4.42, typeguard-4.4.4, anyio-4.11.0\n",
            "collected 1803 items / 1801 deselected / 2 selected                            \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py::test_train_cifar10[needle.backend_ndarray.ndarray_backend_cpu] \u001b[31mFAILED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_train_cifar10[needle.backend_ndarray.ndarray_backend_cuda] \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m________ test_train_cifar10[needle.backend_ndarray.ndarray_backend_cpu] ________\u001b[0m\n",
            "\n",
            "device = cpu()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_train_cifar10\u001b[39;49;00m(device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        dataset = ndl.data.CIFAR10Dataset(\u001b[33m\"\u001b[39;49;00m\u001b[33m./data/cifar-10-batches-py\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, train=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        dataloader = ndl.data.DataLoader(\\\n",
            "                 dataset=dataset,\u001b[90m\u001b[39;49;00m\n",
            "                 batch_size=\u001b[94m128\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "                 shuffle=\u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                 \u001b[90m# collate_fn=ndl.data.collate_ndarray,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                 \u001b[90m# drop_last=False,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                 \u001b[90m# device=device,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                 \u001b[90m# dtype=\"float32\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                 )\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mapps\u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96mmodels\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[94mimport\u001b[39;49;00m ResNet9\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            ">       model = ResNet9(device=device, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "ResNet9    = <class 'apps.models.ResNet9'>\n",
            "dataloader = <needle.data.data_basic.DataLoader object at 0x7e76c9b3fcb0>\n",
            "dataset    = <needle.data.datasets.cifar10_dataset.CIFAR10Dataset object at 0x7e77b07ae810>\n",
            "device     = cpu()\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:466: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <apps.models.ResNet9 object at 0x7e76c9d50bc0>, device = cpu()\n",
            "dtype = 'float32'\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[96msuper\u001b[39;49;00m().\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION ###\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m() \u001b[90m###\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
            "\n",
            "__class__  = <class 'apps.models.ResNet9'>\n",
            "device     = cpu()\n",
            "dtype      = 'float32'\n",
            "self       = <apps.models.ResNet9 object at 0x7e76c9d50bc0>\n",
            "\n",
            "\u001b[1m\u001b[31mapps/models.py\u001b[0m:14: NotImplementedError\n",
            "\u001b[31m\u001b[1m_______ test_train_cifar10[needle.backend_ndarray.ndarray_backend_cuda] ________\u001b[0m\n",
            "\n",
            "device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_train_cifar10\u001b[39;49;00m(device):\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        dataset = ndl.data.CIFAR10Dataset(\u001b[33m\"\u001b[39;49;00m\u001b[33m./data/cifar-10-batches-py\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, train=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        dataloader = ndl.data.DataLoader(\\\n",
            "                 dataset=dataset,\u001b[90m\u001b[39;49;00m\n",
            "                 batch_size=\u001b[94m128\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "                 shuffle=\u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                 \u001b[90m# collate_fn=ndl.data.collate_ndarray,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                 \u001b[90m# drop_last=False,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                 \u001b[90m# device=device,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                 \u001b[90m# dtype=\"float32\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                 )\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mapps\u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96mmodels\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[94mimport\u001b[39;49;00m ResNet9\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            ">       model = ResNet9(device=device, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "ResNet9    = <class 'apps.models.ResNet9'>\n",
            "dataloader = <needle.data.data_basic.DataLoader object at 0x7e77b07e1c70>\n",
            "dataset    = <needle.data.datasets.cifar10_dataset.CIFAR10Dataset object at 0x7e77b082d190>\n",
            "device     = cuda()\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:466: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <apps.models.ResNet9 object at 0x7e76c9d7fa70>, device = cuda()\n",
            "dtype = 'float32'\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[96msuper\u001b[39;49;00m().\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION ###\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m() \u001b[90m###\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
            "\n",
            "__class__  = <class 'apps.models.ResNet9'>\n",
            "device     = cuda()\n",
            "dtype      = 'float32'\n",
            "self       = <apps.models.ResNet9 object at 0x7e76c9d7fa70>\n",
            "\n",
            "\u001b[1m\u001b[31mapps/models.py\u001b[0m:14: NotImplementedError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_train_cifar10[needle.backend_ndarray.ndarray_backend_cpu]\u001b[0m - NotImplementedError\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1mtest_train_cifar10[needle.backend_ndarray.ndarray_backend_cuda]\u001b[0m - NotImplementedError\n",
            "\u001b[31m====================== \u001b[31m\u001b[1m2 failed\u001b[0m, \u001b[33m1801 deselected\u001b[0m\u001b[31m in 6.15s\u001b[0m\u001b[31m ======================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"train_cifar10\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sfNQTU766oX"
      },
      "source": [
        "### Submit ResNet9 to mugrade [10 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aamSbJqM66oX",
        "outputId": "a9cd82ba-c3eb-417d-aa40-8380c517f897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submit\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: langsmith-0.4.42, typeguard-4.4.4, anyio-4.11.0\n",
            "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
            "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py \n",
            "Submitting resnet9...\n",
            "\u001b[31mF\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m________________________________ submit_resnet9 ________________________________\u001b[0m\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92msubmit_resnet9\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mnum_params\u001b[39;49;00m(model):\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m np.sum([np.prod(x.shape) \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m model.parameters()])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        device = ndl.cpu()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mimport\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96msys\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        sys.path.append(\u001b[33m'\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mapps\u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96mmodels\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[94mimport\u001b[39;49;00m ResNet9\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(\u001b[94m1\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            ">       model = ResNet9(device=device)\u001b[90m\u001b[39;49;00m\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_conv.py\u001b[0m:661: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = <apps.models.ResNet9 object at 0x7a4f9a32c770>, device = cpu()\n",
            "dtype = 'float32'\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m__init__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, device=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[96msuper\u001b[39;49;00m().\u001b[92m__init__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m### BEGIN YOUR SOLUTION ###\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94mraise\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m() \u001b[90m###\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       NotImplementedError\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mapps/models.py\u001b[0m:14: NotImplementedError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_conv.py::\u001b[1msubmit_resnet9\u001b[0m - NotImplementedError\n",
            "\u001b[31m======================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[31m in 3.07s\u001b[0m\u001b[31m ========================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"resnet9\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glguG1bw66oX"
      },
      "source": [
        "-----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxER6INt66oX"
      },
      "source": [
        "Now, you can train your model on CIFAR-10 using the following code. Note that this is likely going to be quite slow, and also  not all that accurate due to the lack of data augmentation. You should expect it to take around 500s per epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "bU6Rrc7D66oX",
        "outputId": "d40cc0d5-c093-4c11-d10e-dffcd96792a8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1616907413.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCIFAR10Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/cifar-10-batches-py\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m dataloader = ndl.data.DataLoader(\\\n\u001b[1;32m     11\u001b[0m          \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/10714/hw4/python/needle/data/datasets/cifar10_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, base_folder, train, p, transforms)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \"\"\"\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m### BEGIN YOUR SOLUTION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('./python')\n",
        "sys.path.append('./apps')\n",
        "import needle as ndl\n",
        "from models import ResNet9\n",
        "from simple_ml import train_cifar10, evaluate_cifar10\n",
        "\n",
        "device = ndl.cpu()\n",
        "dataset = ndl.data.CIFAR10Dataset(\"data/cifar-10-batches-py\", train=True)\n",
        "dataloader = ndl.data.DataLoader(\\\n",
        "         dataset=dataset,\n",
        "         batch_size=128,\n",
        "         shuffle=True,)\n",
        "model = ResNet9(device=device, dtype=\"float32\")\n",
        "train_cifar10(model, dataloader, n_epochs=10, optimizer=ndl.optim.Adam,\n",
        "      lr=0.001, weight_decay=0.001)\n",
        "evaluate_cifar10(model, dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPgCcXde66oX"
      },
      "source": [
        "## Part 4: Recurrent neural network [10 points]\n",
        "\n",
        "**Note:** In the following sections, you may find yourself wanting to index into tensors, i.e., to use getitem or setitem. However, we have not implemented these for tensors in our library; instead, you should use `stack` and `split` operations.\n",
        "\n",
        "In `python/needle/nn/nn_sequence.py`, implement `RNNCell`.\n",
        "\n",
        "$h^\\prime = \\text{tanh}(xW_{ih} + b_{ih} + hW_{hh} + b_{hh})$. If nonlinearity is 'relu', then ReLU is used in place of tanh.\n",
        "\n",
        "All weights and biases should be uniformly initialized on the interval $\\displaystyle\\pm\\frac{1}{\\sqrt{\\verb|hidden_size|}}$.\n",
        "\n",
        "In `python/needle/nn/nn_sequence.py`, implement `RNN`.\n",
        "\n",
        "For each element in the input sequence, each layer computes the following function:\n",
        "\n",
        "$h_t = \\text{tanh}(x_tW_{ih} + b_{ih} + h_{(t-1)}W_{hh} + b_{hh})$\n",
        "\n",
        "where $h_t$ is the hidden state at time $t$, $x_t$ is the input at time $t$, and $h_{(t-1)}$ is the hidden state of the previous layer at time $t-1$ or the initial hidden state at time $0$. If nonlinearity is 'relu', then ReLU is used in place of tanh.\n",
        "\n",
        "In a multi-layer RNN, the input $x_t^{(l)}$ of the $l$-th layer ($l \\ge 2$) is the hidden state $h_t^{(l-1)}$ of the previous layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZT3SSAL66oX"
      },
      "outputs": [],
      "source": [
        "!python3 -m pytest -l -v -k \"test_rnn\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbjuGlvS66oX"
      },
      "outputs": [],
      "source": [
        "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"rnn\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfR5b_Rl66oX"
      },
      "source": [
        "## Part 5: Long short-term memory network [10 points]\n",
        "In `python/needle/nn/nn_sequence.py`, implement `Sigmoid`.\n",
        "\n",
        "$$\\sigma(x) = \\frac{1}{1 + \\text{exp}(-x)}$$\n",
        "\n",
        "In `python/needle/nn/nn_sequence.py`, implement `LSTMCell`.\n",
        "\n",
        "\\begin{align*}\n",
        "i &= \\sigma(xW_{ii} + b_{ii} + hW_{hi} + b_{hi}) \\\\\n",
        "f &= \\sigma(xW_{if} + b_{if} + hW_{hf} + b_{hf}) \\\\\n",
        "g &= \\text{tanh}(xW_{ig} + b_{ig} + hW_{hg} + b_{hg}) \\\\\n",
        "o &= \\sigma(xW_{io} + b_{io} + hW_{ho} + b_{ho}) \\\\\n",
        "c^\\prime &= f * c + i * g \\\\\n",
        "h^\\prime &= o * \\text{tanh}(c^\\prime)\n",
        "\\end{align*}\n",
        "\n",
        "where $\\sigma$ is the sigmoid function, and $i$, $f$, $g$, $o$ are the input, forget, cell, and output gates, respectively.\n",
        "\n",
        "All weights and biases should be uniformly initialized on the interval $\\displaystyle\\pm\\frac{1}{\\sqrt{\\verb|hidden_size|}}$.\n",
        "\n",
        "Now implement `LSTM` in `python/needle/nn/nn_sequence.py`, which applies a multi-layer LSTM RNN to an input sequence. For each element in the input sequence, each layer computes the following function:\n",
        "\n",
        "\\begin{align*}\n",
        "i_t &= \\sigma(x_tW_{ii} + b_{ii} + h_{(t-1)}W_{hi} + b_{hi}) \\\\\n",
        "f_t &= \\sigma(x_tW_{if} + b_{if} + h_{(t-1)}W_{hf} + b_{hf}) \\\\\n",
        "g_t &= \\text{tanh}(x_tW_{ig} + b_{ig} + h_{(t-1)}W_{hg} + b_{hg}) \\\\\n",
        "o_t &= \\sigma(x_tW_{io} + b_{io} + h_{(t-1)}W_{ho} + b_{ho}) \\\\\n",
        "c_t &= f * c_{(t-1)} + i * g \\\\\n",
        "h_t &= o * \\text{tanh}(c_t)\n",
        "\\end{align*}\n",
        "\n",
        "where $h_t$ is the hidden state at time $t$, $c_t$ is the cell state at time $t$, $x_t$ is the input at time $t$, $h_{(t-1)}$ is the hidden state of the layer at time $t-1$ or the initial hidden state at time $0$, and $i_t$, $f_t$, $g_t$, $o_t$ are the input, forget, cell, and output gates at time $t$ respectively.\n",
        "\n",
        "In a multi-layer LSTM, the input $x_t^{(l)}$ of the $l$-th layer ($l \\ge 2$) is the hidden state $h_t^{(l-1)}$ of the previous layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irJRRmpJ66oX"
      },
      "outputs": [],
      "source": [
        "!python3 -m pytest -l -v -k \"test_lstm\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddRdW2Hc66oX"
      },
      "outputs": [],
      "source": [
        "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"lstm\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1DZH3fG66oX"
      },
      "source": [
        "## Part 6: Penn Treebank dataset [10 points]\n",
        "\n",
        "In word-level language modeling tasks, the model predicts the probability of the next word in the sequence, based on the words already observed in the sequence. You will write support for the Penn Treebank dataset, which consists of stories from the Wall Street Journal, to train and evaluate a language model on word-level prediction.\n",
        "\n",
        "In `python/needle/data/datasets/ptb_dataset.py`, start by implementing the `Dictionary` class, which creates a dictionary from a list of words, mapping each word to a unique integer.\n",
        "\n",
        "Next, we will use this `Dictionary` class to create a corpus from the train and test txt files in the Penn Treebank dataset that you downloaded at the beginning of the notebook. Implement the `tokenize` function in the `Corpus` class to do this.\n",
        "\n",
        "In order to prepare the data for training and evaluation, you will next implement the `batchify` function. Starting from sequential data, batchify arranges the dataset into columns. For instance, with the alphabet as the sequence and batch size 4, we'd get\n",
        "\n",
        "```\n",
        " a g m s \n",
        " b h n t \n",
        " c i o u \n",
        " d j p v \n",
        " e k q w \n",
        " f l r x \n",
        "```\n",
        "\n",
        "These columns are treated as independent by the model, which means that the dependence of e. g. 'g' on 'f' cannot be learned, but allows more efficient batch processing.\n",
        "\n",
        "Next, implement the `get_batch` function. `get_batch` subdivides the source data into chunks of length `bptt`. If source is equal to the example output of the batchify function, with a bptt-limit of 2, we'd get the following two `Tensor`s for i = 0:\n",
        "```\n",
        " a g m s   b h n t \n",
        " b h n t   c i o u \n",
        "```\n",
        "Note that despite the name of the function, the subdivison of data is not done along the batch dimension (i.e. dimension 1), since that was handled by the batchify function. The chunks are along dimension 0, corresponding to the seq_len dimension in the LSTM or RNN. Also, as per the function docs, the second returned `Tensor` (the targets) should be reshaped to be 1-dimensional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHv9ar4466oX"
      },
      "outputs": [],
      "source": [
        "!python3 -m pytest -l -v -k \"ptb\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPT4ZRTf66oX"
      },
      "outputs": [],
      "source": [
        "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"ptb\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdrjfqjH66oX"
      },
      "source": [
        "## Part 7: Training a word-level language model [10 points]\n",
        "\n",
        "Finally, you will use the `RNN` and `LSTM` components you have written to construct a language model that we will train on the Penn Treebank dataset.\n",
        "\n",
        "First, in `python/needle/nn/nn_sequence.py` implement `Embedding`. Consider we have a dictionary with 1000 words. Then for a word which indexes into this dictionary, we can represent this word as a one-hot vector of size 1000, and then use a linear layer to project this to a vector of some embedding size.\n",
        "\n",
        "In `apps/models.py`, you can now implement `LanguageModel`. Your language model should consist of\n",
        "\n",
        "- An embedding layer (which maps word IDs to embeddings)\n",
        "- A sequence model (either RNN or LSTM)\n",
        "- A linear layer (which outputs probabilities of the next word)\n",
        "\n",
        "In `apps/simple_ml.py` implement `epoch_general_ptb`, `train_ptb`, and `evaluate_ptb`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwIJkFgK66oX"
      },
      "outputs": [],
      "source": [
        "!python3 -m pytest -l -v -k \"language_model_implementation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIieU9Z266oX"
      },
      "outputs": [],
      "source": [
        "!python3 -m pytest -l -v -k \"language_model_training\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFH6urZ-66oX"
      },
      "outputs": [],
      "source": [
        "!python3 -m mugrade submit \"$MY_API_KEY\" \"$HW4_NAME\" -k \"language_model\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWTeEq_O66oX"
      },
      "source": [
        "Now, you can train your language model on the Penn Treebank dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlJ72eM-66oX"
      },
      "outputs": [],
      "source": [
        "import needle as ndl\n",
        "sys.path.append('./apps')\n",
        "from models import LanguageModel\n",
        "from simple_ml import train_ptb, evaluate_ptb\n",
        "\n",
        "device = ndl.cpu()\n",
        "corpus = ndl.data.Corpus(\"data/ptb\")\n",
        "train_data = ndl.data.batchify(corpus.train, batch_size=16, device=ndl.cpu(), dtype=\"float32\")\n",
        "model = LanguageModel(30, len(corpus.dictionary), hidden_size=10, num_layers=2, seq_model='rnn', device=ndl.cpu())\n",
        "train_ptb(model, train_data, seq_len=1, n_epochs=1, device=device)\n",
        "evaluate_ptb(model, train_data, seq_len=40, device=device)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}